{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSf4fKcfnQQY9uPUwwP65r"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 ##"
      ],
      "metadata": {
        "id": "dLc0p1cFNxiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io, os, re\n",
        "from google.colab import files\n",
        "\n",
        "pd.options.display.float_format = \"{:.6g}\".format\n",
        "\n",
        "# =========================\n",
        "# 설정값\n",
        "# =========================\n",
        "CONFIRM_DETECTED_COLUMNS = True\n",
        "\n",
        "# 음수→NaN\n",
        "NEGATIVE_TO_NAN = True\n",
        "\n",
        "# IQR 셀-마스킹 적용 + 완화 기준(IQR_K=3.0)\n",
        "APPLY_IQR_FILTER = True\n",
        "IQR_K = 3.0  # Tukey 기본 1.5보다 완화 → 피크 이벤트 보존\n",
        "\n",
        "# 대상 전부 NaN인 행만 삭제\n",
        "DROP_EMPTY_TARGET = True\n",
        "\n",
        "# =========================\n",
        "# 파일 업로드(Colab 위젯) + 메모리 직접 로드\n",
        "# =========================\n",
        "def _safe_basename(name: str) -> str:\n",
        "    base, ext = os.path.splitext(name)\n",
        "    base = re.sub(r\"[^\\w\\-]+\", \"_\", base).strip(\"_\")\n",
        "    return base, ext\n",
        "\n",
        "print(\"엑셀 파일(.xlsx) 1개 이상 업로드하세요.\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise RuntimeError(\"업로드된 파일이 없습니다. 다시 실행하여 업로드하세요.\")\n",
        "\n",
        "xlsx_names = [k for k in uploaded.keys() if k.lower().endswith(\".xlsx\")]\n",
        "if not xlsx_names:\n",
        "    raise RuntimeError(\"업로드된 파일 중 .xlsx 확장자가 없습니다.\")\n",
        "\n",
        "src_name = xlsx_names[0]\n",
        "print(\"Uploaded (in-memory):\", src_name)\n",
        "\n",
        "# 메모리에서 바로 DataFrame 로드\n",
        "df_raw = pd.read_excel(io.BytesIO(uploaded[src_name]))\n",
        "df_raw.columns = [str(c).strip() for c in df_raw.columns]\n",
        "\n",
        "# 원본 파일명 기반 산출물 경로 자동 설정\n",
        "_base, _ = _safe_basename(src_name)\n",
        "RAW_REPORT_PATH   = f\"{_base}_QA_raw.xlsx\"     # 전처리 전 QA\n",
        "CLEAN_REPORT_PATH = f\"{_base}_QA_clean.xlsx\"   # 전처리 후 QA\n",
        "CLEAN_DATA_PATH   = f\"{_base}_clean.xlsx\"      # 전처리 후 데이터(엑셀)\n",
        "CLEAN_DATA_CSV    = f\"{_base}_clean.csv\"       # 전처리 후 데이터(CSV)\n",
        "\n",
        "print(\"Output paths set:\")\n",
        "print(\" RAW_REPORT_PATH   =\", RAW_REPORT_PATH)\n",
        "print(\" CLEAN_REPORT_PATH =\", CLEAN_REPORT_PATH)\n",
        "print(\" CLEAN_DATA_PATH   =\", CLEAN_DATA_PATH)\n",
        "print(\" CLEAN_DATA_CSV    =\", CLEAN_DATA_CSV)\n",
        "\n",
        "# =========================\n",
        "# 유틸: 컬럼 자동 검출\n",
        "# =========================\n",
        "def detect_columns(df: pd.DataFrame):\n",
        "    df = df.copy()\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "\n",
        "    # 시간 후보\n",
        "    time_candidates = [c for c in df.columns\n",
        "                       if any(k in c.lower() for k in [\"pump-begin\", \"date\", \"datetime\", \"time\", \"측정일시\"])]\n",
        "    time_col = time_candidates[0] if len(time_candidates) > 0 else None\n",
        "\n",
        "    # PM2.5 후보\n",
        "    pm25_candidates = [c for c in df.columns\n",
        "                       if (\"pm2.5\" in c.lower())\n",
        "                       or (\"con(ug/m3)\" in c.lower())\n",
        "                       or (\"ug/m3\" in c.lower() and \"con\" in c.lower())]\n",
        "    pm25_col = pm25_candidates[0] if len(pm25_candidates) > 0 else None\n",
        "\n",
        "    # 금속 단위 패턴\n",
        "    metal_markers = [\"(ng/m3)\", \"(ng/㎥)\", \"ng/m3\", \"ng/㎥\"]\n",
        "    metal_cols = [c for c in df.columns if any(m.lower() in c.lower() for m in metal_markers)]\n",
        "\n",
        "    # 숫자형 후보(참고용)\n",
        "    numeric_cols = []\n",
        "    for c in df.columns:\n",
        "        ser = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "        if ser.notna().mean() >= 0.7:\n",
        "            numeric_cols.append(c)\n",
        "\n",
        "    return {\"time_col\": time_col, \"pm25_col\": pm25_col,\n",
        "            \"metal_cols\": metal_cols, \"numeric_cols\": numeric_cols}\n",
        "\n",
        "# =========================\n",
        "# 로드 & 자동 검출 결과 출력\n",
        "# =========================\n",
        "detected = detect_columns(df_raw)\n",
        "time_col   = detected[\"time_col\"]\n",
        "pm25_col   = detected[\"pm25_col\"]\n",
        "metal_cols = detected[\"metal_cols\"]\n",
        "numeric_cols = detected[\"numeric_cols\"]\n",
        "\n",
        "print(\"Detected time_col:\", time_col)\n",
        "print(\"Detected pm25_col:\", pm25_col)\n",
        "print(\"Detected metal_cols (first 10):\", metal_cols[:10])\n",
        "print(\"Detected numeric_cols (first 10):\", numeric_cols[:10])\n",
        "\n",
        "if not CONFIRM_DETECTED_COLUMNS:\n",
        "    raise RuntimeError(\"자동 검출된 컬럼 확인 후, 맞으면 CONFIRM_DETECTED_COLUMNS=True로 설정하세요.\")\n",
        "\n",
        "# =========================\n",
        "# QA 리포트 함수\n",
        "# =========================\n",
        "def summarize_series(s: pd.Series, name: str):\n",
        "    s_num = pd.to_numeric(s, errors=\"coerce\")\n",
        "    return pd.Series({\n",
        "        \"col\": name,\n",
        "        \"count_total\": int(s_num.shape[0]),\n",
        "        \"count_valid\": int(s_num.notna().sum()),\n",
        "        \"valid_pct\": float(100.0 * s_num.notna().mean()),\n",
        "        \"mean\": float(s_num.mean(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"std\": float(s_num.std(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"p5\": float(s_num.quantile(0.05)) if s_num.notna().any() else np.nan,\n",
        "        \"p50\": float(s_num.quantile(0.50)) if s_num.notna().any() else np.nan,\n",
        "        \"p95\": float(s_num.quantile(0.95)) if s_num.notna().any() else np.nan,\n",
        "        \"min\": float(s_num.min(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"max\": float(s_num.max(skipna=True)) if s_num.notna().any() else np.nan})\n",
        "\n",
        "def build_qc_table(df: pd.DataFrame, targets: list):\n",
        "    rows = []\n",
        "    for c in targets:\n",
        "        if c in df.columns:\n",
        "            rows.append(summarize_series(df[c], c))\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# =========================\n",
        "# 대상 컬럼 정의\n",
        "# =========================\n",
        "target_cols = []\n",
        "if pm25_col:\n",
        "    target_cols.append(pm25_col)\n",
        "if isinstance(metal_cols, (list, tuple)):\n",
        "    target_cols += list(metal_cols)\n",
        "target_cols = [c for c in target_cols if c in df_raw.columns]\n",
        "assert len(target_cols) > 0, \"PM2.5 또는 금속 대상 컬럼을 찾지 못했습니다.\"\n",
        "\n",
        "# =========================\n",
        "# QA 리포트(전처리 전)\n",
        "# =========================\n",
        "qc_raw = build_qc_table(df_raw, target_cols)\n",
        "with pd.ExcelWriter(RAW_REPORT_PATH, engine=\"openpyxl\") as w:\n",
        "    qc_raw.to_excel(w, index=False, sheet_name=\"RAW_QA\")\n",
        "\n",
        "# =========================\n",
        "# 전처리\n",
        "# =========================\n",
        "df_clean = df_raw.copy()\n",
        "\n",
        "# 시간 정렬\n",
        "if (time_col is not None) and (time_col in df_clean.columns):\n",
        "    df_clean[time_col] = pd.to_datetime(df_clean[time_col], errors=\"coerce\")\n",
        "    df_clean = df_clean.sort_values(time_col).reset_index(drop=True)\n",
        "\n",
        "# 대상만 숫자화(별도 프레임 보관)\n",
        "num_targets = df_clean[target_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# --- 음수 → NaN ---\n",
        "neg_before = int((num_targets < 0).sum().sum())\n",
        "if NEGATIVE_TO_NAN:\n",
        "    num_targets = num_targets.mask(num_targets < 0, np.nan)\n",
        "\n",
        "# --- IQR 셀-마스킹 (행 삭제 금지) ---\n",
        "cells_masked = 0\n",
        "if APPLY_IQR_FILTER:\n",
        "    Q1 = num_targets.quantile(0.25)\n",
        "    Q3 = num_targets.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - IQR_K * IQR\n",
        "    upper = Q3 + IQR_K * IQR\n",
        "\n",
        "    low_mask  = num_targets.lt(lower, axis=1)\n",
        "    high_mask = num_targets.gt(upper, axis=1)\n",
        "    outlier_mask = low_mask | high_mask\n",
        "\n",
        "    cells_masked = int(outlier_mask.sum().sum())\n",
        "    num_targets = num_targets.mask(outlier_mask, np.nan)\n",
        "\n",
        "# 대상 컬럼 적용\n",
        "df_clean[target_cols] = num_targets\n",
        "\n",
        "# --- 대상 전부 NaN 행 삭제 ---\n",
        "rows_before_drop_empty = len(df_clean)\n",
        "if DROP_EMPTY_TARGET:\n",
        "    df_clean = df_clean.dropna(subset=target_cols, how=\"all\").reset_index(drop=True)\n",
        "rows_dropped_empty = rows_before_drop_empty - len(df_clean)\n",
        "\n",
        "neg_after = int((df_clean[target_cols].apply(pd.to_numeric, errors=\"coerce\") < 0).sum().sum())\n",
        "\n",
        "# =========================\n",
        "# 요약 출력\n",
        "# =========================\n",
        "print(\"=== Cleaning Summary ===\")\n",
        "print(f\"Target columns (n={len(target_cols)}): {target_cols[:6]}{' ...' if len(target_cols)>6 else ''}\")\n",
        "print(f\"Negatives (before -> after): {neg_before} -> {neg_after}\")\n",
        "print(f\"IQR masked cells (k={IQR_K}): {cells_masked}\")\n",
        "print(f\"Empty-target dropped rows: {rows_dropped_empty}\")\n",
        "print(f\"Shape: raw {df_raw.shape} -> clean {df_clean.shape}\")\n",
        "\n",
        "# =========================\n",
        "# QA 리포트(전처리 후)\n",
        "# =========================\n",
        "qc_clean = build_qc_table(df_clean, target_cols)\n",
        "with pd.ExcelWriter(CLEAN_REPORT_PATH, engine=\"openpyxl\") as w:\n",
        "    qc_clean.to_excel(w, index=False, sheet_name=\"CLEAN_QA\")\n",
        "\n",
        "# =========================\n",
        "# 저장 + 다운로드\n",
        "# =========================\n",
        "df_clean.to_excel(CLEAN_DATA_PATH, index=False)\n",
        "df_clean.to_csv(CLEAN_DATA_CSV, index=False)\n",
        "\n",
        "files.download(CLEAN_DATA_PATH)\n",
        "files.download(CLEAN_REPORT_PATH)\n",
        "files.download(RAW_REPORT_PATH)\n",
        "\n",
        "# CSV 필요 시 활성화\n",
        "# files.download(CLEAN_DATA_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "vvj5Xt0xN3ks",
        "outputId": "09911fe8-d8f3-461e-a3ae-608a71d96d70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "엑셀 파일(.xlsx) 1개 이상 업로드하세요.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-511f7e85-bbeb-4d10-8dbf-caddbb346ba0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-511f7e85-bbeb-4d10-8dbf-caddbb346ba0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 202501_04.xlsx to 202501_04 (1).xlsx\n",
            "Uploaded (in-memory): 202501_04 (1).xlsx\n",
            "Output paths set:\n",
            " RAW_REPORT_PATH   = 202501_04_1_QA_raw.xlsx\n",
            " CLEAN_REPORT_PATH = 202501_04_1_QA_clean.xlsx\n",
            " CLEAN_DATA_PATH   = 202501_04_1_clean.xlsx\n",
            " CLEAN_DATA_CSV    = 202501_04_1_clean.csv\n",
            "Detected time_col: Pump-Begin\n",
            "Detected pm25_col: Conc(ug/m3)\n",
            "Detected metal_cols (first 10): ['Cr(ng/m3)', 'Co(ng/m3)', 'Ni(ng/m3)', 'As(ng/m3)', 'Cd(ng/m3)', 'Sb(ng/m3)', 'Pb(ng/m3)']\n",
            "Detected numeric_cols (first 10): ['Pump-Begin', 'Pump-End', 'MassResetTime', 'Conc(ug/m3)', 'Cr(ng/m3)', 'Co(ng/m3)', 'Ni(ng/m3)', 'As(ng/m3)', 'Cd(ng/m3)', 'Sb(ng/m3)']\n",
            "=== Cleaning Summary ===\n",
            "Target columns (n=8): ['Conc(ug/m3)', 'Cr(ng/m3)', 'Co(ng/m3)', 'Ni(ng/m3)', 'As(ng/m3)', 'Cd(ng/m3)'] ...\n",
            "Negatives (before -> after): 1817 -> 0\n",
            "IQR masked cells (k=3.0): 62\n",
            "Empty-target dropped rows: 1\n",
            "Shape: raw (1683, 11) -> clean (1682, 11)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_93c44c71-cc5e-4da8-8e38-c0c24d79e294\", \"202501_04_1_clean.xlsx\", 98606)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a03e461d-95ab-4019-9c97-37a8914946f4\", \"202501_04_1_QA_clean.xlsx\", 5779)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_10b9011d-5ce1-4b0e-b44e-c178ed8f77af\", \"202501_04_1_QA_raw.xlsx\", 5705)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 파일 여러개일 때 ##"
      ],
      "metadata": {
        "id": "wFK6e6RyN9B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io, os, re\n",
        "from google.colab import files\n",
        "\n",
        "pd.options.display.float_format = \"{:.6g}\".format\n",
        "\n",
        "# =========================\n",
        "# 금속 선택 옵션\n",
        "# =========================\n",
        "USE_METAL_FILTER = True  # True면 아래 목록에 있는 금속만 사용\n",
        "METAL_NAME_FILTER = [\"Cr\", \"Co\", \"Ni\", \"As\", \"Sb\", \"Pb\"]  # 원하는 금속 기호만 적기\n",
        "\n",
        "# =========================\n",
        "# 설정값\n",
        "# =========================\n",
        "CONFIRM_DETECTED_COLUMNS = True\n",
        "\n",
        "# 음수→NaN\n",
        "NEGATIVE_TO_NAN = True\n",
        "\n",
        "# IQR 셀-마스킹 적용 + 완화 기준(IQR_K=3.0)\n",
        "APPLY_IQR_FILTER = True\n",
        "IQR_K = 3.0  # Tukey 기본 1.5보다 완화 → 피크 이벤트 보존\n",
        "\n",
        "# 대상 전부 NaN인 행만 삭제\n",
        "DROP_EMPTY_TARGET = True\n",
        "\n",
        "# =========================\n",
        "# 유틸 함수들\n",
        "# =========================\n",
        "def _safe_basename(name: str) -> str:\n",
        "    base, ext = os.path.splitext(name)\n",
        "    base = re.sub(r\"[^\\w\\-]+\", \"_\", base).strip(\"_\")\n",
        "    return base, ext\n",
        "\n",
        "def normalize_colname(c: str) -> str:\n",
        "    \"\"\"\n",
        "    컬럼명 정규화:\n",
        "    - 양쪽 공백 제거\n",
        "    - 중간 공백 제거 (As (ng/m3) → As(ng/m3))\n",
        "    - ㎥를 m3로 통일 (ng/㎥ → ng/m3)\n",
        "    \"\"\"\n",
        "    c2 = str(c).strip()\n",
        "    c2 = c2.replace(\" \", \"\")\n",
        "    c2 = c2.replace(\"㎥\", \"m3\")\n",
        "    return c2\n",
        "\n",
        "# =========================\n",
        "# 파일 업로드 + 여러 파일 병합\n",
        "# =========================\n",
        "print(\"엑셀 파일(.xlsx) 1개 이상 업로드하세요.\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise RuntimeError(\"업로드된 파일이 없습니다. 다시 실행하여 업로드하세요.\")\n",
        "\n",
        "# .xlsx 파일 목록 추출\n",
        "xlsx_names = [k for k in uploaded.keys() if k.lower().endswith(\".xlsx\")]\n",
        "if not xlsx_names:\n",
        "    raise RuntimeError(\"업로드된 파일 중 .xlsx 확장자가 없습니다.\")\n",
        "\n",
        "print(f\"업로드된 .xlsx 파일 목록 ({len(xlsx_names)}개):\")\n",
        "for name in xlsx_names:\n",
        "    print(\" -\", name)\n",
        "\n",
        "# 여러 파일을 모두 읽어서 하나의 DataFrame으로 병합\n",
        "df_list = []\n",
        "for name in xlsx_names:\n",
        "    print(f\"Reading: {name}\")\n",
        "    bytes_io = io.BytesIO(uploaded[name])\n",
        "    df_tmp = pd.read_excel(bytes_io)\n",
        "    # 컬럼명 정규화 적용\n",
        "    df_tmp.columns = [normalize_colname(c) for c in df_tmp.columns]\n",
        "    df_list.append(df_tmp)\n",
        "\n",
        "# 세로 병합 (row-wise)\n",
        "df_raw = pd.concat(df_list, axis=0, ignore_index=True)\n",
        "\n",
        "# =========================\n",
        "# 불필요 컬럼 지정 삭제\n",
        "#  - 예: \"Number-of-Split\", \"Alarms\" 등\n",
        "# =========================\n",
        "DROP_COL_EXACT = [\"Number-of-split\",\"Alarms\", \"ElemError\", \"BP_Mass(ugC)\", \"BP_Conc(ugC/m3)\"] # 여기에 더 추가하면 됨\n",
        "\n",
        "# 부분 문자열로 걸러서 지우고 싶을 때 사용\n",
        "DROP_COL_CONTAINS = [\"number-of-split\",\"alarms\", \"elemerror\", \"bp_mass(ugC)\", \"bp_conc(ugC/m3)\"]\n",
        "\n",
        "cols_to_drop = []\n",
        "for c in df_raw.columns:\n",
        "    c_lower = c.lower()\n",
        "    if (c in DROP_COL_EXACT) or any(key in c_lower for key in DROP_COL_CONTAINS):\n",
        "        cols_to_drop.append(c)\n",
        "\n",
        "print(\"Dropping extra non-needed columns:\", cols_to_drop)\n",
        "df_raw = df_raw.drop(columns=cols_to_drop, errors=\"ignore\")\n",
        "\n",
        "\n",
        "# 원본 파일명 기반 산출물 경로 자동 설정\n",
        "# - 1개면 그 파일명 기준\n",
        "# - 2개 이상이면 첫 파일명 + \"_merged\"\n",
        "if len(xlsx_names) == 1:\n",
        "    base0, _ = _safe_basename(xlsx_names[0])\n",
        "    _base = base0\n",
        "else:\n",
        "    base0, _ = _safe_basename(xlsx_names[0])\n",
        "    _base = f\"{base0}_merged\"\n",
        "\n",
        "RAW_REPORT_PATH   = f\"{_base}_QA_raw.xlsx\"     # 전처리 전 QA\n",
        "CLEAN_REPORT_PATH = f\"{_base}_QA_clean.xlsx\"   # 전처리 후 QA\n",
        "CLEAN_DATA_PATH   = f\"{_base}_clean.xlsx\"      # 전처리 후 데이터(엑셀)\n",
        "CLEAN_DATA_CSV    = f\"{_base}_clean.csv\"       # 전처리 후 데이터(CSV)\n",
        "\n",
        "print(\"Output paths set:\")\n",
        "print(\" RAW_REPORT_PATH   =\", RAW_REPORT_PATH)\n",
        "print(\" CLEAN_REPORT_PATH =\", CLEAN_REPORT_PATH)\n",
        "print(\" CLEAN_DATA_PATH   =\", CLEAN_DATA_PATH)\n",
        "print(\" CLEAN_DATA_CSV    =\", CLEAN_DATA_CSV)\n",
        "\n",
        "# =========================\n",
        "# 유틸: 컬럼 자동 검출\n",
        "# =========================\n",
        "def detect_columns(df: pd.DataFrame):\n",
        "    df = df.copy()\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "\n",
        "    # 시간 후보\n",
        "    time_candidates = [\n",
        "        c for c in df.columns\n",
        "        if any(k in c.lower() for k in [\"pump-begin\", \"date\", \"datetime\", \"time\", \"측정일시\"])]\n",
        "    time_col = time_candidates[0] if len(time_candidates) > 0 else None\n",
        "\n",
        "    # PM2.5 후보\n",
        "    pm25_candidates = [\n",
        "        c for c in df.columns\n",
        "        if (\"pm2.5\" in c.lower())\n",
        "        or (\"con(ug/m3)\" in c.lower())\n",
        "        or (\"ug/m3\" in c.lower() and \"con\" in c.lower())]\n",
        "    pm25_col = pm25_candidates[0] if len(pm25_candidates) > 0 else None\n",
        "\n",
        "    # 금속 단위 패턴\n",
        "    metal_markers = [\"(ng/m3)\", \"ng/m3\", \"(ng/㎥)\", \"ng/㎥\"]\n",
        "    metal_cols = [c for c in df.columns if any(m.lower() in c.lower() for m in metal_markers)]\n",
        "\n",
        "    # 숫자형 후보(참고용)\n",
        "    numeric_cols = []\n",
        "    for c in df.columns:\n",
        "        ser = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "        if ser.notna().mean() >= 0.7:\n",
        "            numeric_cols.append(c)\n",
        "\n",
        "    return {\n",
        "        \"time_col\": time_col,\n",
        "        \"pm25_col\": pm25_col,\n",
        "        \"metal_cols\": metal_cols,\n",
        "        \"numeric_cols\": numeric_cols}\n",
        "\n",
        "# =========================\n",
        "# 로드 & 자동 검출 결과 출력\n",
        "# =========================\n",
        "detected = detect_columns(df_raw)\n",
        "time_col   = detected[\"time_col\"]\n",
        "pm25_col   = detected[\"pm25_col\"]\n",
        "metal_cols = detected[\"metal_cols\"]\n",
        "numeric_cols = detected[\"numeric_cols\"]\n",
        "\n",
        "# 전체 금속 후보를 따로 보관\n",
        "all_metal_candidates = metal_cols.copy()\n",
        "\n",
        "# 지정 금속 필터 적용\n",
        "if USE_METAL_FILTER and METAL_NAME_FILTER:\n",
        "    metal_cols = [\n",
        "        c for c in metal_cols\n",
        "        if any(c.lower().startswith(sym.lower() + \"(\") for sym in METAL_NAME_FILTER)]\n",
        "\n",
        "print(\"Detected time_col:\", time_col)\n",
        "print(\"Detected pm25_col:\", pm25_col)\n",
        "print(\"Detected metal_cols (first 10):\", metal_cols[:10])\n",
        "print(\"Detected numeric_cols (first 10):\", numeric_cols[:10])\n",
        "\n",
        "if not CONFIRM_DETECTED_COLUMNS:\n",
        "    raise RuntimeError(\"자동 검출된 컬럼 확인 후, 맞으면 CONFIRM_DETECTED_COLUMNS=True로 설정하세요.\")\n",
        "\n",
        "# =========================\n",
        "# QA 리포트 함수\n",
        "# =========================\n",
        "def summarize_series(s: pd.Series, name: str):\n",
        "    s_num = pd.to_numeric(s, errors=\"coerce\")\n",
        "    return pd.Series({\n",
        "        \"col\": name,\n",
        "        \"count_total\": int(s_num.shape[0]),\n",
        "        \"count_valid\": int(s_num.notna().sum()),\n",
        "        \"valid_pct\": float(s_num.notna().mean()),\n",
        "        \"mean\": float(s_num.mean(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"std\": float(s_num.std(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"p5\": float(s_num.quantile(0.05)) if s_num.notna().any() else np.nan,\n",
        "        \"p50\": float(s_num.quantile(0.50)) if s_num.notna().any() else np.nan,\n",
        "        \"p95\": float(s_num.quantile(0.95)) if s_num.notna().any() else np.nan,\n",
        "        \"min\": float(s_num.min(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"max\": float(s_num.max(skipna=True)) if s_num.notna().any() else np.nan})\n",
        "\n",
        "def build_qc_table(df: pd.DataFrame, targets: list):\n",
        "    rows = []\n",
        "    for c in targets:\n",
        "        if c in df.columns:\n",
        "            rows.append(summarize_series(df[c], c))\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# =========================\n",
        "# 대상 컬럼 정의\n",
        "# =========================\n",
        "target_cols = []\n",
        "if pm25_col:\n",
        "    target_cols.append(pm25_col)\n",
        "if isinstance(metal_cols, (list, tuple)):\n",
        "    target_cols += list(metal_cols)\n",
        "target_cols = [c for c in target_cols if c in df_raw.columns]\n",
        "assert len(target_cols) > 0, \"PM2.5 또는 금속 대상 컬럼을 찾지 못했습니다.\"\n",
        "\n",
        "# =========================\n",
        "# 선택 금속 + PM2.5 외 모든 금속/컬럼 제거\n",
        "# =========================\n",
        "drop_metal_cols = [c for c in all_metal_candidates if c not in target_cols]\n",
        "\n",
        "df_raw = df_raw.drop(columns=drop_metal_cols, errors=\"ignore\")\n",
        "\n",
        "print(\"Removed non-target metal columns:\", drop_metal_cols)\n",
        "\n",
        "# =========================\n",
        "# QA 리포트(전처리 전)\n",
        "# =========================\n",
        "qc_raw = build_qc_table(df_raw, target_cols)\n",
        "with pd.ExcelWriter(RAW_REPORT_PATH, engine=\"openpyxl\") as w:\n",
        "    qc_raw.to_excel(w, index=False, sheet_name=\"RAW_QA\")\n",
        "\n",
        "# =========================\n",
        "# 전처리\n",
        "# =========================\n",
        "df_clean = df_raw.copy()\n",
        "\n",
        "# 시간 정렬\n",
        "if (time_col is not None) and (time_col in df_clean.columns):\n",
        "    df_clean[time_col] = pd.to_datetime(df_clean[time_col], errors=\"coerce\")\n",
        "    df_clean = df_clean.sort_values(time_col).reset_index(drop=True)\n",
        "\n",
        "# 대상만 숫자화(별도 프레임 보관)\n",
        "num_targets = df_clean[target_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# --- 음수 → NaN ---\n",
        "neg_before = int((num_targets < 0).sum().sum())\n",
        "if NEGATIVE_TO_NAN:\n",
        "    num_targets = num_targets.mask(num_targets < 0, np.nan)\n",
        "\n",
        "# --- IQR 셀-마스킹 (행 삭제 금지) ---\n",
        "cells_masked = 0\n",
        "if APPLY_IQR_FILTER:\n",
        "    Q1 = num_targets.quantile(0.25)\n",
        "    Q3 = num_targets.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - IQR_K * IQR\n",
        "    upper = Q3 + IQR_K * IQR\n",
        "\n",
        "    low_mask  = num_targets.lt(lower, axis=1)\n",
        "    high_mask = num_targets.gt(upper, axis=1)\n",
        "    outlier_mask = low_mask | high_mask\n",
        "\n",
        "    cells_masked = int(outlier_mask.sum().sum())\n",
        "    num_targets = num_targets.mask(outlier_mask, np.nan)\n",
        "\n",
        "# 대상 컬럼 적용\n",
        "df_clean[target_cols] = num_targets\n",
        "\n",
        "# --- 대상 전부 NaN 행 삭제 ---\n",
        "rows_before_drop_empty = len(df_clean)\n",
        "if DROP_EMPTY_TARGET:\n",
        "    df_clean = df_clean.dropna(subset=target_cols, how=\"all\").reset_index(drop=True)\n",
        "rows_dropped_empty = rows_before_drop_empty - len(df_clean)\n",
        "\n",
        "neg_after = int((df_clean[target_cols].apply(pd.to_numeric, errors=\"coerce\") < 0).sum().sum())\n",
        "\n",
        "# =========================\n",
        "# 요약 출력\n",
        "# =========================\n",
        "print(\"=== Cleaning Summary ===\")\n",
        "print(f\"Target columns (n={len(target_cols)}): {target_cols[:6]}{' ...' if len(target_cols)>6 else ''}\")\n",
        "print(f\"Negatives (before -> after): {neg_before} -> {neg_after}\")\n",
        "print(f\"IQR masked cells (k={IQR_K}): {cells_masked}\")\n",
        "print(f\"Empty-target dropped rows: {rows_dropped_empty}\")\n",
        "print(f\"Shape: raw {df_raw.shape} -> clean {df_clean.shape}\")\n",
        "\n",
        "# =========================\n",
        "# QA 리포트(전처리 후)\n",
        "# =========================\n",
        "qc_clean = build_qc_table(df_clean, target_cols)\n",
        "with pd.ExcelWriter(CLEAN_REPORT_PATH, engine=\"openpyxl\") as w:\n",
        "    qc_clean.to_excel(w, index=False, sheet_name=\"CLEAN_QA\")\n",
        "\n",
        "# =========================\n",
        "# 저장 + 다운로드\n",
        "# =========================\n",
        "df_clean.to_excel(CLEAN_DATA_PATH, index=False)\n",
        "df_clean.to_csv(CLEAN_DATA_CSV, index=False)\n",
        "\n",
        "files.download(CLEAN_DATA_PATH)\n",
        "files.download(CLEAN_REPORT_PATH)\n",
        "files.download(RAW_REPORT_PATH)\n",
        "\n",
        "# CSV 필요 시 활성화\n",
        "# files.download(CLEAN_DATA_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "Z1Axnq-sXKJD",
        "outputId": "df552e5a-2ab6-46da-c54e-b04934328506"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "엑셀 파일(.xlsx) 1개 이상 업로드하세요.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-86d0605b-9617-478e-ba8e-39577e32c7b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-86d0605b-9617-478e-ba8e-39577e32c7b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 202501.xlsx to 202501 (4).xlsx\n",
            "Saving 202502.xlsx to 202502 (4).xlsx\n",
            "Saving 202503.xlsx to 202503 (4).xlsx\n",
            "Saving 202504.xlsx to 202504 (4).xlsx\n",
            "업로드된 .xlsx 파일 목록 (4개):\n",
            " - 202501 (4).xlsx\n",
            " - 202502 (4).xlsx\n",
            " - 202503 (4).xlsx\n",
            " - 202504 (4).xlsx\n",
            "Reading: 202501 (4).xlsx\n",
            "Reading: 202502 (4).xlsx\n",
            "Reading: 202503 (4).xlsx\n",
            "Reading: 202504 (4).xlsx\n",
            "Dropping extra non-needed columns: ['Number-of-Split', 'Alarms']\n",
            "Output paths set:\n",
            " RAW_REPORT_PATH   = 202501_4_merged_QA_raw.xlsx\n",
            " CLEAN_REPORT_PATH = 202501_4_merged_QA_clean.xlsx\n",
            " CLEAN_DATA_PATH   = 202501_4_merged_clean.xlsx\n",
            " CLEAN_DATA_CSV    = 202501_4_merged_clean.csv\n",
            "Detected time_col: Pump-Begin\n",
            "Detected pm25_col: Conc(ug/m3)\n",
            "Detected metal_cols (first 10): ['Cr(ng/m3)', 'Co(ng/m3)', 'Ni(ng/m3)', 'As(ng/m3)', 'Sb(ng/m3)', 'Pb(ng/m3)']\n",
            "Detected numeric_cols (first 10): ['Pump-Begin', 'Pump-End', 'MassResetTime', 'Analysis-Id', 'Mass(ug)', 'Conc(ug/m3)', 'Al(ng/m3)', 'Si(ng/m3)', 'S(ng/m3)', 'K(ng/m3)']\n",
            "Removed non-target metal columns: ['Al(ng/m3)', 'Si(ng/m3)', 'S(ng/m3)', 'K(ng/m3)', 'Ca(ng/m3)', 'Ti(ng/m3)', 'V(ng/m3)', 'Mn(ng/m3)', 'Fe(ng/m3)', 'Cu(ng/m3)', 'Zn(ng/m3)', 'Ga(ng/m3)', 'Ge(ng/m3)', 'Se(ng/m3)', 'Br(ng/m3)', 'Rb(ng/m3)', 'Sr(ng/m3)', 'Y(ng/m3)', 'Zr(ng/m3)', 'Pd(ng/m3)', 'Ag(ng/m3)', 'Cd(ng/m3)', 'In(ng/m3)', 'Sn(ng/m3)', 'Te(ng/m3)', 'Cs(ng/m3)', 'Ba(ng/m3)', 'Ce(ng/m3)', 'Bi(ng/m3)']\n",
            "=== Cleaning Summary ===\n",
            "Target columns (n=7): ['Conc(ug/m3)', 'Cr(ng/m3)', 'Co(ng/m3)', 'Ni(ng/m3)', 'As(ng/m3)', 'Sb(ng/m3)'] ...\n",
            "Negatives (before -> after): 1817 -> 0\n",
            "IQR masked cells (k=3.0): 67\n",
            "Empty-target dropped rows: 1\n",
            "Shape: raw (1683, 15) -> clean (1682, 15)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb10d68b-6bd5-40d7-8adf-05110808d065\", \"202501_4_merged_clean.xlsx\", 119663)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8e8623f7-35ef-4065-af82-7d794a374e4b\", \"202501_4_merged_QA_clean.xlsx\", 5677)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_42bb24d9-24c1-4620-a458-ee28df00a60d\", \"202501_4_merged_QA_raw.xlsx\", 5621)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 산점도 그래프 생성 ##"
      ],
      "metadata": {
        "id": "t8Od7hQkeFQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import pearsonr\n",
        "from google.colab import files\n",
        "\n",
        "# ===== 파일 업로드 =====\n",
        "uploaded = files.upload()\n",
        "fname = next(iter(uploaded.keys()))\n",
        "df = pd.read_excel(fname)\n",
        "\n",
        "# ===== 분석 대상 컬럼 추출 =====\n",
        "unit_patterns = ['(ng/m3)', '(ug/m3)', '(µg/m³)', '(μg/m3)']\n",
        "columns_to_analyze = [c for c in df.columns if any(p in str(c) for p in unit_patterns)]\n",
        "\n",
        "# X축 후보\n",
        "x_candidates = ['Conc(ug/m3)', 'PM2.5(ug/m3)', 'PM2.5 (ug/m3)', 'Con(ug/m3)']\n",
        "xcol = next((c for c in x_candidates if c in df.columns), None)\n",
        "if xcol is None:\n",
        "    raise ValueError(\"X-axis column not found. Check the actual column name for PM2.5 mass.\")\n",
        "\n",
        "# Y축 후보\n",
        "ycols = [c for c in columns_to_analyze if c != xcol]\n",
        "if len(ycols) == 0:\n",
        "    raise ValueError(\"No Y columns to plot. Check filter logic.\")\n",
        "\n",
        "# ===== 데이터 클린 함수 =====\n",
        "def clean_series(s: pd.Series) -> pd.Series:\n",
        "    s_num = pd.to_numeric(s, errors='coerce')\n",
        "    return s_num.mask(s_num < 0)\n",
        "\n",
        "# ===== 전역 스타일 =====\n",
        "TITLE_FT = 18   # subplot 제목\n",
        "LABEL_FT = 16   # 축 라벨\n",
        "TICK_FT  = 16   # 축 숫자\n",
        "ANN_FT   = 12   # 주석 폰트\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"axes.titlesize\": TITLE_FT,\n",
        "    \"axes.titleweight\": \"bold\",\n",
        "    \"axes.labelsize\": LABEL_FT,\n",
        "    \"axes.labelweight\": \"bold\",\n",
        "    \"xtick.labelsize\": TICK_FT,\n",
        "    \"ytick.labelsize\": TICK_FT\n",
        "})\n",
        "\n",
        "# ===== 산점도 + 회귀 함수 =====\n",
        "def plot_scatter_with_regression(x: str, y: str, data: pd.DataFrame, ax):\n",
        "    title = f\"{y}\"\n",
        "    x_ser = clean_series(data[x])\n",
        "    y_ser = clean_series(data[y])\n",
        "    df_xy = pd.concat([x_ser.rename(x), y_ser.rename(y)], axis=1).dropna()\n",
        "\n",
        "    # 예외 처리\n",
        "    if len(df_xy) < 3 or df_xy[x].std() == 0 or df_xy[y].std() == 0:\n",
        "        sns.scatterplot(data=df_xy, x=x, y=y, ax=ax, s=30, alpha=0.8, edgecolor=None)\n",
        "        ax.set_xlabel(x, fontweight='bold'); ax.set_ylabel(y, fontweight='bold')\n",
        "        ax.set_title(title, fontweight='bold')\n",
        "        # 축 숫자 크기/볼드\n",
        "        ax.tick_params(axis='both', which='both', labelsize=TICK_FT)\n",
        "        for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "            label.set_fontsize(TICK_FT)\n",
        "            label.set_fontweight('bold')\n",
        "        return None\n",
        "\n",
        "    # 산점도\n",
        "    sns.scatterplot(data=df_xy, x=x, y=y, ax=ax, s=30, alpha=0.8, edgecolor=None)\n",
        "\n",
        "    # 선형 회귀\n",
        "    X_vals = df_xy[[x]].to_numpy()\n",
        "    y_vals = df_xy[y].to_numpy()\n",
        "    model = LinearRegression().fit(X_vals, y_vals)\n",
        "    y_pred = model.predict(X_vals)\n",
        "    r2 = float(model.score(X_vals, y_vals))\n",
        "    slope = float(model.coef_[0])\n",
        "    r, p = pearsonr(df_xy[x].to_numpy(), df_xy[y].to_numpy())\n",
        "\n",
        "    # 회귀선\n",
        "    order = np.argsort(X_vals.ravel())\n",
        "    ax.plot(X_vals.ravel()[order], y_pred[order], linewidth=2.5, color='C1')\n",
        "\n",
        "    # 라벨/제목\n",
        "    ax.set_xlabel(x, fontsize=LABEL_FT, fontweight='bold')\n",
        "    ax.set_ylabel(y, fontsize=LABEL_FT, fontweight='bold')\n",
        "    ax.set_title(title, fontsize=TITLE_FT, fontweight='bold')\n",
        "\n",
        "    # 축 숫자 크기/볼드\n",
        "    ax.tick_params(axis='both', which='both', labelsize=TICK_FT)\n",
        "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "        label.set_fontsize(TICK_FT)\n",
        "        label.set_fontweight('bold')\n",
        "\n",
        "    # 라벨/제목\n",
        "    ax.set_xlabel(x, fontsize=LABEL_FT, fontweight='bold')\n",
        "    ax.set_ylabel(y, fontsize=LABEL_FT, fontweight='bold')\n",
        "    ax.set_title(title, fontsize=TITLE_FT, fontweight='bold')\n",
        "\n",
        "    # 축 숫자 크기/볼드\n",
        "    ax.tick_params(axis='both', which='both', labelsize=TICK_FT)\n",
        "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "        label.set_fontsize(TICK_FT)\n",
        "        label.set_fontweight('bold')\n",
        "\n",
        "    # 주석 박스\n",
        "    note = (f\"R²={r2:.3f}\\nr={r:.3f}\\np={p:.3g}\\n\"\n",
        "            f\"slope={slope:.3f}\")\n",
        "    ax.text(0.98, 0.98, note, transform=ax.transAxes,\n",
        "            ha='right', va='top',\n",
        "            fontsize=ANN_FT, fontweight='bold',\n",
        "            bbox=dict(facecolor='white', edgecolor='0.5',\n",
        "                      boxstyle='round,pad=0.3', alpha=0.6))\n",
        "\n",
        "# ===== 서브플롯 배치 =====\n",
        "n = len(ycols)\n",
        "ncols = 4\n",
        "nrows = math.ceil(n / ncols)\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(6.2*ncols, 5.2*nrows))\n",
        "axes = np.atleast_1d(axes).ravel()\n",
        "\n",
        "# 여백 조정\n",
        "fig.subplots_adjust(right=0.96, wspace=0.40, hspace=0.55)\n",
        "\n",
        "# 플롯 생성\n",
        "for i, metal in enumerate(ycols):\n",
        "    plot_scatter_with_regression(xcol, metal, df, axes[i])\n",
        "\n",
        "# 남는 축 숨김\n",
        "for j in range(i + 1, len(axes)):\n",
        "    axes[j].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RPJbdpDYeLzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pearson 상관관계 분석 + 상관관계 분석표 생성 ##"
      ],
      "metadata": {
        "id": "87-Q74LNeNwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 업로드 & 로드 ---\n",
        "uploaded = files.upload()\n",
        "fname = next(iter(uploaded.keys()))\n",
        "df = pd.read_excel(fname)\n",
        "\n",
        "# 1) 중복 열 제거(첫 번째만 유지)\n",
        "if df.columns.duplicated().any():\n",
        "    dup_names = df.columns[df.columns.duplicated()].unique().tolist()\n",
        "    print(f\"[warn] duplicated columns dropped (keeping first): {dup_names}\")\n",
        "    df = df.loc[:, ~df.columns.duplicated()].copy()\n",
        "\n",
        "# 2) 대상 열 선택: (ng|ug|µg|μg)/(m3|m³|㎥) 단위 포함\n",
        "unit_pat = re.compile(r\"µ³㎥\", flags=re.I)\n",
        "target_cols = [c for c in df.columns if unit_pat.search(str(c))]\n",
        "target_cols = pd.Index(target_cols).drop_duplicates().tolist()\n",
        "if not target_cols:\n",
        "    raise ValueError(\"단위 패턴에 맞는 열이 없습니다. 열명/단위를 확인하세요.\")\n",
        "\n",
        "# 3) 숫자화 (전처리 데이터 신뢰: 추가 마스킹/클리닝 금지)\n",
        "df_num = df.loc[:, target_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# 4) 상관계수/유의확률/표본수 테이블\n",
        "rmat = pd.DataFrame(index=target_cols, columns=target_cols, dtype=float)\n",
        "pmat = pd.DataFrame(index=target_cols, columns=target_cols, dtype=float)\n",
        "nmat = pd.DataFrame(index=target_cols, columns=target_cols, dtype=int)\n",
        "\n",
        "for i, c1 in enumerate(target_cols):\n",
        "    s1 = df_num[c1]\n",
        "    for j, c2 in enumerate(target_cols):\n",
        "        if j > i:\n",
        "            continue  # 하삼각만 채움\n",
        "        if i == j:\n",
        "            rmat.iat[i, j] = 1.0\n",
        "            pmat.iat[i, j] = 0.0\n",
        "            nmat.iat[i, j] = s1.notna().sum()\n",
        "            continue\n",
        "\n",
        "        pair = pd.concat([s1, df_num[c2]], axis=1).dropna()\n",
        "        n = len(pair)\n",
        "        nmat.iat[i, j] = n\n",
        "\n",
        "        if n < 3 or pair.iloc[:, 0].nunique() < 2 or pair.iloc[:, 1].nunique() < 2:\n",
        "            rmat.iat[i, j] = np.nan\n",
        "            pmat.iat[i, j] = np.nan\n",
        "            continue\n",
        "\n",
        "        r, p = pearsonr(pair.iloc[:, 0].values, pair.iloc[:, 1].values)\n",
        "        rmat.iat[i, j] = r\n",
        "        pmat.iat[i, j] = p\n",
        "\n",
        "# 하삼각만 채운 행렬을 대칭 보정(표/히트맵에서 NaN처럼 보이는 문제 방지)\n",
        "rmat = rmat.combine_first(rmat.T)\n",
        "pmat = pmat.combine_first(pmat.T)\n",
        "nmat = nmat.combine_first(nmat.T)\n",
        "\n",
        "# 5) 포맷/라운드\n",
        "DECIMALS = 3\n",
        "rmat_round = rmat.round(DECIMALS)\n",
        "pmat_round = pmat.round(DECIMALS)\n",
        "\n",
        "def stars(p):\n",
        "    if pd.isna(p): return \"\"\n",
        "    return \"**\" if p < 0.01 else (\"*\" if p < 0.05 else \"\")\n",
        "\n",
        "out_fmt = pd.DataFrame(\"\", index=rmat.index, columns=rmat.columns, dtype=object)\n",
        "for i in range(len(rmat.index)):\n",
        "    for j in range(len(rmat.columns)):\n",
        "        if j > i:                      # 상삼각은 비움\n",
        "            out_fmt.iat[i, j] = \"\"\n",
        "        elif i == j:                   # 대각선은 1\n",
        "            out_fmt.iat[i, j] = \"1\"\n",
        "        else:                          # 하삼각만 값/별표 표시\n",
        "            rij = rmat.iat[i, j]\n",
        "            pij = pmat.iat[i, j]\n",
        "            out_fmt.iat[i, j] = \"NaN\" if pd.isna(rij) else f\"{rij:.{DECIMALS}f}{stars(pij)}\"\n",
        "\n",
        "# (선택) p값 0.000을 \"<0.001\"로 표시하고 싶으면:\n",
        "pmat_disp = pmat.map(lambda x: \"<0.001\" if pd.notna(x) and x < 0.001 else (f\"{x:.3f}\" if pd.notna(x) else \"NaN\"))\n",
        "\n",
        "# 6) 결과 확인/표시\n",
        "try:\n",
        "    from google.colab import data_table\n",
        "    data_table.enable_dataframe_formatter()\n",
        "except Exception as e:\n",
        "    print(\"[info] data_table 사용 불가:\", e)\n",
        "\n",
        "print(\"▶ 상관관계 분석표 (*: p<0.05, **: p<0.01)\")\n",
        "display(out_fmt)\n",
        "\n",
        "print(\"▶ 상관계수 행렬(r)\")\n",
        "display(rmat_round)\n",
        "\n",
        "print(\"▶ p값 행렬(p)\")\n",
        "display(pmat_round)  # 또는 display(pmat_disp)\n",
        "\n",
        "print(\"▶ 쌍별 표본수(N)\")\n",
        "display(nmat)\n",
        "\n",
        "# 7) 납작화 요약 / 유의쌍\n",
        "def melt_lower(rmat: pd.DataFrame, pmat: pd.DataFrame, nmat: pd.DataFrame) -> pd.DataFrame:\n",
        "    cols = rmat.columns.tolist()\n",
        "    recs = []\n",
        "    for i in range(len(cols)):\n",
        "        for j in range(i):\n",
        "            r = rmat.iat[i, j]; p = pmat.iat[i, j]; n = nmat.iat[i, j]\n",
        "            recs.append({\n",
        "                \"var1\": cols[i], \"var2\": cols[j],\n",
        "                \"r\": r, \"p\": p, \"n\": int(n) if pd.notna(n) else np.nan,\n",
        "                \"abs_r\": abs(r) if pd.notna(r) else np.nan})\n",
        "    return pd.DataFrame(recs)\n",
        "\n",
        "pairs = melt_lower(rmat, pmat, nmat)\n",
        "\n",
        "ALPHA = 0.05\n",
        "MIN_N = 30\n",
        "sig_pairs = pairs[(pairs[\"p\"] < ALPHA) & (pairs[\"n\"] >= MIN_N)].sort_values(\"abs_r\", ascending=False)\n",
        "\n",
        "pairs_round = pairs.copy()\n",
        "for c in [\"r\", \"p\", \"abs_r\"]:\n",
        "    if c in pairs_round.columns:\n",
        "        pairs_round[c] = pairs_round[c].round(DECIMALS)\n",
        "\n",
        "sig_pairs_round = sig_pairs.copy()\n",
        "for c in [\"r\", \"p\", \"abs_r\"]:\n",
        "    if c in sig_pairs_round.columns:\n",
        "        sig_pairs_round[c] = sig_pairs_round[c].round(DECIMALS)\n",
        "\n",
        "print(f\"▶ 유의(p<{ALPHA}) & 표본수≥{MIN_N} 상위 20쌍\")\n",
        "display(sig_pairs_round.head(20))\n",
        "\n",
        "# 8) 히트맵\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "im = ax.imshow(rmat_round.values, aspect='auto', cmap='coolwarm', vmin=-1, vmax=1)\n",
        "ax.set_title(\"PM2.5-Metals Correlation Matrix (Pearson)\", fontsize=18, fontweight='bold')\n",
        "ax.set_xticks(range(len(target_cols))); ax.set_yticks(range(len(target_cols)))\n",
        "ax.set_xticklabels(target_cols, rotation=90); ax.set_yticklabels(target_cols)\n",
        "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# 9) 저장\n",
        "with pd.ExcelWriter(\"상관관계분석표.xlsx\") as w:\n",
        "    out_fmt.to_excel(w, sheet_name=\"pearson_r_fmt\")\n",
        "    rmat.to_excel(w, sheet_name=\"pearson_r_raw\")\n",
        "    pmat.to_excel(w, sheet_name=\"p_values\")\n",
        "    nmat.to_excel(w, sheet_name=\"pair_N\")\n",
        "\n",
        "with pd.ExcelWriter(\"상관분석_요약.xlsx\") as w:\n",
        "    pairs.to_excel(w, index=False, sheet_name=\"all_pairs\")\n",
        "    sig_pairs.to_excel(w, index=False, sheet_name=f\"sig_pairs_p<{ALPHA}_N>={MIN_N}\")\n",
        "\n",
        "# 다운로드 (필요시 활성화)\n",
        "#files.download(\"상관관계분석표.xlsx\")\n",
        "#files.download(\"상관분석_요약.xlsx\")"
      ],
      "metadata": {
        "id": "Y45zqQ0Hejnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Single) 금속별 농도 예측 & 검증 ##"
      ],
      "metadata": {
        "id": "Ou-G2ULQezj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "## 통합 파이프라인\n",
        "# ============================================================\n",
        "\n",
        "# ---------- Imports ----------\n",
        "from google.colab import files\n",
        "import os, re, json, math, warnings, glob\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import kstest\n",
        "from scipy.stats import (\n",
        "    gumbel_r, gumbel_l, lognorm, weibull_min, logistic,\n",
        "    norm, gamma, beta, triang, expon, pareto, uniform, chi2)\n",
        "from scipy.stats import t as student_t\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
        "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "# === 전역 폰트 기본값(크기/굵기) 지정 ===\n",
        "plt.rcParams.update({\n",
        "    \"font.size\": 11,             # 기본 폰트\n",
        "    \"axes.titlesize\": 14,        # 축 제목(각 패널) 크기\n",
        "    \"axes.titleweight\": \"bold\",  # 축 제목 굵기\n",
        "    \"axes.labelsize\": 12,        # x/y 라벨 크기\n",
        "    \"axes.labelweight\": \"bold\",  # x/y 라벨 굵기\n",
        "    \"legend.fontsize\": 11        # 범례 크기\n",
        "})\n",
        "\n",
        "# ---------- 사용자 설정 ----------\n",
        "np.random.seed(20250912)\n",
        "N_SIM       = 10_000\n",
        "BOOTSTRAP_B = 200\n",
        "SAVE_DIR    = \"outputs\"\n",
        "EXCLUDE_METALS = [\"Cr\", \"Cd\"] # 제외금속  ← 문자열로 표기\n",
        "\n",
        "# ---------- 고정 상수 ----------\n",
        "IUR = {\"Cr(VI)\":1.20e-02,\"Co\":9.00e-03,\"Ni\":2.40e-04,\"As\":4.30e-03,\"Cd\":1.80e-03,\"Sb\":2.29e-06,\"Pb\":1.20e-05}\n",
        "ORDER = ['Cr','Cr(VI)','Co','Ni','As','Cd','Sb','Pb']\n",
        "\n",
        "# 제외 설정\n",
        "EXCLUDE_SET  = set(m.strip() for m in EXCLUDE_METALS)\n",
        "ACTIVE_ORDER = [m for m in ORDER if m not in EXCLUDE_SET]\n",
        "\n",
        "ENG_NAME = {\n",
        "    '로그 정규':'Lognormal', '와이블':'Weibull', '감마':'Gamma', '지수':'Exponential',\n",
        "    '최대 극값':'Gumbel Max', '최소 극값':'Gumbel Min', '정규':'Normal', '로지스틱':'Logistic',\n",
        "    \"스튜던트의 t\":\"Student's t\", '베타':'Beta', 'BetaPERT':'BetaPERT',\n",
        "    '삼각형':'Triangular', '균일':'Uniform', '파레토':'Pareto'}\n",
        "\n",
        "# ===== 분포별 라인 색상 팔레트 =====\n",
        "DIST_COLOR = {\n",
        "    'Lognormal': 'tab:orange',\n",
        "    'Weibull': 'tab:green',\n",
        "    'Gamma': 'tab:purple',\n",
        "    'Exponential': 'tab:red',\n",
        "    'Gumbel Max': 'tab:olive',\n",
        "    'Gumbel Min': 'tab:cyan',\n",
        "    'Normal': 'tab:blue',\n",
        "    'Logistic': 'tab:pink',\n",
        "    \"Student's t\": 'tab:brown',\n",
        "    'Beta': 'tab:gray',\n",
        "    'BetaPERT': 'tab:purple',\n",
        "    'Triangular': 'tab:teal',\n",
        "    'Uniform': 'tab:cyan',\n",
        "    'Pareto': 'tab:red'}\n",
        "\n",
        "# --- 패턴 ---\n",
        "PAT = {\n",
        "    \"Cr(VI)\": r\"(?:\\bCr\\s*VI\\b|\\bCr[-\\s]*VI\\b|\\bCr\\s*6\\+\\b|Cr[-\\s]*6\\+|Hexa(?:valent)?\\s*Chrom(?:ium)?|6가\\s*크롬|육가\\s*크롬|육가크롬)\",\n",
        "    \"Cr\"    : r\"(?:\\bCr\\b(?!\\s*(?:VI|6\\+))|Chromium|크롬)\",\n",
        "    \"Co\"    : r\"(?:\\bCo\\b|\\bC\\s*o\\b|Cobalt|코발트)\",\n",
        "    \"Ni\"    : r\"(?:\\bNi\\b|\\bN\\s*i\\b|Nickel|니켈)\",\n",
        "    \"As\"    : r\"(?:\\bA\\s*s\\b|\\bAs\\b(?=[\\s\\(\\[]|$)|Arsenic|비소)\",\n",
        "    \"Cd\"    : r\"(?:\\bCd\\b|\\bC\\s*d\\b|Cadmium|카드뮴)\",\n",
        "    \"Sb\"    : r\"(?:\\bS[bB]\\b|\\bS\\s*B\\b|Stibium|Antimon(?:y)?|안티몬)\",\n",
        "    \"Pb\"    : r\"(?:\\bPb\\b|\\bP\\s*b\\b|Lead|납)\"}\n",
        "\n",
        "# Excel 스타일\n",
        "HEADER_BLUE = '2F5597'; BEST_FILL='FFF2CC'; THIN_GRAY='999999'; TABLE_STYLE=\"TableStyleMedium9\"\n",
        "\n",
        "# 노출 파라미터\n",
        "EF_days_per_year = 350; EF = EF_days_per_year/365.0\n",
        "LT_years = 78.6\n",
        "ACT_POINT = {\"0-<1\":24,\"1-<2\":84,\"2-<3\":120,\"3-<6\":108,\"6-<11\":132,\"11-<16\":102,\"16-<18\":102}\n",
        "ACT_LN_P5_P95 = {\"18-<25\":(14.455,250.0),\"25-<35\":(6.516,220.0),\"35-<45\":(5.789,195.0),\n",
        "                 \"45-<55\":(6.401,260.0),\"55-<65\":(8.083,350.0),\"65-<78.6\":(6.094,390.0)}\n",
        "ED_years = {\"0-<1\":1,\"1-<2\":1,\"2-<3\":1,\"3-<6\":3,\"6-<11\":5,\"11-<16\":5,\"16-<18\":2,\n",
        "            \"18-<25\":7,\"25-<35\":10,\"35-<45\":10,\"45-<55\":10,\"55-<65\":10,\"65-<78.6\":13.6}\n",
        "AGE_ORDER=[\"0-<1\",\"1-<2\",\"2-<3\",\"3-<6\",\"6-<11\",\"11-<16\",\"16-<18\",\"18-<25\",\"25-<35\",\"35-<45\",\"45-<55\",\"55-<65\",\"65-<78.6\"]\n",
        "INFANT = [\"0-<1\",\"1-<2\"]; CHILD=[\"2-<3\",\"3-<6\",\"6-<11\",\"11-<16\",\"16-<18\"]; ADULT=[\"18-<25\",\"25-<35\",\"35-<45\",\"45-<55\",\"55-<65\",\"65-<78.6\"]\n",
        "\n",
        "# RNG helpers\n",
        "_master_rs = np.random.RandomState(20250912)\n",
        "def child_rs(): return np.random.RandomState(_master_rs.randint(0, 2**31-1))\n",
        "_mdl_rs = child_rs()  # ND/MDL 치환용 난수원\n",
        "\n",
        "# ============================================================\n",
        "# 유틸\n",
        "# ============================================================\n",
        "def freedman_diaconis_bins(x, min_bins=30, max_bins=70):\n",
        "    x = np.asarray(x, float); x = x[np.isfinite(x)]\n",
        "    n = x.size\n",
        "    if n < 2: return max(2, min_bins)\n",
        "    q75, q25 = np.percentile(x, [75, 25]); iqr = q75 - q25\n",
        "    if iqr <= 0: return max(min_bins, min(max_bins, int(np.sqrt(n))))\n",
        "    h = 2 * iqr * (n ** (-1/3))\n",
        "    if h <= 0: return max(min_bins, min(max_bins, int(np.sqrt(n))))\n",
        "    bins = int(np.ceil((x.max() - x.min()) / h))\n",
        "    return max(2, max(min_bins, min(max_bins, bins)))\n",
        "\n",
        "# --- ND/<MDL> 수치화 ---\n",
        "MDL_POLICY = \"uniform\"  # \"half\" | \"nan\" | \"uniform\"\n",
        "def coerce_numeric_with_mdl(s):\n",
        "    s = pd.Series(s).astype(str).str.strip().str.replace(',', '', regex=False)\n",
        "\n",
        "    # <a or ≤a → half*a / NaN / Uniform(0,a)\n",
        "    m = s.str.match(r'^[<≤]\\s*([0-9]*\\.?[0-9]+)$')\n",
        "    if m.any():\n",
        "        vals = s[m].str.replace('≤','<',regex=False).str.replace('<','',regex=False).astype(float).values\n",
        "        if MDL_POLICY == 'half':\n",
        "            s.loc[m] = (vals/2.0)\n",
        "        elif MDL_POLICY == 'nan':\n",
        "            s.loc[m] = np.nan\n",
        "        elif MDL_POLICY == 'uniform':\n",
        "            # Uniform(0, a) 샘플\n",
        "            u = _mdl_rs.uniform(0.0, 1.0, size=len(vals))\n",
        "            s.loc[m] = vals * u\n",
        "        else:\n",
        "            s.loc[m] = (vals/2.0)\n",
        "\n",
        "    # common tokens → NaN\n",
        "    s = s.replace({'ND':np.nan,'N.D.':np.nan,'MDL':np.nan,'BDL':np.nan,'-':np.nan,'--':np.nan,'':np.nan}, regex=False)\n",
        "    return pd.to_numeric(s, errors='coerce')\n",
        "\n",
        "def hist_mode_estimate(x):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "    if x.size<2: return float(np.nanmedian(x)) if x.size else np.nan\n",
        "    iqr=np.subtract(*np.percentile(x,[75,25]))\n",
        "    bins=max(10,int(np.sqrt(x.size))) if iqr<=0 else max(10,int(np.ceil((x.max()-x.min())/(2*iqr*x.size**(-1/3)))) )\n",
        "    cnt,edges=np.histogram(x,bins=bins); i=int(cnt.argmax())\n",
        "    return float((edges[i]+edges[i+1])/2)\n",
        "\n",
        "def apply_pretty_xticks(ax, min_ticks=4, max_ticks=7):\n",
        "    x_lo, x_hi = ax.get_xlim()\n",
        "    if not np.isfinite(x_lo) or not np.isfinite(x_hi):\n",
        "        return\n",
        "    if x_hi <= x_lo:\n",
        "        return\n",
        "\n",
        "    x_range = x_hi - x_lo\n",
        "\n",
        "    # 1) 가능한 step 후보 생성 (1,2,2.5,5 × 10^k)\n",
        "    base = np.array([1.0, 2.0, 2.5, 5.0])\n",
        "    steps = []\n",
        "    for k in range(-6, 2):   # 10^-6 ~ 10^1 정도까지면 충분\n",
        "        steps.extend(base * (10.0 ** k))\n",
        "    steps = np.array(sorted(steps))\n",
        "\n",
        "    # 2) 현재 범위에 맞는 step 선택\n",
        "    best_step = None\n",
        "    best_diff = None\n",
        "\n",
        "    for step in steps:\n",
        "        if step <= 0:\n",
        "            continue\n",
        "        start = np.ceil(x_lo / step) * step\n",
        "        end   = np.floor(x_hi / step) * step\n",
        "        if end < start:\n",
        "            continue\n",
        "\n",
        "        n_ticks = int(np.floor((end - start) / step)) + 1\n",
        "\n",
        "        # min~max 사이면 바로 채택\n",
        "        if min_ticks <= n_ticks <= max_ticks:\n",
        "            best_step = step\n",
        "            break\n",
        "\n",
        "        # 아니면, 차이가 가장 적은 후보를 기억\n",
        "        if n_ticks < min_ticks:\n",
        "            diff = min_ticks - n_ticks\n",
        "        else:\n",
        "            diff = n_ticks - max_ticks\n",
        "\n",
        "        if best_diff is None or diff < best_diff:\n",
        "            best_diff = diff\n",
        "            best_step = step\n",
        "\n",
        "    if best_step is None:\n",
        "        return\n",
        "\n",
        "    step = best_step\n",
        "\n",
        "    # 3) 실제 tick 계산\n",
        "    start = np.ceil(x_lo / step) * step\n",
        "    end   = np.floor(x_hi / step) * step\n",
        "    if end < start:\n",
        "        return\n",
        "\n",
        "    ticks = np.arange(start, end + step*0.5, step)\n",
        "    ticks[np.isclose(ticks, 0.0, atol=step*0.01)] = 0.0  # -0 보정\n",
        "\n",
        "    ax.set_xticks(ticks)\n",
        "\n",
        "    # 4) 라벨 포맷 (과학표기 제거)\n",
        "    def _smart_fmt(v, pos):\n",
        "        s = f\"{v:.6f}\".rstrip('0').rstrip('.')\n",
        "        return \"0\" if s in (\"\", \"-0\") else s\n",
        "\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(_smart_fmt))\n",
        "    ax.grid(True, alpha=0.25)\n",
        "\n",
        "# ============================================================\n",
        "# 1) 파일 업로드 & 시트 자동 선택\n",
        "# ============================================================\n",
        "print(\"엑셀 파일 업로드(.xlsx/.xls)\")\n",
        "up = files.upload()\n",
        "INPUT = next((k for k in up if k.lower().endswith(('.xlsx','.xls'))), None)\n",
        "if INPUT is None:\n",
        "    cand = sorted(glob.glob(\"*.xlsx\"))\n",
        "    if not cand: raise FileNotFoundError(\"엑셀 파일을 찾지 못했습니다.\")\n",
        "    INPUT = cand[-1]\n",
        "\n",
        "xls = pd.ExcelFile(INPUT)\n",
        "sheet_scores=[]\n",
        "for sh in xls.sheet_names:\n",
        "    try:\n",
        "        df_head = pd.read_excel(INPUT, sheet_name=sh, nrows=3)\n",
        "    except Exception:\n",
        "        df_head = pd.DataFrame()\n",
        "    score=0\n",
        "    for c in df_head.columns:\n",
        "        s=str(c)\n",
        "        score += sum(bool(re.search(p, s, flags=re.I)) for p in PAT.values())\n",
        "    sheet_scores.append((sh,score))\n",
        "sheet_scores.sort(key=lambda x:x[1], reverse=True)\n",
        "SHEET = sheet_scores[0][0]\n",
        "raw = pd.read_excel(INPUT, sheet_name=SHEET)\n",
        "print(f\"선택된 시트: {SHEET}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2) 단위 통일 & 열 자동 매칭 (+ Cr(VI) 파생)\n",
        "# ============================================================\n",
        "def find_col(df, regex):\n",
        "    for c in df.columns:\n",
        "        if re.search(regex, str(c), flags=re.I): return c\n",
        "    return None\n",
        "\n",
        "def to_ug(series, name):\n",
        "    header = str(name)\n",
        "    s = coerce_numeric_with_mdl(series).replace([np.inf, -np.inf], np.nan)\n",
        "    has_ug = bool(re.search(r'(?i)[µμu]\\s*g\\s*/?\\s*m\\^?3', header))\n",
        "    has_ng = bool(re.search(r'(?i)n\\s*g\\s*/?\\s*m\\^?3', header))\n",
        "    if has_ug: return (s, 'as_is_ug')\n",
        "    if has_ng: return (s/1000.0, 'converted_from_ng')\n",
        "    return (s, 'as_is_ug')\n",
        "\n",
        "series_map, log_rows = {}, []\n",
        "for m in ORDER:\n",
        "    if m in EXCLUDE_SET:\n",
        "        log_rows.append((m, None, 'excluded_by_user', 0, np.nan))\n",
        "        continue\n",
        "    c = find_col(raw, PAT.get(m, r\"^\"))\n",
        "    if c is None:\n",
        "        log_rows.append((m, None, 'missing', 0, np.nan)); continue\n",
        "    v, how = to_ug(raw[c], c); series_map[m]=v\n",
        "    n_nonna = int(pd.to_numeric(v, errors='coerce').notna().sum())\n",
        "    log_rows.append((m, c, how, n_nonna, float(np.nanmean(v))))\n",
        "log = pd.DataFrame(log_rows, columns=['Metal','Matched_Column','Unit_Status','N_nonNa','Mean(ug/m3)'])\n",
        "\n",
        "# 디버그 요약\n",
        "print(\"\\n[DEBUG] 유효 표본수 요약:\", {m:int(pd.to_numeric(series_map[m],errors='coerce').notna().sum()) for m in series_map})\n",
        "\n",
        "# Cr은 제외하더라도 파생만은 허용 (원자료에 Cr 열이 있을 때)\n",
        "if ('Cr(VI)' not in series_map):\n",
        "    c_col = find_col(raw, PAT.get(\"Cr\", r\"^\"))\n",
        "    if c_col is not None:\n",
        "        cr_series, _ = to_ug(raw[c_col], c_col)\n",
        "        series_map['Cr(VI)'] = cr_series/7.0\n",
        "        log.loc[len(log)] = ['Cr(VI)','(derived from Cr/7 even if Cr excluded)','derived',\n",
        "                             int(pd.to_numeric(series_map['Cr(VI)'],errors='coerce').notna().sum()),\n",
        "                             float(np.nanmean(series_map['Cr(VI)']))]\n",
        "\n",
        "# ============================================================\n",
        "# 3) 14개 분포 래퍼 + 적합도 함수\n",
        "# ============================================================\n",
        "class D:\n",
        "    def __init__(self,name): self.name=name; self.p={}; self.np=None; self.valid=False\n",
        "    def ok(self,p,np_): self.p=p; self.np=np_; self.valid=True; return self\n",
        "    def cdf(self,z): raise NotImplementedError\n",
        "    def ppf(self,q): raise NotImplementedError\n",
        "    def rvs(self,n,rs=None): raise NotImplementedError\n",
        "\n",
        "class LogNormal(D):\n",
        "    def __init__(self): super().__init__('로그 정규')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: s,loc,sc=lognorm.fit(x)\n",
        "        except: return self\n",
        "        if s>0 and sc>0 and np.isfinite(loc): return self.ok({'s':s,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return lognorm.cdf(z, s=self.p['s'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return lognorm.ppf(q, s=self.p['s'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return lognorm.rvs(self.p['s'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class Weibull(D):\n",
        "    def __init__(self): super().__init__('와이블')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: c,loc,sc=weibull_min.fit(x)\n",
        "        except: return self\n",
        "        if c>0 and sc>0 and np.isfinite(loc): return self.ok({'c':c,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return weibull_min.cdf(z, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return weibull_min.ppf(q, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return weibull_min.rvs(self.p['c'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class Gamma_(D):\n",
        "    def __init__(self): super().__init__('감마')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: a,loc,sc=gamma.fit(x)\n",
        "        except: return self\n",
        "        if a>0 and sc>0 and np.isfinite(loc): return self.ok({'a':a,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return gamma.cdf(z, a=self.p['a'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return gamma.ppf(q, a=self.p['a'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return gamma.rvs(self.p['a'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class LogisticD(D):\n",
        "    def __init__(self): super().__init__('로지스틱')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=logistic.fit(x)\n",
        "        except: return self\n",
        "        if sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return logistic.cdf(z, **self.p)\n",
        "    def ppf(self,q): return logistic.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return logistic.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class NormalD(D):\n",
        "    def __init__(self): super().__init__('정규')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: mu,sig=norm.fit(x)\n",
        "        except: return self\n",
        "        if sig>0: return self.ok({'loc':mu,'scale':sig},2)\n",
        "        return self\n",
        "    def cdf(self,z): return norm.cdf(z, **self.p)\n",
        "    def ppf(self,q): return norm.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return norm.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class StudentT(D):\n",
        "    def __init__(self): super().__init__('스튜던트의 t')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: df_,loc,sc=student_t.fit(x)\n",
        "        except: return self\n",
        "        if df_>0 and sc>0: return self.ok({'df':df_,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return student_t.cdf(z, **self.p)\n",
        "    def ppf(self,q): return student_t.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return student_t.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class Exponential_(D):\n",
        "    def __init__(self): super().__init__('지수')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=expon.fit(x)\n",
        "        except: return self\n",
        "        if sc>0 and np.isfinite(loc): return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return expon.cdf(z, loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return expon.ppf(q, loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return expon.rvs(size=n, loc=self.p['loc'], scale=self.p['scale'], random_state=rs)\n",
        "\n",
        "class BetaPERT_(D):\n",
        "    def __init__(self,lam=4.0): super().__init__('BetaPERT'); self.lam=lam\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        a,b=float(np.nanmin(x)),float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        m=float(np.clip(hist_mode_estimate(x), a+1e-9, b-1e-9))\n",
        "        al=1+self.lam*(m-a)/(b-a); be=1+self.lam*(b-m)/(b-a)\n",
        "        if al<=0 or be<=0: return self\n",
        "        return self.ok({'a':a,'b':b,'alpha':al,'beta':be,'m':m},2)\n",
        "    def cdf(self,z):\n",
        "        zz=(z-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        return beta.cdf(np.clip(zz,1e-9,1-1e-9), self.p['alpha'], self.p['beta'])\n",
        "    def ppf(self,q): return self.p['a']+(self.p['b']-self.p['a'])*beta.ppf(q, self.p['alpha'], self.p['beta'])\n",
        "    def rvs(self,n,rs=None):\n",
        "        r=beta.rvs(self.p['alpha'], self.p['beta'], size=n, random_state=rs)\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*r\n",
        "\n",
        "class Triangular_(D):\n",
        "    def __init__(self): super().__init__('삼각형')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        a,b=float(np.nanmin(x)),float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        m=float(np.clip(hist_mode_estimate(x), a+1e-9, b-1e-9))\n",
        "        c=(m-a)/(b-a)\n",
        "        if not(0.0 < c < 1.0): return self\n",
        "        return self.ok({'c':c,'loc':a,'scale':(b-a)},2)\n",
        "    def cdf(self,z): return triang.cdf(z, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return triang.ppf(q, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return triang.rvs(self.p['c'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class Uniform_(D):\n",
        "    def __init__(self): super().__init__('균일')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<2: return self\n",
        "        a=float(np.nanmin(x)); b=float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        return self.ok({'loc':a,'scale':(b-a)},2)\n",
        "    def cdf(self,z): return uniform.cdf(z, **self.p)\n",
        "    def ppf(self,q): return uniform.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return uniform.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class GumbelR_(D):\n",
        "    def __init__(self): super().__init__('최대 극값')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=gumbel_r.fit(x)\n",
        "        except: return self\n",
        "        if np.isfinite(loc) and sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return gumbel_r.cdf(z, **self.p)\n",
        "    def ppf(self,q): return gumbel_r.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return gumbel_r.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class GumbelL_(D):\n",
        "    def __init__(self): super().__init__('최소 극값')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=gumbel_l.fit(x)\n",
        "        except: return self\n",
        "        if np.isfinite(loc) and sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return gumbel_l.cdf(z, **self.p)\n",
        "    def ppf(self,q): return gumbel_l.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return gumbel_l.rvs(size=n, random_state=rs, **self.p)\n",
        "\n",
        "class Beta_(D):\n",
        "    def __init__(self): super().__init__('베타')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        a=float(np.nanmin(x)); b=float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        z=np.clip((x-a)/(b-a), 1e-9, 1-1e-9)\n",
        "        try: al,be,_,_ = beta.fit(z, floc=0, fscale=1)\n",
        "        except: return self\n",
        "        if (al>0) and (be>0): return self.ok({'a':a,'b':b,'alpha':al,'beta':be},2)\n",
        "        return self\n",
        "    def cdf(self,z):\n",
        "        zz=(z-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        return beta.cdf(np.clip(zz,1e-9,1-1e-9), self.p['alpha'], self.p['beta'])\n",
        "    def ppf(self,q):\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*beta.ppf(q, self.p['alpha'], self.p['beta'])\n",
        "    def rvs(self,n,rs=None):\n",
        "        r=beta.rvs(self.p['alpha'], self.p['beta'], size=n, random_state=rs)\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*r\n",
        "\n",
        "class Pareto_(D):\n",
        "    def __init__(self): super().__init__('파레토')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: b,loc,sc=pareto.fit(x)\n",
        "        except: return self\n",
        "        if b>0 and sc>0 and np.isfinite(loc): return self.ok({'b':b,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return pareto.cdf(z, b=self.p['b'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return pareto.ppf(q, b=self.p['b'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return pareto.rvs(self.p['b'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "# 적합도 통계\n",
        "def AD_stat(x, cdf, eps=1e-12):\n",
        "    x=np.sort(np.asarray(x,float)); n=x.size\n",
        "    if n<5: return np.inf\n",
        "    u=np.clip(cdf(x),eps,1-eps); i=np.arange(1,n+1)\n",
        "    return float(-n - np.sum((2*i-1)*(np.log(u)+np.log(1-u[::-1])))/n)\n",
        "\n",
        "def AD_p_boot_refit(x, dist_obj, B=BOOTSTRAP_B):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "    n=x.size\n",
        "    if n<5 or (not dist_obj.valid): return np.nan\n",
        "    A2_obs=AD_stat(x, dist_obj.cdf); ge=0; m=0\n",
        "    for _ in range(B):\n",
        "        rs=child_rs(); xs=dist_obj.rvs(n, rs=rs)\n",
        "        d=type(dist_obj)(); d.fit(xs)\n",
        "        if not d.valid: continue\n",
        "        A2_bs=AD_stat(xs, d.cdf); ge+=(A2_bs>=A2_obs); m+=1\n",
        "    return float((ge+1)/(m+1)) if m>0 else np.nan\n",
        "\n",
        "def KS_stat_p(x, d):\n",
        "    try:\n",
        "        D, p = kstest(x, lambda z: d.cdf(z))\n",
        "        return float(D), float(p)\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def Chi2_stat_p(x,d):\n",
        "    try:\n",
        "        n=len(x); N=max(5,min(50,n//5)); eps=1e-6\n",
        "        qs=np.linspace(eps,1-eps,N+1); edges=np.unique(d.ppf(qs))\n",
        "        if len(edges)<3: return np.nan,np.nan\n",
        "        obs,_=np.histogram(x,bins=edges); exp=np.diff(qs)*n\n",
        "        k=d.np or 0; df=len(obs)-1-k\n",
        "        if df<=0: return np.nan,np.nan\n",
        "        exp=np.maximum(exp[:len(obs)],1e-9)\n",
        "        chi=np.sum((obs-exp)**2/exp); p=1.0-chi2.cdf(chi,df)\n",
        "        return float(chi), float(p)\n",
        "    except: return np.nan,np.nan\n",
        "\n",
        "def pstr(name,p):\n",
        "    try:\n",
        "        if name=='정규':         return f\"평균={p['loc']:.5g}, 표준 편차={p['scale']:.5g}\"\n",
        "        if name=='로지스틱':     return f\"평균={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='최대 극값':    return f\"최고가능성={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='최소 극값':    return f\"최고가능성={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='지수':         return f\"위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='로그 정규':    return f\"형태={p['s']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='와이블':       return f\"형태={p['c']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='감마':         return f\"형태={p['a']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='스튜던트의 t': return f\"자유도={p['df']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='베타':         return f\"최소={p['a']:.5g}, 최대={p['b']:.5g}, 알파={p['alpha']:.5g}, 베타={p['beta']:.5g}\"\n",
        "        if name=='BetaPERT':    return f\"최소={p['a']:.5g}, 최빈값={p['m']:.5g}, 최대={p['b']:.5g}, 알파={p['alpha']:.5g}, 베타={p['beta']:.5g}\"\n",
        "        if name=='삼각형':       return f\"최소={p['loc']:.5g}, 최빈값={(p['loc']+p['c']*p['scale']):.5g}, 최대={(p['loc']+p['scale']):.5g}\"\n",
        "        if name=='균일':         return f\"최소={p['loc']:.5g}, 최대={(p['loc']+p['scale']):.5g}\"\n",
        "        if name=='파레토':       return f\"위치={p['loc']:.5g}, 스케일={p['scale']:.5g}, 형태={p['b']:.5g}\"\n",
        "        return json.dumps(p, ensure_ascii=False)\n",
        "    except Exception:\n",
        "        return json.dumps(p, ensure_ascii=False)\n",
        "\n",
        "# ============================================================\n",
        "# 4) 분포 피팅 & 랭킹\n",
        "# ============================================================\n",
        "def fit_one(x):\n",
        "    x=pd.Series(x, dtype=float).replace([np.inf,-np.inf], np.nan).dropna().values\n",
        "    if x.size < 8: return None\n",
        "    if np.unique(x).size < 3:\n",
        "        return None\n",
        "    cands=[LogNormal(),Gamma_(),Weibull(),LogisticD(),NormalD(),StudentT(),\n",
        "           Exponential_(),BetaPERT_(),Triangular_(),Uniform_(),GumbelR_(),GumbelL_(),\n",
        "           Beta_(), Pareto_()]\n",
        "    rows=[]\n",
        "    for d in cands:\n",
        "        d.fit(x)\n",
        "        if not d.valid:\n",
        "            rows.append({'분포':d.name,'AD':np.inf,'ADp':np.nan,'KS':np.nan,'KSp':np.nan,\n",
        "                         'Chi2':np.nan,'Chi2p':np.nan,'np':1e9,'obj':d})\n",
        "            continue\n",
        "        A2=AD_stat(x, d.cdf); pAD=AD_p_boot_refit(x, d, BOOTSTRAP_B)\n",
        "        D,pks=KS_stat_p(x,d); chi,pchi=Chi2_stat_p(x,d)\n",
        "        rows.append({'분포':d.name,'AD':A2,'ADp':pAD,'KS':D,'KSp':pks,\n",
        "                     'Chi2':chi,'Chi2p':pchi,'np':d.np or 9,'obj':d})\n",
        "    df=pd.DataFrame(rows)\n",
        "    ksp_key  = -df['KSp'].fillna(-np.inf)\n",
        "    chi2_key = -df['Chi2p'].fillna(-np.inf)\n",
        "    df['_key'] = list(zip(df['AD'].fillna(np.inf), ksp_key, chi2_key, df['np'].fillna(np.inf)))\n",
        "    df=df.sort_values('_key', kind='mergesort').drop(columns=['_key']).reset_index(drop=True)\n",
        "    best=df.iloc[0]\n",
        "    return best, df\n",
        "\n",
        "fit_tables={}\n",
        "for m in ACTIVE_ORDER:\n",
        "    s = series_map.get(m, None)\n",
        "    if s is None:\n",
        "        fit_tables[m]={'best':None,'table':pd.DataFrame()}; continue\n",
        "    res=fit_one(s.values)\n",
        "    fit_tables[m] = {'best':None,'table':pd.DataFrame()} if res is None else {'best':res[0],'table':res[1]}\n",
        "\n",
        "# ============================================================\n",
        "# 5) 히스토그램 + 최적 PDF\n",
        "# ============================================================\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(f\"{SAVE_DIR}/plots\", exist_ok=True)\n",
        "\n",
        "def plot_hist_with_fit(ax, data, dist_obj, title, bins=None):\n",
        "    x = np.asarray(pd.to_numeric(data, errors='coerce'), float)\n",
        "    x = x[np.isfinite(x)]\n",
        "    n = x.size\n",
        "    ax.cla()\n",
        "\n",
        "    if n == 0:\n",
        "        ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=10)\n",
        "        ax.set_title(title); ax.set_xlabel(\"Concentration (µg/m³)\"); ax.set_ylabel(\"Frequency\")\n",
        "        ax.grid(True, alpha=0.25); return\n",
        "\n",
        "    if (bins is None) or (isinstance(bins, int) and bins <= 0):\n",
        "        bins = freedman_diaconis_bins(x, 30, 70)\n",
        "\n",
        "    counts, edges, _ = ax.hist(x, bins=bins, density=False, alpha=0.5, edgecolor='k')\n",
        "    bin_width = np.diff(edges).mean()\n",
        "\n",
        "    if (dist_obj is not None) and getattr(dist_obj, 'valid', False):\n",
        "\n",
        "        q_lo, q_hi = 0.0005, 0.9995\n",
        "        try:\n",
        "            lo_q = float(dist_obj.ppf(q_lo))\n",
        "            hi_q = float(dist_obj.ppf(q_hi))\n",
        "        except Exception:\n",
        "            lo_q, hi_q = np.nan, np.nan\n",
        "        lo = edges[0]  if (not np.isfinite(lo_q)) else max(edges[0],  lo_q)\n",
        "        hi = edges[-1] if (not np.isfinite(hi_q)) else min(edges[-1], hi_q)\n",
        "        if not (np.isfinite(lo) and np.isfinite(hi) and hi > lo):\n",
        "            lo, hi = edges[0], edges[-1]\n",
        "\n",
        "        xs = np.linspace(lo, hi, 600)\n",
        "\n",
        "        pdf = None\n",
        "        EPS = 1e-9\n",
        "        try:\n",
        "            name = dist_obj.name; p = dist_obj.p\n",
        "            if name == '로그 정규':\n",
        "                pdf = lognorm.pdf(xs, s=p['s'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '와이블':\n",
        "                pdf = weibull_min.pdf(xs, c=p['c'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '감마':\n",
        "                pdf = gamma.pdf(xs, a=p['a'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '지수':\n",
        "                pdf = expon.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '최대 극값':\n",
        "                pdf = gumbel_r.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '최소 극값':\n",
        "                pdf = gumbel_l.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '정규':\n",
        "                pdf = norm.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '로지스틱':\n",
        "                pdf = logistic.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '스튜던트의 t':\n",
        "                pdf = student_t.pdf(xs, df=p['df'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name in ('베타','BetaPERT'):\n",
        "                zz = np.clip((xs - p['a'])/(p['b']-p['a']), EPS, 1 - EPS)\n",
        "                pdf = beta.pdf(zz, p['alpha'], p['beta']) / (p['b']-p['a'])\n",
        "            elif name == '삼각형':\n",
        "                pdf = triang.pdf(xs, c=p['c'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '균일':\n",
        "                pdf = uniform.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '파레토':\n",
        "                pdf = pareto.pdf(xs, b=p['b'], loc=p['loc'], scale=p['scale'])\n",
        "        except Exception:\n",
        "            pdf = None\n",
        "\n",
        "        if pdf is None:\n",
        "            cdf_vals = dist_obj.cdf(xs)\n",
        "            pdf = np.gradient(cdf_vals, xs)\n",
        "\n",
        "        y_pdf = pdf * (n * bin_width)\n",
        "\n",
        "        disp_name = ENG_NAME.get(dist_obj.name, dist_obj.name)\n",
        "        color = DIST_COLOR.get(disp_name, None)\n",
        "        ax.plot(xs, y_pdf, lw=4, label=disp_name, color=color)\n",
        "\n",
        "        y_hist_max = float(np.max(counts)) if len(counts) else 1.0\n",
        "        y_pdf_max  = float(np.nanmax(y_pdf)) if np.all(np.isfinite(y_pdf)) else y_hist_max\n",
        "        ax.set_ylim(0, min(max(y_hist_max, y_pdf_max)*1.2, y_hist_max*20.0))\n",
        "\n",
        "    # ----- 글꼴 크기 & 굵기 일괄 지정 -----\n",
        "    TITLE_FONTSIZE = 17\n",
        "    LABEL_FONTSIZE = 15\n",
        "    TICK_FONTSIZE  = 14\n",
        "    LEGEND_FONTSIZE = 14\n",
        "\n",
        "    ax.set_title(title, fontsize=TITLE_FONTSIZE, fontweight='bold')\n",
        "    ax.set_xlabel(\"Concentration (µg/m³)\", fontsize=LABEL_FONTSIZE, fontweight='bold')\n",
        "    ax.set_ylabel(\"Frequency\",              fontsize=LABEL_FONTSIZE, fontweight='bold')\n",
        "\n",
        "    # 틱 라벨 크기/굵기\n",
        "    ax.tick_params(axis='both', which='major', labelsize=TICK_FONTSIZE)\n",
        "    for lab in (list(ax.get_xticklabels()) + list(ax.get_yticklabels())):\n",
        "        lab.set_fontweight('bold')\n",
        "\n",
        "    # 범례(있는 경우) 크기/굵기\n",
        "    leg = ax.legend()\n",
        "    if leg is not None:\n",
        "        for txt in leg.get_texts():\n",
        "            txt.set_fontsize(LEGEND_FONTSIZE)\n",
        "            txt.set_fontweight('bold')\n",
        "\n",
        "    # ---------- x축 눈금: 숫자 + 개수 자동 조정 ----------\n",
        "    apply_pretty_xticks(ax, min_ticks=4, max_ticks=7)\n",
        "\n",
        "\n",
        "# 4x2 패널 요약 그림\n",
        "fig, axes = plt.subplots(4, 2, figsize=(12, 16))\n",
        "axes = axes.ravel()\n",
        "idx = 0\n",
        "\n",
        "for m in ACTIVE_ORDER:\n",
        "    data = series_map.get(m, pd.Series(dtype=float))\n",
        "    best = fit_tables.get(m, {}).get('best')\n",
        "    obj  = best['obj'] if (best is not None and best.get('obj') is not None and best['obj'].valid) else None\n",
        "    plot_hist_with_fit(axes[idx], data, obj, m)\n",
        "    idx += 1\n",
        "    if idx >= 8:\n",
        "        break\n",
        "\n",
        "# 빈 패널 끄기 (여기서 ':7' 제거 + 들여쓰기 정상화)\n",
        "while idx < 8:\n",
        "    axes[idx].axis('off')\n",
        "    idx += 1\n",
        "\n",
        "fig.suptitle(\"Histograms with Best-Fit Distribution\", fontsize=20, fontweight='bold')\n",
        "fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "fig.savefig(f\"{SAVE_DIR}/plots/Tx_fitting_summary.png\", dpi=200)\n",
        "plt.show()\n",
        "\n",
        "# 개별 그림\n",
        "for m in ACTIVE_ORDER:\n",
        "    data = series_map.get(m, pd.Series(dtype=float))\n",
        "    best = fit_tables.get(m, {}).get('best')\n",
        "    obj  = best['obj'] if (best is not None and best.get('obj') is not None and best['obj'].valid) else None\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    plot_hist_with_fit(ax, data, obj, m)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(f\"{SAVE_DIR}/plots/{m}_fit.png\", dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "# ============================================================\n",
        "# 6) 피팅 결과 엑셀 저장\n",
        "# ============================================================\n",
        "suffix = (\"excl_\" + \"_\".join(sorted(EXCLUDE_SET))) if EXCLUDE_SET else \"all\"\n",
        "fit_xlsx = os.path.join(SAVE_DIR, f\"Tx_fit_result_{suffix}.xlsx\")\n",
        "wb=Workbook()\n",
        "ws=wb.active; ws.title=\"Tx-적합도 보고서\"\n",
        "\n",
        "def set_col_widths(ws, widths):\n",
        "    for col,w in widths.items(): ws.column_dimensions[col].width = w\n",
        "def styled_header(ws, row, headers, start_col=1, fill_color=HEADER_BLUE):\n",
        "    fill = PatternFill('solid', fgColor=fill_color); white = Font(color='FFFFFF', bold=True)\n",
        "    center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
        "    thin = Border(left=Side(style='thin', color=THIN_GRAY), right=Side(style='thin', color=THIN_GRAY),\n",
        "                  top=Side(style='thin', color=THIN_GRAY), bottom=Side(style='thin', color=THIN_GRAY))\n",
        "    for j,h in enumerate(headers, start=start_col):\n",
        "        c = ws.cell(row=row, column=j, value=h)\n",
        "        c.fill = fill; c.font = white; c.alignment = center; c.border = thin\n",
        "def write_num(ws, r, c, v, fmt='0.0000'):\n",
        "    cell=ws.cell(row=r, column=c)\n",
        "    if v is None or (isinstance(v,float) and (np.isnan(v) or np.isinf(v))): cell.value='---'\n",
        "    else:\n",
        "        cell.value=float(v) if isinstance(v,(int,float,np.floating)) else v\n",
        "        if isinstance(v,(int,float,np.floating)): cell.number_format = fmt\n",
        "\n",
        "set_col_widths(ws, {'A':18,'B':12,'C':12,'D':12,'E':12,'F':12,'G':12,'H':12,'I':64})\n",
        "ws.freeze_panes = 'B3'\n",
        "ws['A1'] = '순위: AD↓ → KS p↑ → χ² p↑ → #params↓'; ws['A2']='데이터 계열'\n",
        "\n",
        "row=3; table_idx=1\n",
        "for m in ACTIVE_ORDER:\n",
        "    ws.cell(row=row, column=1, value=m).font = Font(bold=True); row += 1\n",
        "    headers=['분포','A-D','A-D P-값','K-S','K-S P-값','카이제곱','카이제곱 P-값','매개 변수']\n",
        "    styled_header(ws,row,headers,start_col=2); start_row=row; row+=1\n",
        "\n",
        "    tbl = fit_tables.get(m,{}).get('table', pd.DataFrame())\n",
        "    if tbl is None or tbl.empty:\n",
        "        ws.cell(row=row, column=2, value=\"(no data or <8 or <3 uniques)\"); row+=2; continue\n",
        "\n",
        "    for i,r_ in tbl.iterrows():\n",
        "        rr=row+i\n",
        "        ws.cell(row=rr, column=2, value=r_['분포'])\n",
        "        write_num(ws, rr,3, r_['AD'])\n",
        "        write_num(ws, rr,4, r_['ADp'])\n",
        "        write_num(ws, rr,5, r_['KS'])\n",
        "        write_num(ws, rr,6, r_['KSp'])\n",
        "        write_num(ws, rr,7, r_['Chi2'])\n",
        "        write_num(ws, rr,8, r_['Chi2p'])\n",
        "        ws.cell(row=rr, column=9, value=pstr(r_['분포'], r_['obj'].p))\n",
        "\n",
        "    end_row = row + len(tbl) - 1\n",
        "    try:\n",
        "        t = Table(displayName=f\"T_{table_idx}\", ref=f\"B{start_row}:I{end_row}\")\n",
        "        t.tableStyleInfo = TableStyleInfo(name=TABLE_STYLE, showFirstColumn=False, showLastColumn=False,\n",
        "                                          showRowStripes=True, showColumnStripes=False)\n",
        "        ws.add_table(t); table_idx+=1\n",
        "    except Exception: pass\n",
        "    fill = PatternFill('solid', fgColor=BEST_FILL)\n",
        "    if len(tbl)>0:\n",
        "        for c in range(2,10): ws.cell(row=start_row+1, column=c).fill=fill\n",
        "    row=end_row+2\n",
        "\n",
        "# --- 시트2: Tx-일괄 분포 적합 가정 (데이터≥1이면 표기) ---\n",
        "wsS = wb.create_sheet(\"Tx-일괄 분포 적합 가정\")\n",
        "metals = [m for m in ACTIVE_ORDER if (m in series_map) and (pd.to_numeric(series_map[m], errors='coerce').notna().sum()>=1)]\n",
        "\n",
        "# 행 라벨(공통)\n",
        "rows_hdr = [\"E[X] (µg/m³)\", \"Best-fit\", \"Anderson–Darling\", \"A–D p-value\"]\n",
        "for i, label in enumerate(rows_hdr, start=2):  # 2~5행에 라벨\n",
        "    wsS.cell(row=i, column=1, value=label).font = Font(bold=True)\n",
        "\n",
        "# 금속 헤더(1행) + 값(2~5행)\n",
        "for j, m in enumerate(metals, start=2):\n",
        "    wsS.cell(row=1, column=j, value=m).font = Font(bold=True)\n",
        "\n",
        "    best = fit_tables.get(m, {}).get('best')\n",
        "\n",
        "    # E[X] 산정(가능하면 적합분포로부터, 아니면 원자료 평균)\n",
        "    def safe_EX(best_, m_):\n",
        "        if best_ is not None and best_.get('obj') is not None and best_['obj'].valid:\n",
        "            try:\n",
        "                return float(np.mean(best_['obj'].rvs(200000, rs=child_rs())))\n",
        "            except Exception:\n",
        "                pass\n",
        "        if m_ in series_map:\n",
        "            return float(np.nanmean(pd.to_numeric(series_map[m_], errors='coerce')))\n",
        "        return np.nan\n",
        "\n",
        "    ex = safe_EX(best, m); cell = wsS.cell(row=2, column=j, value=ex); cell.number_format = '0.0000'\n",
        "\n",
        "    wsS.cell(row=3, column=j, value=(best['분포'] if best is not None else '---'))\n",
        "\n",
        "    ad_val = float(best['AD']) if (best is not None and np.isfinite(best['AD'])) else np.nan\n",
        "    cell = wsS.cell(row=4, column=j, value=ad_val); cell.number_format = '0.0000'\n",
        "\n",
        "    adp_val = float(best['ADp']) if (best is not None and np.isfinite(best['ADp'])) else np.nan\n",
        "    cell = wsS.cell(row=5, column=j, value=adp_val); cell.number_format = '0.0000'\n",
        "\n",
        "# 상관행렬\n",
        "start_r = 6\n",
        "wsS.cell(row=start_r, column=1, value=\"상관관계:\").font = Font(bold=True)\n",
        "if metals:\n",
        "    df_corr = pd.DataFrame({m: pd.to_numeric(series_map[m], errors='coerce') for m in metals}).corr()\n",
        "    for i, m in enumerate(metals, start=2):\n",
        "        wsS.cell(row=start_r+1, column=i, value=m).font = Font(bold=True)\n",
        "        wsS.cell(row=start_r+1+i-1, column=1, value=m).font = Font(bold=True)\n",
        "    for r, m in enumerate(metals, start=0):\n",
        "        for c, n in enumerate(metals, start=0):\n",
        "            v = float(df_corr.iloc[r, c]) if np.isfinite(df_corr.iloc[r, c]) else np.nan\n",
        "            cell = wsS.cell(row=start_r+2+r, column=2+c, value=v); cell.number_format='0.000'\n",
        "\n",
        "# --- 시트3: Log ---\n",
        "wsL = wb.create_sheet(\"Log\")\n",
        "wsL.append(list(log.columns))\n",
        "for _,r in log.iterrows(): wsL.append(list(r.values))\n",
        "\n",
        "wb.save(fit_xlsx)\n",
        "print(\"Saved:\", fit_xlsx)\n",
        "\n",
        "# ============================================================\n",
        "# 7) 몬테카를로: 농도 난수 + 검증(ECDF/QQ)\n",
        "# ============================================================\n",
        "C_sims={}\n",
        "for m in ACTIVE_ORDER:\n",
        "    s = series_map.get(m, None)\n",
        "    if s is None: continue\n",
        "    info=fit_tables[m]['best']\n",
        "    if (info is not None) and (info.get('obj') is not None) and (info['obj'].valid):\n",
        "        C_sims[m]=info['obj'].rvs(N_SIM, rs=child_rs())\n",
        "    else:\n",
        "        x = pd.to_numeric(s, errors='coerce').dropna().values\n",
        "        if x.size>=1:\n",
        "            idx=np.random.randint(0,len(x), size=N_SIM); C_sims[m]=x[idx]\n",
        "# Cr(VI) 시뮬 파생 — 제외되지 않았을 때만\n",
        "if ('Cr(VI)' not in EXCLUDE_SET) and ('Cr(VI)' not in C_sims) and ('Cr' in C_sims):\n",
        "    C_sims['Cr(VI)']=C_sims['Cr']/7.0\n",
        "\n",
        "print(\"\\n===== Monte Carlo 난수 샘플 (금속별 농도, µg/m³) =====\")\n",
        "for m in ACTIVE_ORDER:\n",
        "    if m in C_sims:\n",
        "        arr = np.array(C_sims[m]); print(f\"{m}: {np.array2string(arr[:10], precision=6, separator=', ')}\")\n",
        "\n",
        "def qstats(x):\n",
        "    x=np.asarray(x, float); x=x[np.isfinite(x)]\n",
        "    return {'mean': float(np.mean(x)), 'median': float(np.median(x)),\n",
        "            'p5': float(np.percentile(x,5)), 'p95': float(np.percentile(x,95))}\n",
        "def print_row(label, d):\n",
        "    print(f\"{label:<18} mean={d['mean']:.3e}, median={d['median']:.3e}, p5={d['p5']:.3e}, p95={d['p95']:.3e}\")\n",
        "def fitted_ppf_summary(dist_obj):\n",
        "    p5  = float(dist_obj.ppf(0.05)); p50 = float(dist_obj.ppf(0.50)); p95 = float(dist_obj.ppf(0.95))\n",
        "    xs  = dist_obj.rvs(200000, rs=child_rs()); mean = float(np.mean(xs))\n",
        "    return {'mean':mean, 'median':p50, 'p5':p5, 'p95':p95}\n",
        "def ecdf(x):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]; x=np.sort(x); n=x.size\n",
        "    if n==0: return x, x\n",
        "    y=np.arange(1,n+1)/n; return x,y\n",
        "\n",
        "def qq_plot_raw_vs_single(ax, raw_sample, dist_obj, title):\n",
        "    \"\"\"\n",
        "    Q–Q: Raw vs Single\n",
        "    - x축: Raw quantiles\n",
        "    - y축: Single(선택된 단일분포) 이론 quantiles\n",
        "    \"\"\"\n",
        "    x = np.asarray(raw_sample, float)\n",
        "    x = x[np.isfinite(x)]\n",
        "\n",
        "    if x.size < 5:\n",
        "        ax.text(0.5, 0.5, \"(표본부족)\", ha='center', va='center')\n",
        "        ax.set_title(title)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        return\n",
        "\n",
        "    # Raw quantiles\n",
        "    x = np.sort(x)\n",
        "    n = x.size\n",
        "    probs = (np.arange(1, n + 1) - 0.5) / n\n",
        "\n",
        "    # Single 분포 이론 quantiles\n",
        "    try:\n",
        "        theo = dist_obj.ppf(probs)\n",
        "    except Exception:\n",
        "        ax.text(0.5, 0.5, \"(PPF 계산 실패)\", ha='center', va='center')\n",
        "        ax.set_title(title)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        return\n",
        "\n",
        "    # 산점도 + 1:1 선\n",
        "    ax.scatter(x, theo, s=6, alpha=0.6)\n",
        "\n",
        "    both = np.concatenate([x, theo])\n",
        "    lo, hi = np.nanpercentile(both, [1, 99])\n",
        "    if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:\n",
        "        lo, hi = np.nanmin(both), np.nanmax(both)\n",
        "\n",
        "    ax.plot([lo, hi], [lo, hi], lw=1, linestyle='--')\n",
        "\n",
        "    ax.set_xlabel(\"Raw quantiles\")\n",
        "    ax.set_ylabel(\"Single quantiles\")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "def validate_C_distributions():\n",
        "    metals_to_check = [m for m in ACTIVE_ORDER if m in C_sims]\n",
        "    for m in metals_to_check:\n",
        "        print(\"\\n\" + \"=\"*76); print(f\"[C 검증] {m}\")\n",
        "        raw_trim = pd.to_numeric(series_map.get(m, pd.Series(dtype=float)), errors='coerce')\n",
        "        raw_trim = raw_trim[np.isfinite(raw_trim)]\n",
        "        s_raw = qstats(raw_trim) if raw_trim.size>0 else None\n",
        "\n",
        "        best = fit_tables.get(m, {}).get('best')\n",
        "        dist = best['obj'] if (best is not None and best.get('obj') is not None) else None\n",
        "        s_fit = fitted_ppf_summary(dist) if (dist is not None and dist.valid) else None\n",
        "\n",
        "        csim = np.asarray(C_sims[m], float); s_sim = qstats(csim)\n",
        "        if s_raw: print_row(\"Raw(trimmed)\", s_raw)\n",
        "        else: print(\"Raw(trimmed)     없음/표본부족\")\n",
        "        if s_fit: print_row(\"Fitted(theory)\", s_fit)\n",
        "        else: print(\"Fitted(theory)   없음/피팅불가\")\n",
        "        print_row(\"Simulated(C_sims)\", s_sim)\n",
        "\n",
        "        plt.figure(figsize=(10,4))\n",
        "        ax1 = plt.subplot(1,2,1)\n",
        "        if raw_trim.size>0:\n",
        "            x,y = ecdf(raw_trim); ax1.step(x,y, where='post', label='Raw', alpha=0.8)\n",
        "        xs,ys = ecdf(csim); ax1.step(xs,ys, where='post', label='Simulated', alpha=0.8)\n",
        "        try:\n",
        "            spread = np.nanpercentile(xs,95)/max(1e-12,np.nanpercentile(xs,5))\n",
        "            if spread>20: ax1.set_xscale('log')\n",
        "        except: pass\n",
        "        ax1.set_title(f\"{m} – ECDF\"); ax1.set_xlabel(\"Concentration (µg/m³)\"); ax1.set_ylabel(\"Cumulative probability\")\n",
        "        ax1.grid(True, alpha=0.3); ax1.legend()\n",
        "\n",
        "        ax2 = plt.subplot(1, 2, 2)\n",
        "        if (dist is not None) and dist.valid and (raw_trim.size > 0):\n",
        "            # Q–Q: Raw vs Single (선택된 단일분포)\n",
        "            qq_plot_raw_vs_single(ax2, raw_trim, dist, f\"{m} – Q–Q (Raw vs Single)\")\n",
        "        else:\n",
        "            ax2.text(0.5, 0.5, \"피팅없음/표본부족\", ha='center', va='center')\n",
        "            ax2.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "validate_C_distributions()\n",
        "\n",
        "# ============================================================\n",
        "# 8) Time-outdoors 난수 → K 계산 + 검증 표\n",
        "# ============================================================\n",
        "_Z95=1.6448536269514722\n",
        "def mu_sigma_from_p5p95(p5,p95):\n",
        "    p5=max(1e-9,float(p5)); p95=max(1e-9,float(p95))\n",
        "    if p95<=p5: p95=p5*1.01\n",
        "    ln5,ln95=np.log(p5),np.log(p95); sigma=(ln95-ln5)/(2*_Z95); mu=(ln5+ln95)/2; return mu,sigma\n",
        "def sample_AcTout(age, n):\n",
        "    if age in ACT_POINT: return np.full(n, float(ACT_POINT[age]), dtype=float)\n",
        "    p5,p95=ACT_LN_P5_P95[age]; mu,sg=mu_sigma_from_p5p95(p5,p95)\n",
        "    return np.random.lognormal(mu,sg,size=n)\n",
        "def K_by_group(n):\n",
        "    Kg = {'Infant':np.zeros(n), 'Child':np.zeros(n), 'Adult':np.zeros(n)}\n",
        "    for age in INFANT+CHILD+ADULT:\n",
        "        act = sample_AcTout(age, n)\n",
        "        act_dayfrac = act / 1440.0\n",
        "        add = act_dayfrac * EF * (ED_years[age]/LT_years) * (10.0 if age in INFANT else (3.0 if age in CHILD else 1.0))\n",
        "        if age in INFANT: Kg['Infant'] += add\n",
        "        elif age in CHILD: Kg['Child'] += add\n",
        "        else: Kg['Adult'] += add\n",
        "    Kg['Lifetime'] = Kg['Infant'] + Kg['Child'] + Kg['Adult']\n",
        "    return Kg\n",
        "Kg = K_by_group(N_SIM)\n",
        "\n",
        "print(\"\\n===== Time outdoors 난수 샘플 (min/day) =====\")\n",
        "for age in AGE_ORDER:\n",
        "    arr = sample_AcTout(age, 10)\n",
        "    print(f\"{age}: {np.array2string(arr, precision=3, separator=', ')}\")\n",
        "\n",
        "def check_time_out_samples():\n",
        "    print(\"\\n===== Time outdoors 난수 분포 검증 =====\")\n",
        "    print(f\"{'Age':<10} {'Mean(sample)':>12} {'P5(sample)':>12} {'P95(sample)':>12} {'Target Mean':>12} {'Target 95th':>12}\")\n",
        "    for age in AGE_ORDER:\n",
        "        n=200000\n",
        "        s=sample_AcTout(age, n)\n",
        "        mean_s=np.mean(s); p5_s=np.percentile(s,5); p95_s=np.percentile(s,95)\n",
        "        if age in ACT_POINT: t_mean=ACT_POINT[age]; t_p95=ACT_POINT[age]\n",
        "        else: t_mean=None; t_p95=ACT_LN_P5_P95[age][1]\n",
        "        t_mean_str = f\"{t_mean:,.1f}\" if t_mean is not None else \"---\"\n",
        "        print(f\"{age:<10} {mean_s:12.3f} {p5_s:12.3f} {p95_s:12.3f} {t_mean_str:>12} {t_p95:12.1f}\")\n",
        "check_time_out_samples()\n",
        "\n",
        "# ============================================================\n",
        "# 9) LECR 계산 (Infant/Child/Adult 분리) + 요약 출력\n",
        "# ============================================================\n",
        "def _stats(v: np.ndarray):\n",
        "    v = np.asarray(v, float)\n",
        "    v = v[np.isfinite(v)]\n",
        "    return dict(\n",
        "        mean=float(np.mean(v)),\n",
        "        median=float(np.median(v)),\n",
        "        p95=float(np.percentile(v, 95)),\n",
        "        p99=float(np.percentile(v, 99)))\n",
        "\n",
        "def summarize_risk_by_stage(C_sims: dict, Kg: dict):\n",
        "    out_rows = []\n",
        "    cum_vec  = np.zeros(N_SIM, float)\n",
        "\n",
        "    for m in ACTIVE_ORDER:\n",
        "        if (m not in IUR) or (m not in C_sims):\n",
        "            continue\n",
        "\n",
        "        C = np.asarray(C_sims[m], float)\n",
        "        lecr_inf   = C * Kg['Infant'] * float(IUR[m])\n",
        "        lecr_child = C * Kg['Child']  * float(IUR[m])\n",
        "        lecr_adult = C * Kg['Adult']  * float(IUR[m])\n",
        "        lecr_tot   = lecr_inf + lecr_child + lecr_adult\n",
        "\n",
        "        cum_vec += lecr_tot\n",
        "\n",
        "        out_rows.append({\n",
        "            'Metal': m,\n",
        "            'Infant': _stats(lecr_inf),\n",
        "            'Child':  _stats(lecr_child),\n",
        "            'Adult':  _stats(lecr_adult),\n",
        "            'LECR (per metal)': _stats(lecr_tot)})\n",
        "\n",
        "    cum_stats = {\n",
        "        'Total LECR': {\n",
        "            'mean':   float(np.mean(cum_vec)),\n",
        "            'median': float(np.median(cum_vec)),\n",
        "            'p95':    float(np.percentile(cum_vec, 95)),\n",
        "            'p99':    float(np.percentile(cum_vec, 99))}}\n",
        "    return out_rows, cum_stats\n",
        "\n",
        "# 계산 및 콘솔 출력\n",
        "risk_rows, cum_stats = summarize_risk_by_stage(C_sims, Kg)\n",
        "\n",
        "print(\"\\n===== LECR 요약 (Infant / Child / Adult / LECR (per metal)) =====\")\n",
        "for r in risk_rows:\n",
        "    m = r['Metal']\n",
        "    si, sc, sa, st = r['Infant'], r['Child'], r['Adult'], r['LECR (per metal)']\n",
        "    print(f\"\\n[{m}]\")\n",
        "    print(f\"  Infant          : mean={si['mean']:.5e}, median={si['median']:.5e}, P95={si['p95']:.5e}, P99={si['p99']:.5e}\")\n",
        "    print(f\"  Child           : mean={sc['mean']:.5e}, median={sc['median']:.5e}, P95={sc['p95']:.5e}, P99={sc['p99']:.5e}\")\n",
        "    print(f\"  Adult           : mean={sa['mean']:.5e}, median={sa['median']:.5e}, P95={sa['p95']:.5e}, P99={sa['p99']:.5e}\")\n",
        "    print(f\"  LECR (per metal): mean={st['mean']:.5e}, median={st['median']:.5e}, P95={st['p95']:.5e}, P99={st['p99']:.5e}\")\n",
        "\n",
        "print(\"\\n===== Total LECR (Lifetime, across metals) =====\")\n",
        "cs = cum_stats['Total LECR']\n",
        "print(f\"  mean={cs['mean']:.3e}, median={cs['median']:.3e}, P95={cs['p95']:.3e}, P99={cs['p99']:.3e}\")\n",
        "\n",
        "# 엑셀 저장\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "lecr_xlsx = os.path.join(SAVE_DIR, \"Tx.xlsx\")\n",
        "wb2 = Workbook(); wsR=wb2.active; wsR.title=\"LECR 결과 요약\"\n",
        "wsR.append([\"Metal\",\"mean\",\"median\",\"P95\",\"P99\"])\n",
        "for r in risk_rows:\n",
        "    m=r['Metal']; s=r['LECR (per metal)']; wsR.append([m,s['mean'],s['median'],s['p95'],s['p99']])\n",
        "wsR2 = wb2.create_sheet(\"Total LECR\")\n",
        "wsR2.append([\"metric\",\"value\"])\n",
        "for k,v in cum_stats['Total LECR'].items(): wsR2.append([k,v])\n",
        "wb2.save(lecr_xlsx)\n",
        "\n",
        "print(\"\\n=== 완료 ===\")\n",
        "print(f\"- 피팅 엑셀: {fit_xlsx}\")\n",
        "print(f\"- LECR 엑셀: {lecr_xlsx}\")\n",
        "print(f\"- 그림 폴더: {SAVE_DIR}/plots\")\n",
        "files.download(fit_xlsx); files.download(lecr_xlsx)"
      ],
      "metadata": {
        "id": "s8UoKBoZge3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Single + GMM) 금속별 농도 예측 & 검증 ##"
      ],
      "metadata": {
        "id": "4zVI3x6OgQL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 최종 통합 파이프라인  (Best single-fit vs GMM(Log) + MC + LECR)\n",
        "# - ADD: GMM (bimodal 또는 single 불안정일 때만 후보)\n",
        "# - TUNE: GMM: AD 개선 10%/ΔBIC 6, bimodal에서는 완화 3%/10\n",
        "# - ADD: 꼬리 폭주 방지(P95 rollback): GMM 채택 후 P95_sim/P95_raw > 2.0 이면 단일로 롤백\n",
        "# - KEEP: AD bootstrap refit 시 GMM 설정 유지 / Chi-square에서 GMM 제외 / Tout QA\n",
        "# - FIX: get_chosen_model_label() 미정의 → 함수 추가\n",
        "# - FIX: ECDF 로그축에서 0 포함 시 에러/빈그래프 → 0을 EPS로 치환하여 로그축 안전화\n",
        "# - FIX: 히스토그램/PDF 끊김(퍼센타일 컷 제거) → edges 전체구간(+pad)로 PDF 생성\n",
        "# - ADD: (운영안정) GMM rvs에서 floor 미만 재샘플링(최대 20회) + 최후 floor 클램프\n",
        "# ============================================================\n",
        "\n",
        "# ---------- Imports ----------\n",
        "from google.colab import files\n",
        "import os, re, json, math, warnings, glob, io\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import kstest\n",
        "from scipy.stats import (\n",
        "    gumbel_r, gumbel_l, lognorm, weibull_min, logistic,\n",
        "    norm, gamma, beta, triang, expon, pareto, uniform, chi2)\n",
        "from scipy.stats import t as student_t\n",
        "\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
        "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---- sklearn GMM import ----\n",
        "try:\n",
        "    from sklearn.mixture import GaussianMixture\n",
        "    _SKLEARN_OK = True\n",
        "except Exception:\n",
        "    _SKLEARN_OK = False\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 0) 사용자 설정\n",
        "# ============================================================\n",
        "np.random.seed(20250912)\n",
        "\n",
        "N_SIM       = 10_000\n",
        "BOOTSTRAP_B = 200\n",
        "SAVE_DIR    = \"outputs\"\n",
        "\n",
        "# 제외 금속: 예) [\"Cr\", \"Cd\"]\n",
        "EXCLUDE_METALS = [\"Cr\", \"Cd\"]\n",
        "\n",
        "# ND/<MDL> 처리 정책: \"half\" | \"nan\" | \"uniform\"\n",
        "MDL_POLICY = \"uniform\"\n",
        "\n",
        "# GMM(Log) 컴포넌트 후보\n",
        "GMM_K_LIST = (1, 2, 3, 4)\n",
        "\n",
        "# ---- 운영 안정성 옵션 ----\n",
        "RUN_TOUT_QA = True\n",
        "TOUT_QA_N   = 50_000\n",
        "FIT_MIN_N   = 8\n",
        "GMM_MIN_N   = 30\n",
        "GMM_W_MIN   = 0.02\n",
        "DIAG_ENABLE = True\n",
        "\n",
        "# ---- 모델 선택 정책(운영 안정성 추천값) ----\n",
        "# 기본(단봉에서 GMM 억제)\n",
        "GMM_AD_IMPROVE_RATIO = 0.10    # AD 개선률 10% 이상\n",
        "GMM_BIC_DELTA_MAX    = 6.0     # ΔBIC 허용폭 6 이하\n",
        "\n",
        "# bimodal(이중피크)일 때만 완화\n",
        "GMM_AD_IMPROVE_BIMODAL = 0.03  # 3%만 개선돼도\n",
        "GMM_BIC_DELTA_BIMODAL  = 10.0  # ΔBIC 허용폭 완화\n",
        "\n",
        "# ---- GMM 후보 게이트 ----\n",
        "# bimodal=True이면 GMM 후보, 또는 single 적합 불량(ADp<0.05) + GMM이 개선되면 후보\n",
        "GMM_GATE_ADP_SINGLE_BAD = 0.05\n",
        "\n",
        "# ---- 꼬리 폭주 방지: P95 롤백 ----\n",
        "P95_ROLLBACK_RATIO = 2.0  # P95_sim / P95_raw > 2.0 이면 GMM 취소 -> 단일로 롤백\n",
        "\n",
        "# ---- 다봉 판정 히스토그램 파라미터 ----\n",
        "BIMODAL_BINS = 60\n",
        "BIMODAL_SMOOTH = 2\n",
        "BIMODAL_MIN_PROM_RATIO = 0.12\n",
        "\n",
        "# ---- GMM near-zero 억제 + K 과민 억제 ----\n",
        "GMM_FLOOR_Q   = 1.0    # 양수값 하위 q%를 floor로 두고 학습(권장 1~5)\n",
        "GMM_SIGMA_MIN = 0.15   # log공간 sigma 최소(권장 0.1~0.25)\n",
        "GMM_K_BIC_TOL = 10.0   # sklearn-bic 최저 대비 tol 이내면 동급 -> 작은 K 선택\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1) 고정 상수/매핑\n",
        "# ============================================================\n",
        "IUR = {\"Cr(VI)\":1.20e-02,\"Co\":9.00e-03,\"Ni\":2.40e-04,\"As\":4.30e-03,\"Cd\":1.80e-03,\"Sb\":2.29e-06,\"Pb\":1.20e-05}\n",
        "ORDER = ['Cr','Cr(VI)','Co','Ni','As','Cd','Sb','Pb']\n",
        "\n",
        "EXCLUDE_SET  = set(m.strip() for m in EXCLUDE_METALS)\n",
        "ACTIVE_ORDER = [m for m in ORDER if m not in EXCLUDE_SET]\n",
        "\n",
        "ENG_NAME = {\n",
        "    '로그 정규':'Lognormal', '와이블':'Weibull', '감마':'Gamma', '지수':'Exponential',\n",
        "    '최대 극값':'Gumbel Max', '최소 극값':'Gumbel Min', '정규':'Normal', '로지스틱':'Logistic',\n",
        "    \"스튜던트의 t\":\"Student's t\", '베타':'Beta', 'BetaPERT':'BetaPERT',\n",
        "    '삼각형':'Triangular', '균일':'Uniform', '파레토':'Pareto',\n",
        "    'GMM(Log)':'GMM(Log)'}\n",
        "\n",
        "DIST_COLOR = {\n",
        "    'Lognormal': 'tab:orange',\n",
        "    'Weibull': 'tab:green',\n",
        "    'Gamma': 'tab:purple',\n",
        "    'Exponential': 'tab:red',\n",
        "    'Gumbel Max': 'tab:olive',\n",
        "    'Gumbel Min': 'tab:cyan',\n",
        "    'Normal': 'tab:blue',\n",
        "    'Logistic': 'tab:pink',\n",
        "    \"Student's t\": 'tab:brown',\n",
        "    'Beta': 'tab:gray',\n",
        "    'BetaPERT': 'tab:purple',\n",
        "    'Triangular': 'tab:teal',\n",
        "    'Uniform': 'tab:cyan',\n",
        "    'Pareto': 'tab:red',\n",
        "    'GMM(Log)': '#111111'}\n",
        "\n",
        "PAT = {\n",
        "    \"Cr(VI)\": r\"(?:\\bCr\\s*VI\\b|\\bCr[-\\s]*VI\\b|\\bCr\\s*6\\+\\b|Cr[-\\s]*6\\+|Hexa(?:valent)?\\s*Chrom(?:ium)?|6가\\s*크롬|육가\\s*크롬|육가크롬)\",\n",
        "    \"Cr\"    : r\"(?:\\bCr\\b(?!\\s*(?:VI|6\\+))|Chromium|크롬)\",\n",
        "    \"Co\"    : r\"(?:\\bCo\\b|\\bC\\s*o\\b|Cobalt|코발트)\",\n",
        "    \"Ni\"    : r\"(?:\\bNi\\b|\\bN\\s*i\\b|Nickel|니켈)\",\n",
        "    \"As\"    : r\"(?:\\bA\\s*s\\b|\\bAs\\b(?=[\\s\\(\\[]|$)|Arsenic|비소)\",\n",
        "    \"Cd\"    : r\"(?:\\bCd\\b|\\bC\\s*d\\b|Cadmium|카드뮴)\",\n",
        "    \"Sb\"    : r\"(?:\\bS[bB]\\b|\\bS\\s*B\\b|Stibium|Antimon(?:y)?|안티몬)\",\n",
        "    \"Pb\"    : r\"(?:\\bPb\\b|\\bP\\s*b\\b|Lead|납)\"}\n",
        "\n",
        "HEADER_BLUE = '2F5597'\n",
        "BEST_FILL   = 'FFF2CC'\n",
        "THIN_GRAY   = '999999'\n",
        "TABLE_STYLE = \"TableStyleMedium9\"\n",
        "\n",
        "EF_days_per_year = 350\n",
        "EF = EF_days_per_year/365.0\n",
        "LT_years = 78.6\n",
        "\n",
        "ACT_POINT = {\"0-<1\":24,\"1-<2\":84,\"2-<3\":120,\"3-<6\":108,\"6-<11\":132,\"11-<16\":102,\"16-<18\":102}\n",
        "ACT_LN_P5_P95 = {\n",
        "    \"18-<25\":(14.455,250.0),\"25-<35\":(6.516,220.0),\"35-<45\":(5.789,195.0),\n",
        "    \"45-<55\":(6.401,260.0),\"55-<65\":(8.083,350.0),\"65-<78.6\":(6.094,390.0)}\n",
        "ED_years = {\n",
        "    \"0-<1\":1,\"1-<2\":1,\"2-<3\":1,\"3-<6\":3,\"6-<11\":5,\"11-<16\":5,\"16-<18\":2,\n",
        "    \"18-<25\":7,\"25-<35\":10,\"35-<45\":10,\"45-<55\":10,\"55-<65\":10,\"65-<78.6\":13.6}\n",
        "\n",
        "AGE_ORDER=[\"0-<1\",\"1-<2\",\"2-<3\",\"3-<6\",\"6-<11\",\"11-<16\",\"16-<18\",\"18-<25\",\"25-<35\",\"35-<45\",\"45-<55\",\"55-<65\",\"65-<78.6\"]\n",
        "INFANT = [\"0-<1\",\"1-<2\"]\n",
        "CHILD  = [\"2-<3\",\"3-<6\",\"6-<11\",\"11-<16\",\"16-<18\"]\n",
        "ADULT  = [\"18-<25\",\"25-<35\",\"35-<45\",\"45-<55\",\"55-<65\",\"65-<78.6\"]\n",
        "\n",
        "_master_rs = np.random.RandomState(20250912)\n",
        "def child_rs():\n",
        "    return np.random.RandomState(_master_rs.randint(0, 2**31-1))\n",
        "\n",
        "_mdl_rs = child_rs()\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"font.size\": 11,\n",
        "    \"axes.titlesize\": 14,\n",
        "    \"axes.titleweight\": \"bold\",\n",
        "    \"axes.labelsize\": 12,\n",
        "    \"axes.labelweight\": \"bold\",\n",
        "    \"legend.fontsize\": 11})\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2) 유틸\n",
        "# ============================================================\n",
        "EPS = 1e-12\n",
        "\n",
        "def clean_conc(arr, allow_zero=True, drop_nonfinite=True):\n",
        "    \"\"\"\n",
        "    전처리 유틸\n",
        "    - drop_nonfinite=True  : 피팅/진단용 → finite만 남기고 길이 줄어들 수 있음\n",
        "    - drop_nonfinite=False : MC/LECR용(권장) → 길이 유지, non-finite는 0으로 치환\n",
        "\n",
        "    allow_zero:\n",
        "      - True  : 0 허용(음수는 0으로 치환)\n",
        "      - False : 0도 불허(>0만 유지)\n",
        "    \"\"\"\n",
        "    x = np.asarray(arr, float)\n",
        "\n",
        "    if drop_nonfinite:\n",
        "        x = x[np.isfinite(x)]\n",
        "        if allow_zero:\n",
        "            x = x[x >= 0]\n",
        "        else:\n",
        "            x = x[x > 0]\n",
        "        return x\n",
        "\n",
        "    x = np.where(np.isfinite(x), x, 0.0)\n",
        "\n",
        "    if allow_zero:\n",
        "        x = np.maximum(x, 0.0)\n",
        "        return x\n",
        "    else:\n",
        "        x = x[x > 0]\n",
        "        return x\n",
        "\n",
        "def bic_from_loglik(loglik, n, k_params):\n",
        "    n = max(int(n), 1)\n",
        "    return float(-2.0*float(loglik) + float(k_params)*np.log(n))\n",
        "\n",
        "def safe_logsum(x):\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[np.isfinite(x)]\n",
        "    if x.size == 0:\n",
        "        return np.nan\n",
        "    return float(np.sum(x))\n",
        "\n",
        "def freedman_diaconis_bins(x, min_bins=30, max_bins=70):\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[np.isfinite(x)]\n",
        "    n = x.size\n",
        "    if n < 2:\n",
        "        return max(2, min_bins)\n",
        "    q75, q25 = np.percentile(x, [75, 25])\n",
        "    iqr = q75 - q25\n",
        "    if iqr <= 0:\n",
        "        return max(min_bins, min(max_bins, int(np.sqrt(n))))\n",
        "    h = 2 * iqr * (n ** (-1/3))\n",
        "    if h <= 0:\n",
        "        return max(min_bins, min(max_bins, int(np.sqrt(n))))\n",
        "    bins = int(np.ceil((x.max() - x.min()) / h))\n",
        "    return max(2, max(min_bins, min(max_bins, bins)))\n",
        "\n",
        "def coerce_numeric_with_mdl(s):\n",
        "    s = pd.Series(s).astype(str).str.strip().str.replace(',', '', regex=False)\n",
        "    m = s.str.match(r'^[<≤]\\s*([0-9]*\\.?[0-9]+)$')\n",
        "    if m.any():\n",
        "        vals = s[m].str.replace('≤','<',regex=False).str.replace('<','',regex=False).astype(float).values\n",
        "        if MDL_POLICY == 'half':\n",
        "            s.loc[m] = (vals/2.0)\n",
        "        elif MDL_POLICY == 'nan':\n",
        "            s.loc[m] = np.nan\n",
        "        elif MDL_POLICY == 'uniform':\n",
        "            u = _mdl_rs.uniform(0.0, 1.0, size=len(vals))\n",
        "            s.loc[m] = vals * u\n",
        "        else:\n",
        "            s.loc[m] = (vals/2.0)\n",
        "    s = s.replace({'ND':np.nan,'N.D.':np.nan,'MDL':np.nan,'BDL':np.nan,'-':np.nan,'--':np.nan,'':np.nan}, regex=False)\n",
        "    return pd.to_numeric(s, errors='coerce')\n",
        "\n",
        "def hist_mode_estimate(x):\n",
        "    x=np.asarray(x,float)\n",
        "    x=x[np.isfinite(x)]\n",
        "    if x.size<2:\n",
        "        return float(np.nanmedian(x)) if x.size else np.nan\n",
        "    iqr=np.subtract(*np.percentile(x,[75,25]))\n",
        "    bins=max(10,int(np.sqrt(x.size))) if iqr<=0 else max(10,int(np.ceil((x.max()-x.min())/(2*iqr*x.size**(-1/3)))))\n",
        "    cnt,edges=np.histogram(x,bins=bins)\n",
        "    i=int(cnt.argmax())\n",
        "    return float((edges[i]+edges[i+1])/2)\n",
        "\n",
        "def apply_pretty_xticks(ax, min_ticks=4, max_ticks=7):\n",
        "    x_lo, x_hi = ax.get_xlim()\n",
        "    if not np.isfinite(x_lo) or not np.isfinite(x_hi) or x_hi <= x_lo:\n",
        "        return\n",
        "    base = np.array([1.0, 2.0, 2.5, 5.0])\n",
        "    steps=[]\n",
        "    for k in range(-6, 2):\n",
        "        steps.extend(base*(10.0**k))\n",
        "    steps=np.array(sorted(steps))\n",
        "    best_step, best_diff = None, None\n",
        "    for step in steps:\n",
        "        if step<=0: continue\n",
        "        start=np.ceil(x_lo/step)*step\n",
        "        end=np.floor(x_hi/step)*step\n",
        "        if end<start: continue\n",
        "        n_ticks=int(np.floor((end-start)/step))+1\n",
        "        if min_ticks<=n_ticks<=max_ticks:\n",
        "            best_step=step\n",
        "            break\n",
        "        diff=(min_ticks-n_ticks) if (n_ticks<min_ticks) else (n_ticks-max_ticks)\n",
        "        if (best_diff is None) or (diff<best_diff):\n",
        "            best_diff=diff\n",
        "            best_step=step\n",
        "    if best_step is None: return\n",
        "    step=best_step\n",
        "    start=np.ceil(x_lo/step)*step\n",
        "    end=np.floor(x_hi/step)*step\n",
        "    if end<start: return\n",
        "    ticks=np.arange(start, end+step*0.5, step)\n",
        "    ticks[np.isclose(ticks,0.0,atol=step*0.01)]=0.0\n",
        "    ax.set_xticks(ticks)\n",
        "    def _smart_fmt(v, pos):\n",
        "        s=f\"{v:.6f}\".rstrip('0').rstrip('.')\n",
        "        return \"0\" if s in (\"\",\"-0\") else s\n",
        "    ax.xaxis.set_major_formatter(FuncFormatter(_smart_fmt))\n",
        "    ax.grid(True, alpha=0.25)\n",
        "\n",
        "# ============================================================\n",
        "# 히스토그램 기반 bimodal 진단\n",
        "# ============================================================\n",
        "def is_bimodal_hist(x_pos: np.ndarray,\n",
        "                    nbins: int = 40,\n",
        "                    smooth_k: int = 3,\n",
        "                    peak_min_frac: float = 0.10,\n",
        "                    min_sep_frac_iqr: float = 0.25,\n",
        "                    return_info: bool = False):\n",
        "    \"\"\"\n",
        "    x_pos: 양수 샘플 (log 변환 전 원공간)\n",
        "    nbins: 히스토그램 bin 수\n",
        "    smooth_k: 이동평균 스무딩 window\n",
        "    peak_min_frac: 최대 높이 대비 최소 피크 비율 (가짜 잡음 피크 제거)\n",
        "    min_sep_frac_iqr: 피크 간 최소 간격(IQR 비율) 기준\n",
        "    \"\"\"\n",
        "    x = np.asarray(x_pos, float)\n",
        "    x = x[np.isfinite(x) & (x > 0)]\n",
        "    info = {\n",
        "        \"is_bimodal\": False,\n",
        "        \"n_peaks\": 0,\n",
        "        \"peaks_x\": [],\n",
        "        \"peaks_counts\": [],\n",
        "        \"max_count\": 0.0,\n",
        "        \"rule\": \"insufficient_data\",\n",
        "        \"nbins\": nbins}\n",
        "    if x.size < 10:\n",
        "        if return_info:\n",
        "            return False, info\n",
        "        return False\n",
        "\n",
        "    counts, edges = np.histogram(x, bins=nbins)\n",
        "    if counts.max() <= 0:\n",
        "        info[\"rule\"] = \"all_zero_hist\"\n",
        "        if return_info:\n",
        "            return False, info\n",
        "        return False\n",
        "\n",
        "    # --- 간단 스무딩 (이동평균) ---\n",
        "    if smooth_k > 1:\n",
        "        k = smooth_k\n",
        "        pad = k // 2\n",
        "        padded = np.pad(counts, pad_width=pad, mode=\"edge\")\n",
        "        smooth = np.convolve(padded, np.ones(k)/k, mode=\"valid\")\n",
        "    else:\n",
        "        smooth = counts.astype(float)\n",
        "\n",
        "    max_c = float(smooth.max())\n",
        "    info[\"max_count\"] = max_c\n",
        "    if max_c <= 0:\n",
        "        info[\"rule\"] = \"all_zero_smooth\"\n",
        "        if return_info:\n",
        "            return False, info\n",
        "        return False\n",
        "\n",
        "    # --- 피크 탐지 (local maxima) ---\n",
        "    peak_idx = []\n",
        "    peak_vals = []\n",
        "    for i in range(1, len(smooth)-1):\n",
        "        if smooth[i] >= smooth[i-1] and smooth[i] >= smooth[i+1]:\n",
        "            if smooth[i] >= peak_min_frac * max_c:\n",
        "                peak_idx.append(i)\n",
        "                peak_vals.append(smooth[i])\n",
        "\n",
        "    if not peak_idx:\n",
        "        info[\"rule\"] = \"no_peak\"\n",
        "        if return_info:\n",
        "            return False, info\n",
        "\n",
        "    # 피크 위치 (x 좌표는 bin center)\n",
        "    centers = 0.5 * (edges[:-1] + edges[1:])\n",
        "    peaks_x = [float(centers[i]) for i in peak_idx]\n",
        "\n",
        "    info[\"n_peaks\"] = len(peak_idx)\n",
        "    info[\"peaks_x\"] = peaks_x\n",
        "    info[\"peaks_counts\"] = [float(v) for v in peak_vals]\n",
        "\n",
        "    if len(peak_idx) < 2:\n",
        "        info[\"rule\"] = \"single_peak\"\n",
        "        if return_info:\n",
        "            return False, info\n",
        "\n",
        "    # --- 피크 간 거리 기준 (IQR 기반) ---\n",
        "    q1, q3 = np.percentile(x, [25, 75])\n",
        "    iqr = max(q3 - q1, 1e-12)\n",
        "    min_sep = min_sep_frac_iqr * iqr\n",
        "\n",
        "    peaks_x_sorted = np.sort(peaks_x)\n",
        "    sep_ok = any(\n",
        "        (peaks_x_sorted[j+1] - peaks_x_sorted[j]) >= min_sep\n",
        "        for j in range(len(peaks_x_sorted)-1))\n",
        "\n",
        "    if sep_ok:\n",
        "        info[\"is_bimodal\"] = True\n",
        "        info[\"rule\"] = (\n",
        "            f\"n_peaks>={len(peak_idx)}, \"\n",
        "            f\"max_count={max_c:.2f}, \"\n",
        "            f\"peak_min_frac={peak_min_frac}, \"\n",
        "            f\"min_sep>={min_sep_frac_iqr}*IQR\")\n",
        "        if return_info:\n",
        "            return True, info\n",
        "        return True\n",
        "    else:\n",
        "        info[\"is_bimodal\"] = False\n",
        "        info[\"rule\"] = \"peaks_exist_but_too_close\"\n",
        "        if return_info:\n",
        "            return False, info\n",
        "        return False\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3) 파일 업로드 & 시트 자동 선택\n",
        "# ============================================================\n",
        "def load_excel_auto_sheet():\n",
        "    print(\"엑셀 파일 업로드(.xlsx/.xls)\")\n",
        "    up = files.upload()\n",
        "    INPUT = next((k for k in up if k.lower().endswith(('.xlsx','.xls'))), None)\n",
        "    if INPUT is None:\n",
        "        cand = sorted(glob.glob(\"*.xlsx\"))\n",
        "        if not cand:\n",
        "            raise FileNotFoundError(\"엑셀 파일을 찾지 못했습니다.\")\n",
        "        INPUT = cand[-1]\n",
        "    xls = pd.ExcelFile(INPUT)\n",
        "    sheet_scores=[]\n",
        "    for sh in xls.sheet_names:\n",
        "        try:\n",
        "            df_head = pd.read_excel(INPUT, sheet_name=sh, nrows=3)\n",
        "        except Exception:\n",
        "            df_head = pd.DataFrame()\n",
        "        score=0\n",
        "        for c in df_head.columns:\n",
        "            s=str(c)\n",
        "            score += sum(bool(re.search(p, s, flags=re.I)) for p in PAT.values())\n",
        "        sheet_scores.append((sh,score))\n",
        "    sheet_scores.sort(key=lambda x:x[1], reverse=True)\n",
        "    SHEET = sheet_scores[0][0]\n",
        "    raw = pd.read_excel(INPUT, sheet_name=SHEET)\n",
        "    print(f\"선택된 파일: {INPUT}\")\n",
        "    print(f\"선택된 시트: {SHEET}\")\n",
        "    return raw, INPUT, SHEET\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3) 단위 통일 & 열 자동 매칭\n",
        "# ============================================================\n",
        "def find_col(df, regex):\n",
        "    for c in df.columns:\n",
        "        if re.search(regex, str(c), flags=re.I):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def to_ug(series, header_name):\n",
        "    header = str(header_name)\n",
        "    s = coerce_numeric_with_mdl(series).replace([np.inf, -np.inf], np.nan)\n",
        "    has_ug = bool(re.search(r'(?i)[µμu]\\s*g\\s*/?\\s*m\\^?3', header))\n",
        "    has_ng = bool(re.search(r'(?i)n\\s*g\\s*/?\\s*m\\^?3', header))\n",
        "    if has_ug:\n",
        "        return (s, 'as_is_ug')\n",
        "    if has_ng:\n",
        "        return (s/1000.0, 'converted_from_ng')\n",
        "    return (s, 'as_is_ug')\n",
        "\n",
        "def build_series_map(raw):\n",
        "    series_map, log_rows = {}, []\n",
        "    for m in ORDER:\n",
        "        if m in EXCLUDE_SET:\n",
        "            log_rows.append((m, None, 'excluded_by_user', 0, np.nan))\n",
        "            continue\n",
        "        c = find_col(raw, PAT.get(m, r\"^\"))\n",
        "        if c is None:\n",
        "            log_rows.append((m, None, 'missing', 0, np.nan))\n",
        "            continue\n",
        "        v, how = to_ug(raw[c], c)\n",
        "        series_map[m]=v\n",
        "        n_nonna = int(pd.to_numeric(v, errors='coerce').notna().sum())\n",
        "        log_rows.append((m, c, how, n_nonna, float(np.nanmean(v)) if n_nonna>0 else np.nan))\n",
        "\n",
        "    log_df = pd.DataFrame(log_rows, columns=['Metal','Matched_Column','Unit_Status','N_nonNa','Mean(ug/m3)'])\n",
        "\n",
        "    if ('Cr(VI)' not in series_map):\n",
        "        c_col = find_col(raw, PAT.get(\"Cr\", r\"^\"))\n",
        "        if c_col is not None:\n",
        "            cr_series, _ = to_ug(raw[c_col], c_col)\n",
        "            series_map['Cr(VI)'] = cr_series/7.0\n",
        "            log_df.loc[len(log_df)] = [\n",
        "                'Cr(VI)','(derived from Cr/7 even if Cr excluded)','derived',\n",
        "                int(pd.to_numeric(series_map['Cr(VI)'],errors='coerce').notna().sum()),\n",
        "                float(np.nanmean(series_map['Cr(VI)']))]\n",
        "\n",
        "    print(\"\\n[DEBUG] 유효 표본수(원자료, NaN 제외) 요약:\",\n",
        "          {m:int(pd.to_numeric(series_map[m],errors='coerce').notna().sum()) for m in series_map})\n",
        "    return series_map, log_df\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4) 분포 클래스 (14개 + GMM(Log))\n",
        "# ============================================================\n",
        "class D:\n",
        "    def __init__(self,name):\n",
        "        self.name=name\n",
        "        self.p={}\n",
        "        self.np=None\n",
        "        self.valid=False\n",
        "    def ok(self,p,np_):\n",
        "        self.p=p\n",
        "        self.np=np_\n",
        "        self.valid=True\n",
        "        return self\n",
        "    def cdf(self,z): raise NotImplementedError\n",
        "    def ppf(self,q): raise NotImplementedError\n",
        "    def rvs(self,n,rs=None): raise NotImplementedError\n",
        "    def logpdf(self, x): raise NotImplementedError\n",
        "\n",
        "class LogNormal(D):\n",
        "    def __init__(self): super().__init__('로그 정규')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=False)\n",
        "        if x.size<3: return self\n",
        "        try: s,loc,sc=lognorm.fit(x)\n",
        "        except: return self\n",
        "        if s>0 and sc>0 and np.isfinite(loc): return self.ok({'s':s,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return lognorm.cdf(z, s=self.p['s'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return lognorm.ppf(q, s=self.p['s'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return lognorm.rvs(self.p['s'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "    def logpdf(self,x): return lognorm.logpdf(x, s=self.p['s'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "\n",
        "class Weibull(D):\n",
        "    def __init__(self): super().__init__('와이블')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: c,loc,sc=weibull_min.fit(x)\n",
        "        except: return self\n",
        "        if c>0 and sc>0 and np.isfinite(loc): return self.ok({'c':c,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return weibull_min.cdf(z, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return weibull_min.ppf(q, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return weibull_min.rvs(self.p['c'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "    def logpdf(self,x): return weibull_min.logpdf(x, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "\n",
        "class Gamma_(D):\n",
        "    def __init__(self): super().__init__('감마')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: a,loc,sc=gamma.fit(x)\n",
        "        except: return self\n",
        "        if a>0 and sc>0 and np.isfinite(loc): return self.ok({'a':a,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return gamma.cdf(z, a=self.p['a'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return gamma.ppf(q, a=self.p['a'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return gamma.rvs(self.p['a'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "    def logpdf(self,x): return gamma.logpdf(x, a=self.p['a'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "\n",
        "class LogisticD(D):\n",
        "    def __init__(self): super().__init__('로지스틱')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=logistic.fit(x)\n",
        "        except: return self\n",
        "        if sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return logistic.cdf(z, **self.p)\n",
        "    def ppf(self,q): return logistic.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return logistic.rvs(size=n, **self.p, random_state=rs)\n",
        "    def logpdf(self,x): return logistic.logpdf(x, **self.p)\n",
        "\n",
        "class NormalD(D):\n",
        "    def __init__(self): super().__init__('정규')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: mu,sig=norm.fit(x)\n",
        "        except: return self\n",
        "        if sig>0: return self.ok({'loc':mu,'scale':sig},2)\n",
        "        return self\n",
        "    def cdf(self,z): return norm.cdf(z, **self.p)\n",
        "    def ppf(self,q): return norm.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return norm.rvs(size=n, **self.p, random_state=rs)\n",
        "    def logpdf(self,x): return norm.logpdf(x, **self.p)\n",
        "\n",
        "class StudentT(D):\n",
        "    def __init__(self): super().__init__('스튜던트의 t')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: df_,loc,sc=student_t.fit(x)\n",
        "        except: return self\n",
        "        if df_>0 and sc>0: return self.ok({'df':df_,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return student_t.cdf(z, **self.p)\n",
        "    def ppf(self,q): return student_t.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return student_t.rvs(size=n, **self.p, random_state=rs)\n",
        "    def logpdf(self,x): return student_t.logpdf(x, **self.p)\n",
        "\n",
        "class Exponential_(D):\n",
        "    def __init__(self): super().__init__('지수')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=expon.fit(x)\n",
        "        except: return self\n",
        "        if sc>0 and np.isfinite(loc): return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return expon.cdf(z, loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return expon.ppf(q, loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return expon.rvs(size=n, loc=self.p['loc'], scale=self.p['scale'], random_state=rs)\n",
        "    def logpdf(self,x): return expon.logpdf(x, loc=self.p['loc'], scale=self.p['scale'])\n",
        "\n",
        "class BetaPERT_(D):\n",
        "    def __init__(self,lam=4.0): super().__init__('BetaPERT'); self.lam=lam\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        a,b=float(np.nanmin(x)),float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        m=float(np.clip(hist_mode_estimate(x), a+1e-9, b-1e-9))\n",
        "        al=1+self.lam*(m-a)/(b-a); be=1+self.lam*(b-m)/(b-a)\n",
        "        if al<=0 or be<=0: return self\n",
        "        return self.ok({'a':a,'b':b,'alpha':al,'beta':be,'m':m},2)\n",
        "    def cdf(self,z):\n",
        "        zz=(z-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        return beta.cdf(np.clip(zz,EPS,1-EPS), self.p['alpha'], self.p['beta'])\n",
        "    def ppf(self,q): return self.p['a']+(self.p['b']-self.p['a'])*beta.ppf(q, self.p['alpha'], self.p['beta'])\n",
        "    def rvs(self,n,rs=None):\n",
        "        r=beta.rvs(self.p['alpha'], self.p['beta'], size=n, random_state=rs)\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*r\n",
        "    def logpdf(self,x):\n",
        "        x=np.asarray(x,float)\n",
        "        zz=(x-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        zz=np.clip(zz,EPS,1-EPS)\n",
        "        return beta.logpdf(zz, self.p['alpha'], self.p['beta']) - np.log(self.p['b']-self.p['a'])\n",
        "\n",
        "class Triangular_(D):\n",
        "    def __init__(self): super().__init__('삼각형')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        a,b=float(np.nanmin(x)),float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        m=float(np.clip(hist_mode_estimate(x), a+1e-9, b-1e-9))\n",
        "        c=(m-a)/(b-a)\n",
        "        if not(0.0 < c < 1.0): return self\n",
        "        return self.ok({'c':c,'loc':a,'scale':(b-a)},2)\n",
        "    def cdf(self,z): return triang.cdf(z, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return triang.ppf(q, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return triang.rvs(self.p['c'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "    def logpdf(self,x): return triang.logpdf(x, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "\n",
        "class Uniform_(D):\n",
        "    def __init__(self): super().__init__('균일')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<2: return self\n",
        "        a=float(np.nanmin(x)); b=float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        return self.ok({'loc':a,'scale':(b-a)},2)\n",
        "    def cdf(self,z): return uniform.cdf(z, **self.p)\n",
        "    def ppf(self,q): return uniform.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return uniform.rvs(size=n, **self.p, random_state=rs)\n",
        "    def logpdf(self,x): return uniform.logpdf(x, **self.p)\n",
        "\n",
        "class GumbelR_(D):\n",
        "    def __init__(self): super().__init__('최대 극값')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=gumbel_r.fit(x)\n",
        "        except: return self\n",
        "        if np.isfinite(loc) and sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return gumbel_r.cdf(z, **self.p)\n",
        "    def ppf(self,q): return gumbel_r.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return gumbel_r.rvs(size=n, **self.p, random_state=rs)\n",
        "    def logpdf(self,x): return gumbel_r.logpdf(x, **self.p)\n",
        "\n",
        "class GumbelL_(D):\n",
        "    def __init__(self): super().__init__('최소 극값')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=gumbel_l.fit(x)\n",
        "        except: return self\n",
        "        if np.isfinite(loc) and sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return gumbel_l.cdf(z, **self.p)\n",
        "    def ppf(self,q): return gumbel_l.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return gumbel_l.rvs(size=n, **self.p, random_state=rs)\n",
        "    def logpdf(self,x): return gumbel_l.logpdf(x, **self.p)\n",
        "\n",
        "class Beta_(D):\n",
        "    def __init__(self): super().__init__('베타')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        a=float(np.nanmin(x)); b=float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        z=np.clip((x-a)/(b-a), EPS, 1-EPS)\n",
        "        try: al,be,_,_ = beta.fit(z, floc=0, fscale=1)\n",
        "        except: return self\n",
        "        if (al>0) and (be>0): return self.ok({'a':a,'b':b,'alpha':al,'beta':be},2)\n",
        "        return self\n",
        "    def cdf(self,z):\n",
        "        zz=(z-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        return beta.cdf(np.clip(zz,EPS,1-EPS), self.p['alpha'], self.p['beta'])\n",
        "    def ppf(self,q):\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*beta.ppf(q, self.p['alpha'], self.p['beta'])\n",
        "    def rvs(self,n,rs=None):\n",
        "        r=beta.rvs(self.p['alpha'], self.p['beta'], size=n, random_state=rs)\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*r\n",
        "    def logpdf(self,x):\n",
        "        x=np.asarray(x,float)\n",
        "        zz=(x-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        zz=np.clip(zz,EPS,1-EPS)\n",
        "        return beta.logpdf(zz, self.p['alpha'], self.p['beta']) - np.log(self.p['b']-self.p['a'])\n",
        "\n",
        "class Pareto_(D):\n",
        "    def __init__(self): super().__init__('파레토')\n",
        "    def fit(self,x):\n",
        "        x=clean_conc(x, allow_zero=True)\n",
        "        if x.size<3: return self\n",
        "        try: b,loc,sc=pareto.fit(x)\n",
        "        except: return self\n",
        "        if b>0 and sc>0 and np.isfinite(loc): return self.ok({'b':b,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return pareto.cdf(z, b=self.p['b'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return pareto.ppf(q, b=self.p['b'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return pareto.rvs(self.p['b'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "    def logpdf(self,x): return pareto.logpdf(x, b=self.p['b'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "\n",
        "# ---- GMM(Log) ----\n",
        "class GMMLog(D):\n",
        "    def __init__(self, K_list=(1,2,3), max_iter=500, reg_covar=1e-6, random_state=20250912, eps=1e-12):\n",
        "        super().__init__('GMM(Log)')\n",
        "        self.K_list = tuple(K_list)\n",
        "        self.max_iter = int(max_iter)\n",
        "        self.reg_covar = float(reg_covar)\n",
        "        self.random_state = int(random_state)\n",
        "        self.eps = float(eps)\n",
        "\n",
        "    def fit(self, x):\n",
        "        if (not _SKLEARN_OK):\n",
        "            return self\n",
        "\n",
        "        x = clean_conc(x, allow_zero=False)\n",
        "        if x.size < GMM_MIN_N:\n",
        "            return self\n",
        "\n",
        "        floor = np.percentile(x, GMM_FLOOR_Q) if x.size > 0 else 0.0\n",
        "        floor = max(float(floor), 1e-30)\n",
        "        x_fit = x[x >= floor]\n",
        "        if x_fit.size < GMM_MIN_N:\n",
        "            return self\n",
        "\n",
        "        y = np.log(x_fit + self.eps).reshape(-1, 1)\n",
        "\n",
        "        gmms = []\n",
        "        for K in self.K_list:\n",
        "            if K < 1:\n",
        "                continue\n",
        "            try:\n",
        "                gmm = GaussianMixture(\n",
        "                    n_components=int(K),\n",
        "                    covariance_type='full',\n",
        "                    max_iter=self.max_iter,\n",
        "                    reg_covar=self.reg_covar,\n",
        "                    random_state=self.random_state,\n",
        "                    n_init=5)\n",
        "                gmm.fit(y)\n",
        "                bic_s = gmm.bic(y)\n",
        "                if np.isfinite(bic_s):\n",
        "                    gmms.append((int(K), gmm, float(bic_s)))\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        if not gmms:\n",
        "            return self\n",
        "\n",
        "        bic_min = min(b for (_, _, b) in gmms)\n",
        "        cand = [(K, g, b) for (K, g, b) in gmms if b <= bic_min + float(GMM_K_BIC_TOL)]\n",
        "        cand.sort(key=lambda t: (t[0], t[2]))\n",
        "        K, best_gmm, best_bic_sklearn = cand[0]\n",
        "\n",
        "        w = np.asarray(best_gmm.weights_, float).reshape(-1)\n",
        "        mu = np.asarray(best_gmm.means_, float).reshape(-1)\n",
        "\n",
        "        cov = np.asarray(best_gmm.covariances_, float)\n",
        "        if cov.ndim == 3:\n",
        "            var = cov[:, 0, 0]\n",
        "        elif cov.ndim == 2 and cov.shape[1] == 1:\n",
        "            var = cov[:, 0]\n",
        "        else:\n",
        "            var = cov.reshape(-1)\n",
        "\n",
        "        sg = np.sqrt(np.maximum(var, 1e-12))\n",
        "        sg = np.maximum(sg, float(GMM_SIGMA_MIN))\n",
        "\n",
        "        if (K < 1) or np.any(~np.isfinite(w)) or np.any(~np.isfinite(mu)) or np.any(~np.isfinite(sg)):\n",
        "            return self\n",
        "        if np.any(sg <= 0) or np.any(w < 0):\n",
        "            return self\n",
        "\n",
        "        keep = (w >= GMM_W_MIN)\n",
        "        if keep.sum() >= 1 and keep.sum() < K:\n",
        "            w = w[keep]\n",
        "            mu = mu[keep]\n",
        "            sg = sg[keep]\n",
        "            K = int(len(w))\n",
        "\n",
        "        w = np.maximum(w, 0.0)\n",
        "        s = w.sum()\n",
        "        if s <= 0:\n",
        "            return self\n",
        "        w = w / s\n",
        "\n",
        "        self.ok(\n",
        "            {'K': K, 'weights': w.tolist(), 'mu': mu.tolist(), 'sigma': sg.tolist(),\n",
        "             'bic_sklearn': float(best_bic_sklearn), 'floor': float(floor)},\n",
        "            np_=(3*K - 1))\n",
        "        return self\n",
        "\n",
        "    def cdf(self, z):\n",
        "        z = np.asarray(z, float)\n",
        "        out = np.zeros_like(z, float)\n",
        "\n",
        "        if not self.valid:\n",
        "            return np.full_like(z, np.nan, float)\n",
        "\n",
        "        w = np.asarray(self.p['weights'], float)\n",
        "        mu = np.asarray(self.p['mu'], float)\n",
        "        sg = np.asarray(self.p['sigma'], float)\n",
        "        K = int(self.p['K'])\n",
        "\n",
        "        mask = np.isfinite(z) & (z > 0)\n",
        "        out[~np.isfinite(z)] = np.nan\n",
        "        out[z <= 0] = 0.0\n",
        "\n",
        "        if not np.any(mask):\n",
        "            return out\n",
        "\n",
        "        zz = z[mask]\n",
        "        y = np.log(zz + self.eps)\n",
        "\n",
        "        c = np.zeros_like(y, float)\n",
        "        for i in range(K):\n",
        "            c += w[i] * norm.cdf((y - mu[i]) / sg[i])\n",
        "\n",
        "        out[mask] = np.clip(c, 0.0, 1.0)\n",
        "        return out\n",
        "\n",
        "    def ppf(self, q):\n",
        "        if not self.valid:\n",
        "            q_arr = np.asarray(q, float)\n",
        "            return np.nan if q_arr.ndim == 0 else np.full_like(q_arr, np.nan, dtype=float)\n",
        "\n",
        "        q_arr = np.asarray(q, float)\n",
        "        scalar_input = (q_arr.ndim == 0)\n",
        "        out = np.full(q_arr.shape, np.nan, dtype=float)\n",
        "\n",
        "        finite = np.isfinite(q_arr)\n",
        "        qv = q_arr.copy()\n",
        "        qv[~finite] = np.nan\n",
        "\n",
        "        out[(finite) & (qv <= 0.0)] = 0.0\n",
        "        out[(finite) & (qv >= 1.0)] = np.inf\n",
        "\n",
        "        mask_mid = (finite) & (qv > 0.0) & (qv < 1.0)\n",
        "        if not np.any(mask_mid):\n",
        "            return float(out) if scalar_input else out\n",
        "\n",
        "        mu = np.asarray(self.p['mu'], float)\n",
        "        sg = np.asarray(self.p['sigma'], float)\n",
        "\n",
        "        lo_y0 = float(np.min(mu - 10.0 * sg))\n",
        "        hi_y0 = float(np.max(mu + 10.0 * sg))\n",
        "        lo0 = max(float(np.exp(lo_y0)), 1e-30)\n",
        "        hi0 = max(float(np.exp(hi_y0)), lo0 * 1.01)\n",
        "\n",
        "        def F_scalar(x):\n",
        "            return float(self.cdf(np.array([x], float))[0])\n",
        "\n",
        "        def ppf_scalar(qs):\n",
        "            lo, hi = lo0, hi0\n",
        "            f_lo, f_hi = F_scalar(lo), F_scalar(hi)\n",
        "\n",
        "            it = 0\n",
        "            while (np.isfinite(f_lo) and f_lo > qs) and (it < 40):\n",
        "                hi, f_hi = lo, f_lo\n",
        "                lo = max(lo * 0.1, 1e-30)\n",
        "                f_lo = F_scalar(lo)\n",
        "                it += 1\n",
        "\n",
        "            it = 0\n",
        "            while (np.isfinite(f_hi) and f_hi < qs) and (it < 40):\n",
        "                lo, f_lo = hi, f_hi\n",
        "                hi = hi * 10.0\n",
        "                f_hi = F_scalar(hi)\n",
        "                it += 1\n",
        "\n",
        "            if (not np.isfinite(f_lo)) or (not np.isfinite(f_hi)) or (f_lo > qs) or (f_hi < qs):\n",
        "                return np.nan\n",
        "\n",
        "            for _ in range(100):\n",
        "                mid = np.sqrt(lo * hi)\n",
        "                f_mid = F_scalar(mid)\n",
        "                if not np.isfinite(f_mid):\n",
        "                    hi = mid\n",
        "                    continue\n",
        "                if f_mid < qs:\n",
        "                    lo = mid\n",
        "                else:\n",
        "                    hi = mid\n",
        "                if hi / lo - 1.0 < 1e-10:\n",
        "                    break\n",
        "            return float(np.sqrt(lo * hi))\n",
        "\n",
        "        qs_list = qv[mask_mid].ravel()\n",
        "        vals = np.array([ppf_scalar(float(qs)) for qs in qs_list], dtype=float)\n",
        "        out[mask_mid] = vals.reshape(out[mask_mid].shape)\n",
        "        return float(out) if scalar_input else out\n",
        "\n",
        "    def rvs(self, n, rs=None):\n",
        "        if (not self.valid) or (n <= 0):\n",
        "            return np.array([], float)\n",
        "\n",
        "        rs = rs if rs is not None else child_rs()\n",
        "\n",
        "        w = np.asarray(self.p['weights'], float)\n",
        "        mu = np.asarray(self.p['mu'], float)\n",
        "        sg = np.asarray(self.p['sigma'], float)\n",
        "        K = int(self.p['K'])\n",
        "\n",
        "        comp = rs.choice(np.arange(K), size=int(n), p=w)\n",
        "        y = np.zeros(int(n), float)\n",
        "        for k in range(K):\n",
        "            idx = np.where(comp == k)[0]\n",
        "            if idx.size == 0:\n",
        "                continue\n",
        "            y[idx] = rs.normal(loc=mu[k], scale=sg[k], size=idx.size)\n",
        "\n",
        "        out = np.exp(y)  # 원공간\n",
        "\n",
        "        # ---- floor 미만 재샘플링 ----\n",
        "        floor = float(self.p.get(\"floor\", 0.0))\n",
        "        if floor > 0:\n",
        "            mask = out < floor\n",
        "            tries = 0\n",
        "            while mask.any() and tries < 20:\n",
        "                comp2 = comp[mask]\n",
        "                y2 = rs.normal(loc=mu[comp2], scale=sg[comp2], size=comp2.size)\n",
        "                out[mask] = np.exp(y2)\n",
        "                mask = out < floor\n",
        "                tries += 1\n",
        "            if mask.any():\n",
        "                out[mask] = floor\n",
        "\n",
        "        return out\n",
        "\n",
        "    def logpdf(self, x):\n",
        "        if not self.valid:\n",
        "            return np.full_like(np.asarray(x,float), np.nan, dtype=float)\n",
        "\n",
        "        x = np.asarray(x, float)\n",
        "        out = np.full_like(x, np.nan, dtype=float)\n",
        "        mask = np.isfinite(x) & (x > 0)\n",
        "        if not np.any(mask):\n",
        "            return out\n",
        "\n",
        "        xm = x[mask]\n",
        "        w = np.asarray(self.p['weights'], float)\n",
        "        mu = np.asarray(self.p['mu'], float)\n",
        "        sg = np.asarray(self.p['sigma'], float)\n",
        "        K  = int(self.p['K'])\n",
        "\n",
        "        y = np.log(xm + self.eps)\n",
        "        pdf = np.zeros_like(xm, float)\n",
        "        for i in range(K):\n",
        "            pdf += w[i] * (1.0/(xm*sg[i]*np.sqrt(2*np.pi))) * np.exp(-0.5*((y-mu[i])/sg[i])**2)\n",
        "        pdf = np.maximum(pdf, 1e-300)\n",
        "        out[mask] = np.log(pdf)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5) 적합도 통계\n",
        "# ============================================================\n",
        "def AD_stat(x, cdf, eps=1e-12):\n",
        "    x=np.sort(np.asarray(x,float))\n",
        "    n=x.size\n",
        "    if n<5:\n",
        "        return np.inf\n",
        "    u=np.clip(cdf(x),eps,1-eps)\n",
        "    i=np.arange(1,n+1)\n",
        "    return float(-n - np.sum((2*i-1)*(np.log(u)+np.log(1-u[::-1])))/n)\n",
        "\n",
        "def _clone_dist_for_bootstrap(d0):\n",
        "    if isinstance(d0, GMMLog):\n",
        "        return GMMLog(K_list=d0.K_list, max_iter=d0.max_iter, reg_covar=d0.reg_covar, random_state=d0.random_state, eps=d0.eps)\n",
        "    if isinstance(d0, BetaPERT_):\n",
        "        return BetaPERT_(lam=d0.lam)\n",
        "    return type(d0)()\n",
        "\n",
        "def AD_p_boot_refit(x, dist_obj, B=BOOTSTRAP_B):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "    n=x.size\n",
        "    if n<5 or (not dist_obj.valid):\n",
        "        return np.nan\n",
        "    A2_obs=AD_stat(x, dist_obj.cdf)\n",
        "    ge=0; m=0\n",
        "    for _ in range(B):\n",
        "        rs=child_rs()\n",
        "        xs=dist_obj.rvs(n, rs=rs)\n",
        "        d=_clone_dist_for_bootstrap(dist_obj)\n",
        "        d.fit(xs)\n",
        "        if not d.valid:\n",
        "            continue\n",
        "        A2_bs=AD_stat(xs, d.cdf)\n",
        "        ge+=(A2_bs>=A2_obs)\n",
        "        m+=1\n",
        "    return float((ge+1)/(m+1)) if m>0 else np.nan\n",
        "\n",
        "def KS_stat_p(x, d):\n",
        "    try:\n",
        "        Dv, p = kstest(x, lambda z: d.cdf(z))\n",
        "        return float(Dv), float(p)\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def Chi2_stat_p(x, d):\n",
        "    if isinstance(d, GMMLog) or (getattr(d, \"name\", \"\") == \"GMM(Log)\"):\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    try:\n",
        "        x = np.asarray(x, float)\n",
        "        x = x[np.isfinite(x)]\n",
        "        n = len(x)\n",
        "        if n < 10:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        N = max(5, min(50, n // 5))\n",
        "        eps = 1e-6\n",
        "\n",
        "        qs = np.linspace(eps, 1 - eps, N + 1)\n",
        "        edges = d.ppf(qs)\n",
        "        edges = np.asarray(edges, float)\n",
        "        edges = edges[np.isfinite(edges)]\n",
        "        edges = np.unique(edges)\n",
        "        if len(edges) < 3:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        obs, _ = np.histogram(x, bins=edges)\n",
        "\n",
        "        c = d.cdf(edges)\n",
        "        c = np.clip(c, 0.0, 1.0)\n",
        "        exp = np.diff(c) * n\n",
        "\n",
        "        k = d.np or 0\n",
        "        df = len(obs) - 1 - k\n",
        "        if df <= 0:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        exp = np.maximum(exp, 1e-9)\n",
        "        chi = np.sum((obs - exp) ** 2 / exp)\n",
        "        p = 1.0 - chi2.cdf(chi, df)\n",
        "        return float(chi), float(p)\n",
        "\n",
        "    except Exception:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def pstr(name,p):\n",
        "    try:\n",
        "        if name=='정규':         return f\"평균={p['loc']:.5g}, 표준 편차={p['scale']:.5g}\"\n",
        "        if name=='로지스틱':     return f\"평균={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='최대 극값':    return f\"최고가능성={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='최소 극값':    return f\"최고가능성={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='지수':         return f\"위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='로그 정규':    return f\"형태={p['s']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='와이블':       return f\"형태={p['c']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='감마':         return f\"형태={p['a']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='스튜던트의 t': return f\"자유도={p['df']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='베타':         return f\"최소={p['a']:.5g}, 최대={p['b']:.5g}, 알파={p['alpha']:.5g}, 베타={p['beta']:.5g}\"\n",
        "        if name=='BetaPERT':     return f\"최소={p['a']:.5g}, 최빈값={p['m']:.5g}, 최대={p['b']:.5g}, 알파={p['alpha']:.5g}, 베타={p['beta']:.5g}\"\n",
        "        if name=='삼각형':       return f\"최소={p['loc']:.5g}, 최빈값={(p['loc']+p['c']*p['scale']):.5g}, 최대={(p['loc']+p['scale']):.5g}\"\n",
        "        if name=='균일':         return f\"최소={p['loc']:.5g}, 최대={(p['loc']+p['scale']):.5g}\"\n",
        "        if name=='파레토':       return f\"위치={p['loc']:.5g}, 스케일={p['scale']:.5g}, 형태={p['b']:.5g}\"\n",
        "\n",
        "        if name=='GMM(Log)':\n",
        "            K = int(p.get('K', 0)) if p.get('K', None) is not None else 0\n",
        "            w = np.asarray(p.get('weights', []), float)\n",
        "            mu = np.asarray(p.get('mu', []), float)\n",
        "            sg = np.asarray(p.get('sigma', []), float)\n",
        "\n",
        "            w_list  = np.round(w, 4).tolist() if w.size else []\n",
        "            mu_list = np.round(mu, 4).tolist() if mu.size else []\n",
        "            sg_list = np.round(sg, 4).tolist() if sg.size else []\n",
        "\n",
        "            bic_s = p.get('bic_sklearn', np.nan)\n",
        "            floor = p.get('floor', np.nan)\n",
        "\n",
        "            bic_s_str = f\"{float(bic_s):.3g}\" if np.isfinite(bic_s) else \"---\"\n",
        "            floor_str = f\"{float(floor):.3g}\" if np.isfinite(floor) else \"---\"\n",
        "\n",
        "            return (\n",
        "                f\"컴포넌트수(K)={K}, \"\n",
        "                f\"가중치(w)={w_list}, \"\n",
        "                f\"로그평균(mu)={mu_list}, \"\n",
        "                f\"로그표준편차(sigma)={sg_list}, \"\n",
        "                f\"K선정BIC={bic_s_str}, \"\n",
        "                f\"학습하한(floor)={floor_str}\")\n",
        "\n",
        "        return json.dumps(p, ensure_ascii=False)\n",
        "    except Exception:\n",
        "        return json.dumps(p, ensure_ascii=False)\n",
        "\n",
        "def compute_bic_for_obj(x, obj):\n",
        "    \"\"\"\n",
        "    (FIX-2) 모델 간 BIC 공정 비교를 위해 x는 항상 '양수(>0) & finite'로 통일한다.\n",
        "    - 0 또는 비양수 값에서 logpdf가 -inf/NaN 처리되어 n_eff가 모델마다 달라지는 문제 방지\n",
        "    \"\"\"\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[np.isfinite(x) & (x > 0)]\n",
        "\n",
        "    if x.size < 2 or (obj is None) or (not getattr(obj, \"valid\", False)):\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    try:\n",
        "        lp = np.asarray(obj.logpdf(x), float)\n",
        "    except Exception:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    finite = np.isfinite(lp)\n",
        "    if finite.sum() < 2:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    lp_eff = lp[finite]\n",
        "    n_eff = int(lp_eff.size)\n",
        "\n",
        "    ll = safe_logsum(lp_eff)\n",
        "    if not np.isfinite(ll):\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    k = int(obj.np) if (obj.np is not None and np.isfinite(obj.np)) else np.nan\n",
        "    if not np.isfinite(k) or k <= 0:\n",
        "        return np.nan, float(ll)\n",
        "\n",
        "    bic = bic_from_loglik(ll, n_eff, k)\n",
        "    return float(bic), float(ll)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6) 분포 피팅 & 랭킹 (GMM 포함) + BIC 산출\n",
        "# ============================================================\n",
        "def fit_one(x):\n",
        "    \"\"\"\n",
        "    (FIX-2) 적합도/비교 지표(AD/KS/Chi2/BIC)는 모두 x_pos(>0)로 통일.\n",
        "    \"\"\"\n",
        "    x = pd.Series(x, dtype=float).replace([np.inf, -np.inf], np.nan).dropna().values\n",
        "    x = clean_conc(x, allow_zero=True)\n",
        "\n",
        "    x_pos = clean_conc(x, allow_zero=False)\n",
        "\n",
        "    if x_pos.size < FIT_MIN_N:\n",
        "        return None\n",
        "    if np.unique(x_pos).size < 3:\n",
        "        return None\n",
        "\n",
        "    cands = [\n",
        "        LogNormal(), Gamma_(), Weibull(), LogisticD(), NormalD(), StudentT(),\n",
        "        Exponential_(), BetaPERT_(), Triangular_(), Uniform_(), GumbelR_(), GumbelL_(),\n",
        "        Beta_(), Pareto_()]\n",
        "    cands_gmm = [GMMLog(K_list=GMM_K_LIST)] if _SKLEARN_OK else []\n",
        "\n",
        "    rows = []\n",
        "    for d in (cands + cands_gmm):\n",
        "        d.fit(x_pos)\n",
        "\n",
        "        if not d.valid:\n",
        "            rows.append({'분포': d.name, 'AD': np.inf, 'ADp': np.nan, 'KS': np.nan, 'KSp': np.nan,\n",
        "                         'Chi2': np.nan, 'Chi2p': np.nan, 'np': 1e9, 'BIC': np.nan, 'loglik': np.nan, 'obj': d})\n",
        "            continue\n",
        "\n",
        "        A2  = AD_stat(x_pos, d.cdf)\n",
        "        pAD = AD_p_boot_refit(x_pos, d, BOOTSTRAP_B)\n",
        "        Dv, pks = KS_stat_p(x_pos, d)\n",
        "        chi, pchi = Chi2_stat_p(x_pos, d)\n",
        "\n",
        "        bic, ll = compute_bic_for_obj(x_pos, d)\n",
        "\n",
        "        rows.append({'분포': d.name, 'AD': A2, 'ADp': pAD, 'KS': Dv, 'KSp': pks,\n",
        "                     'Chi2': chi, 'Chi2p': pchi, 'np': d.np or 9, 'BIC': bic, 'loglik': ll, 'obj': d})\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    ksp_key  = -df['KSp'].fillna(-np.inf)\n",
        "    chi2_key = -df['Chi2p'].fillna(-np.inf)\n",
        "    df['_key'] = list(zip(df['AD'].fillna(np.inf), ksp_key, chi2_key, df['np'].fillna(np.inf)))\n",
        "    df = df.sort_values('_key', kind='mergesort').drop(columns=['_key']).reset_index(drop=True)\n",
        "\n",
        "    best_overall = df.iloc[0]\n",
        "\n",
        "    df_single = df[(df['분포'] != 'GMM(Log)') & (df['AD'].replace([np.inf], np.nan).notna())].copy()\n",
        "    best_single = df_single.sort_values('AD', kind='mergesort').iloc[0] if len(df_single) > 0 else None\n",
        "\n",
        "    df_gmm = df[(df['분포'] == 'GMM(Log)') & (df['AD'].replace([np.inf], np.nan).notna())].copy()\n",
        "    best_gmm = df_gmm.iloc[0] if (len(df_gmm) > 0 and df_gmm.iloc[0]['obj'].valid) else None\n",
        "\n",
        "    return best_overall, df, best_single, best_gmm\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7) 히스토그램 + 최적 PDF (단일 vs GMM 오버레이)\n",
        "# ============================================================\n",
        "def plot_hist_with_fit(ax, data, dist_obj, title, bins=None, dist_obj2=None, label2=None):\n",
        "    x = np.asarray(pd.to_numeric(data, errors='coerce'), float)\n",
        "    x = clean_conc(x, allow_zero=True)\n",
        "    n = x.size\n",
        "    ax.cla()\n",
        "\n",
        "    if n == 0:\n",
        "        ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=10)\n",
        "        ax.set_title(title); ax.set_xlabel(\"Concentration (µg/m³)\"); ax.set_ylabel(\"Frequency\")\n",
        "        ax.grid(True, alpha=0.25)\n",
        "        return\n",
        "\n",
        "    if float(np.nanmax(x)) == float(np.nanmin(x)):\n",
        "        v = float(np.nanmin(x))\n",
        "        span = max(abs(v)*0.1, 1e-6)\n",
        "        bins = 10\n",
        "        counts, edges, _ = ax.hist(x, bins=bins, density=False, alpha=0.5, edgecolor='k', range=(v-span, v+span))\n",
        "    else:\n",
        "        if (bins is None) or (isinstance(bins, int) and bins <= 0):\n",
        "            bins = freedman_diaconis_bins(x, 30, 70)\n",
        "        counts, edges, _ = ax.hist(x, bins=bins, density=False, alpha=0.5, edgecolor='k')\n",
        "\n",
        "    bin_width = float(np.diff(edges).mean()) if len(edges) > 1 else 1.0\n",
        "    if (not np.isfinite(bin_width)) or (bin_width <= 0):\n",
        "        bin_width = 1.0\n",
        "\n",
        "    # === 히스토그램 전체 구간 사용 ===\n",
        "    lo = float(edges[0])\n",
        "    hi = float(edges[-1])\n",
        "    pad = 2.0 * bin_width if np.isfinite(bin_width) and bin_width > 0 else 0.0\n",
        "    lo = max(0.0, lo - pad)\n",
        "    hi = hi + pad\n",
        "\n",
        "    if not (np.isfinite(lo) and np.isfinite(hi) and hi > lo):\n",
        "        lo, hi = float(np.nanmin(x)), float(np.nanmax(x))\n",
        "        if not (np.isfinite(lo) and np.isfinite(hi) and hi > lo):\n",
        "            lo, hi = 0.0, 1.0\n",
        "\n",
        "    xs = np.linspace(lo, hi, 800)\n",
        "\n",
        "    # ---- 단일분포 곡선 ----\n",
        "    if (dist_obj is not None) and getattr(dist_obj, 'valid', False):\n",
        "        pdf = None\n",
        "        try:\n",
        "            name = dist_obj.name; p = dist_obj.p\n",
        "            if name == '로그 정규':\n",
        "                pdf = lognorm.pdf(xs, s=p['s'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '와이블':\n",
        "                pdf = weibull_min.pdf(xs, c=p['c'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '감마':\n",
        "                pdf = gamma.pdf(xs, a=p['a'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '지수':\n",
        "                pdf = expon.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '최대 극값':\n",
        "                pdf = gumbel_r.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '최소 극값':\n",
        "                pdf = gumbel_l.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '정규':\n",
        "                pdf = norm.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '로지스틱':\n",
        "                pdf = logistic.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '스튜던트의 t':\n",
        "                pdf = student_t.pdf(xs, df=p['df'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name in ('베타','BetaPERT'):\n",
        "                zz = np.clip((xs - p['a'])/(p['b']-p['a']), EPS, 1 - EPS)\n",
        "                pdf = beta.pdf(zz, p['alpha'], p['beta']) / (p['b']-p['a'])\n",
        "            elif name == '삼각형':\n",
        "                pdf = triang.pdf(xs, c=p['c'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '균일':\n",
        "                pdf = uniform.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '파레토':\n",
        "                pdf = pareto.pdf(xs, b=p['b'], loc=p['loc'], scale=p['scale'])\n",
        "        except Exception:\n",
        "            pdf = None\n",
        "\n",
        "        if pdf is None:\n",
        "            cdf_vals = dist_obj.cdf(xs)\n",
        "            pdf = np.gradient(cdf_vals, xs)\n",
        "\n",
        "        pdf = np.nan_to_num(pdf, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        y_pdf = pdf * (n * bin_width)\n",
        "\n",
        "        disp_name = ENG_NAME.get(dist_obj.name, dist_obj.name)\n",
        "        color = DIST_COLOR.get(disp_name, None)\n",
        "        ax.plot(xs, y_pdf, lw=4, label=disp_name, color=color)\n",
        "\n",
        "    # ---- GMM 오버레이 ----\n",
        "    if (dist_obj2 is not None) and getattr(dist_obj2, 'valid', False):\n",
        "        try:\n",
        "            name2 = dist_obj2.name\n",
        "            pdf2 = None\n",
        "\n",
        "            if name2 == 'GMM(Log)':\n",
        "                xsp = np.maximum(xs, EPS)\n",
        "                y = np.log(xsp)\n",
        "                w = np.asarray(dist_obj2.p[\"weights\"], float)\n",
        "                mu = np.asarray(dist_obj2.p[\"mu\"], float)\n",
        "                sg = np.asarray(dist_obj2.p[\"sigma\"], float)\n",
        "                K  = int(dist_obj2.p[\"K\"])\n",
        "\n",
        "                pdf2 = np.zeros_like(xs, float)\n",
        "                for i in range(K):\n",
        "                    pdf2 += w[i] * (1.0/(xsp*sg[i]*np.sqrt(2*np.pi))) * np.exp(-0.5*((y-mu[i])/sg[i])**2)\n",
        "            else:\n",
        "                cdf2 = dist_obj2.cdf(xs)\n",
        "                pdf2 = np.gradient(cdf2, xs)\n",
        "\n",
        "            pdf2 = np.nan_to_num(pdf2, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "            y_pdf2 = pdf2 * (n * bin_width)\n",
        "\n",
        "            disp2 = label2 if label2 else ENG_NAME.get(dist_obj2.name, dist_obj2.name)\n",
        "            base_key = 'GMM(Log)' if ('GMM(Log)' in str(disp2)) else disp2\n",
        "            color2 = DIST_COLOR.get(base_key, None)\n",
        "\n",
        "            ax.plot(xs, y_pdf2, lw=3, linestyle='--', label=disp2, color=color2)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # === y축은 히스토그램 기준 ===\n",
        "    y_hist_max = float(np.max(counts)) if (counts is not None and len(counts)) else 1.0\n",
        "    if (not np.isfinite(y_hist_max)) or (y_hist_max <= 0):\n",
        "        y_hist_max = 1.0\n",
        "    ax.set_ylim(0, y_hist_max * 1.5)\n",
        "\n",
        "    ax.set_title(title, fontsize=17, fontweight='bold')\n",
        "    ax.set_xlabel(\"Concentration (µg/m³)\", fontsize=15, fontweight='bold')\n",
        "    ax.set_ylabel(\"Frequency\", fontsize=15, fontweight='bold')\n",
        "\n",
        "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
        "    for lab in (list(ax.get_xticklabels()) + list(ax.get_yticklabels())):\n",
        "        lab.set_fontweight('bold')\n",
        "\n",
        "    leg = ax.legend()\n",
        "    if leg is not None:\n",
        "        for txt in leg.get_texts():\n",
        "            txt.set_fontsize(14)\n",
        "            txt.set_fontweight('bold')\n",
        "\n",
        "    apply_pretty_xticks(ax, min_ticks=4, max_ticks=7)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8) 분포 피팅 수행\n",
        "# ============================================================\n",
        "def run_fitting(series_map):\n",
        "    fit_tables = {}\n",
        "    for m in ACTIVE_ORDER:\n",
        "        s = series_map.get(m, None)\n",
        "        if s is None:\n",
        "            fit_tables[m] = {'best': None, 'best_single': None, 'best_gmm': None, 'table': pd.DataFrame()}\n",
        "            continue\n",
        "\n",
        "        res = fit_one(s.values)\n",
        "        if res is None:\n",
        "            fit_tables[m] = {'best': None, 'best_single': None, 'best_gmm': None, 'table': pd.DataFrame()}\n",
        "        else:\n",
        "            fit_tables[m] = {'best': res[0], 'table': res[1], 'best_single': res[2], 'best_gmm': res[3]}\n",
        "    return fit_tables\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9) Monte Carlo: 농도 난수 생성 + 진단 + (게이트+롤백)\n",
        "# ============================================================\n",
        "def _qstats(x):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "    if x.size==0: return dict(mean=np.nan,p5=np.nan,p50=np.nan,p95=np.nan,p99=np.nan)\n",
        "    return dict(mean=float(np.mean(x)),\n",
        "                p5=float(np.percentile(x,5)),\n",
        "                p50=float(np.percentile(x,50)),\n",
        "                p95=float(np.percentile(x,95)),\n",
        "                p99=float(np.percentile(x,99)))\n",
        "\n",
        "def choose_model_for_mc(best_single, best_gmm, raw_x=None):\n",
        "    \"\"\"\n",
        "    - 단일/ GMM 둘 다 없는 경우: None\n",
        "    - 하나만 있는 경우: 있는 모델 그대로 사용\n",
        "    - 둘 다 있는 경우:\n",
        "        1) 히스토그램 기반 bimodal 여부 + AD p값 기준으로 GMM gate 판단\n",
        "        2) gate=False면 단일 고정\n",
        "        3) gate=True면 AD 개선률 + ΔBIC 정책으로 GMM 채택 여부 결정\n",
        "    반환:\n",
        "        chosen_obj, why, info, single_obj, gmm_obj\n",
        "    \"\"\"\n",
        "    # --- (0) 둘 다 없는 경우 ---\n",
        "    if best_single is None and best_gmm is None:\n",
        "        return None, \"none\", {}, None, None\n",
        "\n",
        "    # --- (1) 객체 추출 ---\n",
        "    single_obj = best_single[\"obj\"] if (\n",
        "        best_single is not None\n",
        "        and best_single.get(\"obj\", None) is not None\n",
        "        and best_single[\"obj\"].valid) else None\n",
        "\n",
        "    gmm_obj = best_gmm[\"obj\"] if (\n",
        "        best_gmm is not None\n",
        "        and best_gmm.get(\"obj\", None) is not None\n",
        "        and best_gmm[\"obj\"].valid) else None\n",
        "\n",
        "    # --- (2) 한쪽만 있는 경우 ---\n",
        "    if gmm_obj is None and single_obj is not None:\n",
        "        info = {\"gate\": False, \"accept\": False}\n",
        "        return single_obj, \"single_only\", info, single_obj, None\n",
        "\n",
        "    if single_obj is None and gmm_obj is not None:\n",
        "        info = {\"gate\": True, \"accept\": True}\n",
        "        return gmm_obj, \"gmm_only\", info, None, gmm_obj\n",
        "\n",
        "    # 여기부터는 single_obj, gmm_obj 둘 다 valid인 경우\n",
        "    single_ad  = float(best_single.get(\"AD\", np.inf))\n",
        "    gmm_ad     = float(best_gmm.get(\"AD\",  np.inf))\n",
        "    single_adp = float(best_single.get(\"ADp\", np.nan))\n",
        "\n",
        "    bic_single = float(best_single.get(\"BIC\", np.nan))\n",
        "    bic_gmm    = float(best_gmm.get(\"BIC\",    np.nan))\n",
        "\n",
        "    if (not np.isfinite(single_ad)) or (single_ad <= 0) or (not np.isfinite(gmm_ad)):\n",
        "        ad_improve = np.nan\n",
        "    else:\n",
        "        # AD는 낮을수록 좋으므로, (single - gmm) / single\n",
        "        ad_improve = (single_ad - gmm_ad) / single_ad\n",
        "\n",
        "    delta_bic = (bic_gmm - bic_single) if (\n",
        "        np.isfinite(bic_gmm) and np.isfinite(bic_single)) else np.nan\n",
        "\n",
        "    # --- (3) bimodal 여부 + 상세 info ---\n",
        "    bimodal = False\n",
        "    bimodal_info = None\n",
        "    if raw_x is not None:\n",
        "        xx = clean_conc(raw_x, allow_zero=True)\n",
        "        try:\n",
        "            bimodal, bi_info = is_bimodal_hist(\n",
        "                xx,\n",
        "                nbins=BIMODAL_BINS,\n",
        "                smooth_k=BIMODAL_SMOOTH,\n",
        "                peak_min_frac=BIMODAL_MIN_PROM_RATIO,\n",
        "                return_info=True)\n",
        "            bimodal_info = bi_info\n",
        "        except TypeError:\n",
        "            # 구버전 시그니처 대응\n",
        "            bimodal = is_bimodal_hist(xx)\n",
        "            bimodal_info = None\n",
        "\n",
        "    # --- (4) GMM gate 결정 ---\n",
        "    gmm_gate = False\n",
        "    if bimodal:\n",
        "        # 이중피크면 우선 GMM 후보로 인정\n",
        "        gmm_gate = True\n",
        "    else:\n",
        "        # 단일분포 AD p값이 나쁘고(ADp < threshold),\n",
        "        # GMM의 AD가 더 작으면(=더 좋으면) gate 허용\n",
        "        if (\n",
        "            np.isfinite(single_adp) and (single_adp < GMM_GATE_ADP_SINGLE_BAD)\n",
        "            and np.isfinite(gmm_ad) and np.isfinite(single_ad)\n",
        "            and (gmm_ad < single_ad)):\n",
        "            gmm_gate = True\n",
        "\n",
        "    # gate=False면, 정책 이전에 무조건 단일 고정\n",
        "    if not gmm_gate:\n",
        "        info = {\n",
        "            \"gate\": False,\n",
        "            \"ad_single\": single_ad, \"ad_gmm\": gmm_ad,\n",
        "            \"ad_single_p\": single_adp,\n",
        "            \"bic_single\": bic_single, \"bic_gmm\": bic_gmm,\n",
        "            \"delta_bic\": float(delta_bic) if np.isfinite(delta_bic) else np.nan,\n",
        "            \"ad_improve\": float(ad_improve) if np.isfinite(ad_improve) else np.nan,\n",
        "            \"bimodal\": bool(bimodal),\n",
        "            \"bimodal_info\": bimodal_info,\n",
        "            \"accept\": False}\n",
        "        return single_obj, \"single_by_gate\", info, single_obj, gmm_obj\n",
        "\n",
        "    # --- (5) gate=True인 경우: AD 개선 + ΔBIC 기준으로 GMM 채택 여부 ---\n",
        "    accept = False\n",
        "    why = \"single_by_policy\"\n",
        "\n",
        "    # 1) ΔBIC <= 0 이면 GMM 우선 (복잡도까지 고려해도 이득)\n",
        "    if np.isfinite(delta_bic) and (delta_bic <= 0):\n",
        "        accept = True\n",
        "        why = f\"gmm_by_BIC(delta={delta_bic:.2f})\"\n",
        "\n",
        "    # 2) 기본 정책: AD 개선률 + ΔBIC 범위\n",
        "    if (not accept) and np.isfinite(ad_improve) and np.isfinite(delta_bic):\n",
        "        if (\n",
        "            ad_improve >= GMM_AD_IMPROVE_RATIO\n",
        "            and delta_bic <= GMM_BIC_DELTA_MAX\n",
        "            and gmm_ad < single_ad):\n",
        "            accept = True\n",
        "            why = f\"gmm_by_AD+deltaBIC(improve={ad_improve:.3f}, delta={delta_bic:.2f})\"\n",
        "\n",
        "    # 3) bimodal인 경우에는 완화 기준 적용\n",
        "    if (not accept) and bimodal and np.isfinite(ad_improve) and np.isfinite(delta_bic):\n",
        "        if (\n",
        "            ad_improve >= GMM_AD_IMPROVE_BIMODAL\n",
        "            and delta_bic <= GMM_BIC_DELTA_BIMODAL\n",
        "            and gmm_ad < single_ad):\n",
        "            accept = True\n",
        "            why = f\"gmm_by_bimodal(improve={ad_improve:.3f}, delta={delta_bic:.2f})\"\n",
        "\n",
        "    info = {\n",
        "        \"gate\": True,\n",
        "        \"ad_single\": single_ad, \"ad_gmm\": gmm_ad,\n",
        "        \"ad_single_p\": single_adp,\n",
        "        \"bic_single\": bic_single, \"bic_gmm\": bic_gmm,\n",
        "        \"delta_bic\": float(delta_bic) if np.isfinite(delta_bic) else np.nan,\n",
        "        \"ad_improve\": float(ad_improve) if np.isfinite(ad_improve) else np.nan,\n",
        "        \"bimodal\": bool(bimodal),\n",
        "        \"bimodal_info\": bimodal_info,\n",
        "        \"accept\": bool(accept)}\n",
        "\n",
        "    if accept:\n",
        "        return gmm_obj, why, info, single_obj, gmm_obj\n",
        "    else:\n",
        "        return single_obj, why, info, single_obj, gmm_obj\n",
        "\n",
        "def _ensure_len_nsim(C, rawx):\n",
        "    C = clean_conc(C, allow_zero=True)\n",
        "    if C.size < N_SIM:\n",
        "        if rawx.size > 0:\n",
        "            rs = child_rs()\n",
        "            add = rawx[rs.randint(0, rawx.size, size=(N_SIM - C.size))]\n",
        "            C = np.concatenate([C, add])\n",
        "        else:\n",
        "            C = np.concatenate([C, np.zeros(N_SIM - C.size)])\n",
        "    return C[:N_SIM]\n",
        "\n",
        "def generate_C_sims(series_map, fit_tables):\n",
        "    \"\"\"\n",
        "    (1) 여기서 최종 사용 모델(rollback 포함)을 확정하고,\n",
        "            이후 플롯/ECDF/Q-Q/엑셀 하이라이트는 이 used_model_map을 그대로 사용.\n",
        "    (3) rollback P95는 raw_pos/sim_pos 기반으로 계산.\n",
        "    \"\"\"\n",
        "    C_sims = {}\n",
        "    decision = {}\n",
        "    policy_meta = {}\n",
        "    used_model_map = {}  # metal -> obj (최종 사용 모델, rollback 반영)\n",
        "\n",
        "    for m in ACTIVE_ORDER:\n",
        "        s = series_map.get(m, None)\n",
        "        if s is None:\n",
        "            continue\n",
        "\n",
        "        best_single = fit_tables[m].get('best_single', None)\n",
        "        best_gmm    = fit_tables[m].get('best_gmm', None)\n",
        "\n",
        "        rawx = pd.to_numeric(s, errors='coerce').dropna().values\n",
        "        rawx = clean_conc(rawx, allow_zero=True)\n",
        "\n",
        "        chosen_obj, why, info, single_obj, gmm_obj = choose_model_for_mc(best_single, best_gmm, raw_x=rawx)\n",
        "\n",
        "        if (chosen_obj is not None) and getattr(chosen_obj, \"valid\", False):\n",
        "            C = chosen_obj.rvs(N_SIM, rs=child_rs())\n",
        "            C = _ensure_len_nsim(C, rawx)\n",
        "\n",
        "            rollback = False\n",
        "            rollback_ratio = np.nan\n",
        "\n",
        "            if isinstance(chosen_obj, GMMLog) and (single_obj is not None) and getattr(single_obj, \"valid\", False):\n",
        "                raw_pos = rawx[rawx > 0]\n",
        "                sim_pos = C[C > 0]\n",
        "                if (raw_pos.size >= 20) and (sim_pos.size >= 20):\n",
        "                    raw_p95 = float(np.percentile(raw_pos, 95))\n",
        "                    sim_p95 = float(np.percentile(sim_pos, 95))\n",
        "                    if np.isfinite(raw_p95) and raw_p95 > 0 and np.isfinite(sim_p95):\n",
        "                        rollback_ratio = sim_p95 / raw_p95\n",
        "                        if rollback_ratio > P95_ROLLBACK_RATIO:\n",
        "                            rollback = True\n",
        "\n",
        "            if rollback:\n",
        "                C2 = single_obj.rvs(N_SIM, rs=child_rs())\n",
        "                C2 = _ensure_len_nsim(C2, rawx)\n",
        "                C = C2\n",
        "\n",
        "                used_model_map[m] = single_obj\n",
        "                decision[m] = f\"rollback_to_single(P95ratio={rollback_ratio:.2f})\"\n",
        "\n",
        "                info = dict(info) if isinstance(info, dict) else {}\n",
        "                info[\"rollback\"] = True\n",
        "                info[\"p95_ratio\"] = float(rollback_ratio)\n",
        "                info[\"accept\"] = False\n",
        "                policy_meta[m] = info\n",
        "            else:\n",
        "                used_model_map[m] = chosen_obj\n",
        "                decision[m] = why\n",
        "\n",
        "                info = dict(info) if isinstance(info, dict) else {}\n",
        "                info[\"rollback\"] = False\n",
        "                info[\"p95_ratio\"] = float(rollback_ratio) if np.isfinite(rollback_ratio) else np.nan\n",
        "                policy_meta[m] = info\n",
        "\n",
        "            C_sims[m] = C\n",
        "\n",
        "        else:\n",
        "            # fallback: raw resample\n",
        "            if rawx.size>=1:\n",
        "                rs = child_rs()\n",
        "                idx=rs.randint(0,len(rawx), size=N_SIM)\n",
        "                C_sims[m]=rawx[idx]\n",
        "                decision[m] = \"resample_raw\"\n",
        "                policy_meta[m] = {\"accept\": False, \"gate\": False}\n",
        "                used_model_map[m] = None\n",
        "            else:\n",
        "                decision[m] = \"no_data\"\n",
        "                policy_meta[m] = {\"accept\": False, \"gate\": False}\n",
        "                used_model_map[m] = None\n",
        "\n",
        "    if ('Cr(VI)' not in EXCLUDE_SET) and ('Cr(VI)' not in C_sims) and ('Cr' in C_sims):\n",
        "        C_sims['Cr(VI)']=C_sims['Cr']/7.0\n",
        "        decision['Cr(VI)'] = \"derived_from_Cr/7_in_MC\"\n",
        "        policy_meta['Cr(VI)'] = {\"accept\": False}\n",
        "        used_model_map['Cr(VI)'] = None\n",
        "\n",
        "    print(\"\\n===== MC 채택 모델/정책(게이트 + ΔBIC + AD + bimodal + P95 rollback) =====\")\n",
        "    for m in ACTIVE_ORDER:\n",
        "        if m in decision:\n",
        "            msg = f\"- {m}: {decision[m]}\"\n",
        "            inf = policy_meta.get(m, {})\n",
        "            if isinstance(inf, dict):\n",
        "                msg += f\" | gate={inf.get('gate',np.nan)}\"\n",
        "\n",
        "                # AD/KS/Chi2 관련 요약\n",
        "                if (\"ad_single\" in inf) and (\"ad_gmm\" in inf):\n",
        "                    imp = inf.get('ad_improve',np.nan)\n",
        "                    msg += (\n",
        "                        f\" | AD(single)={inf.get('ad_single',np.nan):.4g}, \"\n",
        "                        f\"AD(gmm)={inf.get('ad_gmm',np.nan):.4g}, \"\n",
        "                        f\"improve={imp*100 if np.isfinite(imp) else np.nan:.2f}%\")\n",
        "\n",
        "                # BIC 비교\n",
        "                if (\"bic_single\" in inf) and (\"bic_gmm\" in inf):\n",
        "                    msg += (\n",
        "                        f\" | BIC(single)={inf.get('bic_single',np.nan):.4g}, \"\n",
        "                        f\"BIC(gmm)={inf.get('bic_gmm',np.nan):.4g}, \"\n",
        "                        f\"ΔBIC={inf.get('delta_bic',np.nan):.3g}\")\n",
        "\n",
        "                # bimodal 여부 + 판정 이유\n",
        "                if \"bimodal\" in inf:\n",
        "                    msg += f\" | bimodal={inf.get('bimodal',False)}\"\n",
        "                    bi = inf.get(\"bimodal_info\", None)\n",
        "                    if isinstance(bi, dict) and inf.get(\"bimodal\", False):\n",
        "                        rule = bi.get(\"rule\", None)\n",
        "                        n_peaks = bi.get(\"n_peaks\", None)\n",
        "                        if rule is not None:\n",
        "                            msg += f\" | bimodal_rule={rule}\"\n",
        "                        if n_peaks is not None:\n",
        "                            msg += f\" | n_peaks={n_peaks}\"\n",
        "\n",
        "                # P95 ratio & rollback\n",
        "                if \"p95_ratio\" in inf and np.isfinite(inf.get(\"p95_ratio\", np.nan)):\n",
        "                    msg += f\" | P95ratio={inf.get('p95_ratio',np.nan):.2f}\"\n",
        "                if \"rollback\" in inf:\n",
        "                    msg += f\" | rollback={inf.get('rollback',False)}\"\n",
        "\n",
        "            print(msg)\n",
        "\n",
        "    if DIAG_ENABLE:\n",
        "        print(\"\\n===== [DIAG] 원자료 vs 시뮬 비교 =====\")\n",
        "        for m in ACTIVE_ORDER:\n",
        "            raw = pd.to_numeric(series_map.get(m, pd.Series(dtype=float)), errors='coerce').dropna().values\n",
        "            raw = clean_conc(raw, allow_zero=True)\n",
        "            sim = np.asarray(C_sims.get(m, []), float)\n",
        "            sim = clean_conc(sim, allow_zero=True)\n",
        "            if raw.size < 5 or sim.size < 5:\n",
        "                continue\n",
        "            a=_qstats(raw); b=_qstats(sim)\n",
        "            flag = \"\"\n",
        "            raw_pos = raw[raw > 0]\n",
        "            sim_pos = sim[sim > 0]\n",
        "            if raw_pos.size >= 5 and sim_pos.size >= 5:\n",
        "                rp95 = float(np.percentile(raw_pos,95))\n",
        "                sp95 = float(np.percentile(sim_pos,95))\n",
        "                if np.isfinite(rp95) and rp95>0 and np.isfinite(sp95):\n",
        "                    ratio = sp95/rp95\n",
        "                    if (ratio>2.0) or (ratio<0.5):\n",
        "                        flag = \"  [WARN:P95 mismatch(pos-only)]\"\n",
        "            print(f\"{m}: raw(mean={a['mean']:.3g},P5={a['p5']:.3g},P50={a['p50']:.3g},P95={a['p95']:.3g}) | \"\n",
        "                  f\"sim(mean={b['mean']:.3g},P5={b['p5']:.3g},P50={b['p50']:.3g},P95={b['p95']:.3g}){flag}\")\n",
        "\n",
        "    return C_sims, used_model_map, decision, policy_meta\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 10) 플롯 저장 (패널 + 개별)\n",
        "# ============================================================\n",
        "def save_plots(series_map, fit_tables, used_model_map):\n",
        "    \"\"\"\n",
        "    (FIX-1) used_model_map(최종 사용모델, rollback 반영) 기준으로 그림 생성\n",
        "    \"\"\"\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "    os.makedirs(f\"{SAVE_DIR}/plots\", exist_ok=True)\n",
        "\n",
        "    fig, axes = plt.subplots(4, 2, figsize=(12, 16))\n",
        "    axes = axes.ravel()\n",
        "    idx = 0\n",
        "\n",
        "    for m in ACTIVE_ORDER:\n",
        "        data = series_map.get(m, pd.Series(dtype=float))\n",
        "        used_obj = used_model_map.get(m, None)\n",
        "\n",
        "        if isinstance(used_obj, GMMLog):\n",
        "            K = int(used_obj.p.get(\"K\", -1))\n",
        "            bic_cmp = np.nan\n",
        "            best_gmm = fit_tables.get(m, {}).get(\"best_gmm\", None)\n",
        "            if best_gmm is not None:\n",
        "                bic_cmp = best_gmm.get(\"BIC\", np.nan)\n",
        "            if not np.isfinite(bic_cmp):\n",
        "                bic_cmp = used_obj.p.get(\"bic_sklearn\", np.nan)\n",
        "            label2 = f\"GMM(Log) (K={K}, BIC={bic_cmp:.1f})\" if np.isfinite(bic_cmp) else f\"GMM(Log) (K={K})\"\n",
        "            plot_hist_with_fit(axes[idx], data, None, m, dist_obj2=used_obj, label2=label2)\n",
        "        else:\n",
        "            plot_hist_with_fit(axes[idx], data, used_obj, m, dist_obj2=None, label2=None)\n",
        "\n",
        "        idx += 1\n",
        "        if idx >= 8:\n",
        "            break\n",
        "\n",
        "    while idx < 8:\n",
        "        axes[idx].axis('off')\n",
        "        idx += 1\n",
        "\n",
        "    fig.suptitle(\"Histograms with Adopted Model (Single vs GMM)\", fontsize=20, fontweight='bold')\n",
        "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "    panel_path = f\"{SAVE_DIR}/plots/Tx_fitting_summary.png\"\n",
        "    fig.savefig(panel_path, dpi=200)\n",
        "    plt.show()\n",
        "\n",
        "    for m in ACTIVE_ORDER:\n",
        "        data = series_map.get(m, pd.Series(dtype=float))\n",
        "        used_obj = used_model_map.get(m, None)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "        if isinstance(used_obj, GMMLog):\n",
        "            K = int(used_obj.p.get(\"K\", -1))\n",
        "            bic_cmp = np.nan\n",
        "            best_gmm = fit_tables.get(m, {}).get(\"best_gmm\", None)\n",
        "            if best_gmm is not None:\n",
        "                bic_cmp = best_gmm.get(\"BIC\", np.nan)\n",
        "            if not np.isfinite(bic_cmp):\n",
        "                bic_cmp = used_obj.p.get(\"bic_sklearn\", np.nan)\n",
        "            label2 = f\"GMM(Log) (K={K}, BIC={bic_cmp:.1f})\" if np.isfinite(bic_cmp) else f\"GMM(Log) (K={K})\"\n",
        "            plot_hist_with_fit(ax, data, None, m, dist_obj2=used_obj, label2=label2)\n",
        "        else:\n",
        "            plot_hist_with_fit(ax, data, used_obj, m, dist_obj2=None, label2=None)\n",
        "\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(f\"{SAVE_DIR}/plots/{m}_fit.png\", dpi=200)\n",
        "        plt.close(fig)\n",
        "\n",
        "    print(\"Saved plots:\")\n",
        "    print(\"-\", panel_path)\n",
        "    print(\"-\", f\"{SAVE_DIR}/plots/<metal>_fit.png\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 11) 피팅 결과 엑셀 저장 (BIC/loglik 열 포함)\n",
        "#     - 하이라이트: \"최종 사용모델(rollback 반영)\"\n",
        "# ============================================================\n",
        "def save_fit_excel(fit_tables, log_df, series_map, used_model_map):\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "    suffix = (\"excl_\" + \"_\".join(sorted(EXCLUDE_SET))) if EXCLUDE_SET else \"all\"\n",
        "    fit_xlsx = os.path.join(SAVE_DIR, f\"Tx_fit_result_{suffix}.xlsx\")\n",
        "\n",
        "    wb=Workbook()\n",
        "    ws=wb.active\n",
        "    ws.title=\"Tx-적합도 보고서\"\n",
        "\n",
        "    def set_col_widths(ws, widths):\n",
        "        for col,w in widths.items():\n",
        "            ws.column_dimensions[col].width = w\n",
        "\n",
        "    def styled_header(ws, row, headers, start_col=1, fill_color=HEADER_BLUE):\n",
        "        fill = PatternFill('solid', fgColor=fill_color)\n",
        "        white = Font(color='FFFFFF', bold=True)\n",
        "        center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
        "        thin = Border(left=Side(style='thin', color=THIN_GRAY),\n",
        "                      right=Side(style='thin', color=THIN_GRAY),\n",
        "                      top=Side(style='thin', color=THIN_GRAY),\n",
        "                      bottom=Side(style='thin', color=THIN_GRAY))\n",
        "        for offset, h in enumerate(headers, start=start_col):\n",
        "            j = offset\n",
        "            c = ws.cell(row=row, column=j, value=h)\n",
        "            c.fill = fill\n",
        "            c.font = white\n",
        "            c.alignment = center\n",
        "            c.border = thin\n",
        "\n",
        "    def write_num(ws, r, c, v, fmt='0.0000'):\n",
        "        cell=ws.cell(row=r, column=c)\n",
        "        if v is None or (isinstance(v,float) and (np.isnan(v) or np.isinf(v))):\n",
        "            cell.value='---'\n",
        "        else:\n",
        "            cell.value=float(v) if isinstance(v,(int,float,np.floating)) else v\n",
        "            if isinstance(v,(int,float,np.floating)):\n",
        "                cell.number_format = fmt\n",
        "\n",
        "    set_col_widths(ws, {'A':18,'B':12,'C':12,'D':12,'E':12,'F':12,'G':12,'H':12,'I':12,'J':12,'K':70})\n",
        "    ws.freeze_panes = 'B3'\n",
        "    ws['A1'] = '랭킹: AD(낮을수록) → KS p(높을수록) → χ² p(높을수록) → #params(적을수록)'\n",
        "    ws['A2'] = '데이터 계열'\n",
        "\n",
        "    row=3\n",
        "    table_idx=1\n",
        "    for m in ACTIVE_ORDER:\n",
        "        ws.cell(row=row, column=1, value=m).font = Font(bold=True)\n",
        "        row += 1\n",
        "\n",
        "        headers=['분포','A-D','A-D P-값','K-S','K-S P-값','카이제곱','카이제곱 P-값','BIC','loglik','매개변수']\n",
        "        styled_header(ws,row,headers,start_col=2)\n",
        "        start_row=row\n",
        "        row+=1\n",
        "\n",
        "        tbl = fit_tables.get(m,{}).get('table', pd.DataFrame())\n",
        "        if tbl is None or tbl.empty:\n",
        "            ws.cell(row=row, column=2, value=\"(no data or <min_n or <3 uniques)\")\n",
        "            row+=2\n",
        "            continue\n",
        "\n",
        "        # (1) 하이라이트는 used_model_map 기준\n",
        "        used_obj = used_model_map.get(m, None)\n",
        "        chosen_disp = None\n",
        "        if (used_obj is not None) and getattr(used_obj, \"valid\", False):\n",
        "            if isinstance(used_obj, GMMLog) or (getattr(used_obj, \"name\", \"\") == \"GMM(Log)\"):\n",
        "                Kc = used_obj.p.get(\"K\", None)\n",
        "                chosen_disp = f\"GMM(Log) (K={int(Kc)})\" if (Kc is not None and np.isfinite(Kc)) else \"GMM(Log)\"\n",
        "            else:\n",
        "                chosen_disp = str(used_obj.name)\n",
        "\n",
        "        chosen_rr = None\n",
        "\n",
        "        for i,r_ in tbl.iterrows():\n",
        "            rr=row+i\n",
        "\n",
        "            disp_name = r_['분포']\n",
        "            if str(disp_name) == 'GMM(Log)':\n",
        "                try:\n",
        "                    obj = r_.get('obj', None)\n",
        "                    K = None\n",
        "                    if obj is not None and getattr(obj, \"valid\", False):\n",
        "                        K = obj.p.get('K', None)\n",
        "                    if K is not None and np.isfinite(K):\n",
        "                        disp_name = f\"GMM(Log) (K={int(K)})\"\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            ws.cell(row=rr, column=2, value=disp_name)\n",
        "            write_num(ws, rr,3, r_['AD'])\n",
        "            write_num(ws, rr,4, r_['ADp'])\n",
        "            write_num(ws, rr,5, r_['KS'])\n",
        "            write_num(ws, rr,6, r_['KSp'])\n",
        "            write_num(ws, rr,7, r_['Chi2'])\n",
        "            write_num(ws, rr,8, r_['Chi2p'])\n",
        "            write_num(ws, rr,9,  r_.get('BIC', np.nan))\n",
        "            write_num(ws, rr,10, r_.get('loglik', np.nan))\n",
        "            ws.cell(row=rr, column=11, value=pstr(r_['분포'], r_['obj'].p))\n",
        "\n",
        "            if chosen_disp is not None:\n",
        "                if str(disp_name) == str(chosen_disp):\n",
        "                    chosen_rr = rr\n",
        "                elif (\"GMM(Log)\" in str(chosen_disp)) and (\"GMM(Log)\" in str(disp_name)):\n",
        "                    # K를 포함한 표기 불일치 대비\n",
        "                    chosen_rr = rr\n",
        "\n",
        "        end_row = row + len(tbl) - 1\n",
        "        try:\n",
        "            t = Table(displayName=f\"T_{table_idx}\", ref=f\"B{start_row}:K{end_row}\")\n",
        "            t.tableStyleInfo = TableStyleInfo(\n",
        "                name=TABLE_STYLE, showFirstColumn=False, showLastColumn=False,\n",
        "                showRowStripes=True, showColumnStripes=False)\n",
        "            ws.add_table(t)\n",
        "            table_idx+=1\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        fill = PatternFill('solid', fgColor=BEST_FILL)\n",
        "        if len(tbl)>0:\n",
        "            target_rr = chosen_rr if (chosen_rr is not None) else (start_row + 1)\n",
        "            for c in range(2,12):\n",
        "                ws.cell(row=target_rr, column=c).fill=fill\n",
        "\n",
        "        row=end_row+2\n",
        "\n",
        "    wsL = wb.create_sheet(\"Log\")\n",
        "    wsL.append(list(log_df.columns))\n",
        "    for _,r in log_df.iterrows():\n",
        "        wsL.append(list(r.values))\n",
        "\n",
        "    wb.save(fit_xlsx)\n",
        "    print(\"Saved:\", fit_xlsx)\n",
        "    return fit_xlsx\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 12) ECDF + Q-Q 검증\n",
        "#      - ECDF: Raw vs Sim\n",
        "#      - Q-Q: Raw vs Single, Raw vs GMM\n",
        "# ============================================================\n",
        "def plot_ecdf_qq(metal, raw_x, sim_x, single_obj=None, gmm_obj=None, title_suffix=\"\"):\n",
        "    raw = np.asarray(raw_x, float)\n",
        "    sim = np.asarray(sim_x, float)\n",
        "\n",
        "    raw = clean_conc(raw, allow_zero=True)\n",
        "    sim = clean_conc(sim, allow_zero=True)\n",
        "\n",
        "    if raw.size < 5 or sim.size < 5:\n",
        "        print(f\"[{metal}] ECDF/Q-Q skipped (insufficient data)\")\n",
        "        return\n",
        "\n",
        "    def ecdf(x):\n",
        "        x = np.sort(x)\n",
        "        y = np.arange(1, len(x)+1) / len(x)\n",
        "        return x, y\n",
        "\n",
        "    xr, yr = ecdf(raw)\n",
        "    xs, ys = ecdf(sim)\n",
        "\n",
        "    # Q-Q는 양수(raw>0)만 사용\n",
        "    raw_pos = raw[raw > 0]\n",
        "    if raw_pos.size < 5:\n",
        "        print(f\"[{metal}] Q-Q skipped (insufficient positive raw data)\")\n",
        "        return\n",
        "\n",
        "    # 공통 quantile grid\n",
        "    n_q = min(raw_pos.size, 200)\n",
        "    q = np.linspace(0.01, 0.99, n_q)\n",
        "    qr = np.quantile(raw_pos, q)\n",
        "\n",
        "    q_single = None\n",
        "    if (single_obj is not None) and getattr(single_obj, \"valid\", False):\n",
        "        try:\n",
        "            q_single = single_obj.ppf(q)\n",
        "        except Exception:\n",
        "            q_single = None\n",
        "\n",
        "    q_gmm = None\n",
        "    if (gmm_obj is not None) and getattr(gmm_obj, \"valid\", False):\n",
        "        try:\n",
        "            q_gmm = gmm_obj.ppf(q)\n",
        "        except Exception:\n",
        "            q_gmm = None\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    # 0 포함 시 EPS로 치환 후 로그축\n",
        "    xr_plot = np.maximum(xr, EPS)\n",
        "    xs_plot = np.maximum(xs, EPS)\n",
        "\n",
        "    # --- ECDF: Raw vs Sim (그대로 유지) ---\n",
        "    axes[0].plot(xr_plot, yr, lw=2, label=\"Raw ECDF\")\n",
        "    axes[0].plot(xs_plot, ys, lw=2, ls=\"--\", label=\"Sim ECDF\")\n",
        "    axes[0].set_xscale(\"log\")\n",
        "    axes[0].set_xlabel(\"Concentration (µg/m³)\")\n",
        "    axes[0].set_ylabel(\"ECDF\")\n",
        "    axes[0].set_title(f\"{metal} – ECDF\")\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # --- Q-Q: Raw vs Single ---\n",
        "    axes[1].plot(qr, qr, \"k--\", lw=1, label=\"1:1\")\n",
        "    if q_single is not None:\n",
        "        q_single = np.asarray(q_single, float)\n",
        "        mask = np.isfinite(q_single)\n",
        "        if mask.sum() >= 5:\n",
        "            axes[1].plot(qr[mask], q_single[mask], \"o\", ms=3, label=\"Single\")\n",
        "            axes[1].legend()\n",
        "            axes[1].set_title(\"Q-Q: Raw vs Single\")\n",
        "        else:\n",
        "            axes[1].text(0.5, 0.5, \"Single Q-Q unavailable\",\n",
        "                         ha=\"center\", va=\"center\", transform=axes[1].transAxes)\n",
        "            axes[1].set_title(\"Q-Q: Raw vs Single (N/A)\")\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, \"Single Q-Q unavailable\",\n",
        "                     ha=\"center\", va=\"center\", transform=axes[1].transAxes)\n",
        "        axes[1].set_title(\"Q-Q: Raw vs Single (N/A)\")\n",
        "\n",
        "    axes[1].set_xlabel(\"Raw quantiles\")\n",
        "    axes[1].set_ylabel(\"Single quantiles\")\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    # --- Q-Q: Raw vs GMM ---\n",
        "    axes[2].plot(qr, qr, \"k--\", lw=1, label=\"1:1\")\n",
        "    if q_gmm is not None:\n",
        "        q_gmm = np.asarray(q_gmm, float)\n",
        "        mask = np.isfinite(q_gmm)\n",
        "        if mask.sum() >= 5:\n",
        "            axes[2].plot(qr[mask], q_gmm[mask], \"o\", ms=3, label=\"GMM(Log)\")\n",
        "            axes[2].legend()\n",
        "            axes[2].set_title(\"Q-Q: Raw vs GMM(Log)\")\n",
        "        else:\n",
        "            axes[2].text(0.5, 0.5, \"GMM Q-Q unavailable\",\n",
        "                         ha=\"center\", va=\"center\", transform=axes[2].transAxes)\n",
        "            axes[2].set_title(\"Q-Q: Raw vs GMM(Log) (N/A)\")\n",
        "    else:\n",
        "        axes[2].text(0.5, 0.5, \"GMM Q-Q unavailable\",\n",
        "                     ha=\"center\", va=\"center\", transform=axes[2].transAxes)\n",
        "        axes[2].set_title(\"Q-Q: Raw vs GMM(Log) (N/A)\")\n",
        "\n",
        "    axes[2].set_xlabel(\"Raw quantiles\")\n",
        "    axes[2].set_ylabel(\"GMM(Log) quantiles\")\n",
        "    axes[2].grid(alpha=0.3)\n",
        "\n",
        "    fig.suptitle(f\"{metal} | ECDF & Q-Q diagnostics {title_suffix}\",\n",
        "                 fontsize=14, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 13) Time-outdoors 난수 → K 계산 + 검증\n",
        "# ============================================================\n",
        "_Z95=1.6448536269514722\n",
        "def mu_sigma_from_p5p95(p5,p95):\n",
        "    p5=max(1e-9,float(p5)); p95=max(1e-9,float(p95))\n",
        "    if p95<=p5:\n",
        "        p95=p5*1.01\n",
        "    ln5,ln95=np.log(p5),np.log(p95)\n",
        "    sigma=(ln95-ln5)/(2*_Z95)\n",
        "    mu=(ln5+ln95)/2\n",
        "    return mu,sigma\n",
        "\n",
        "def sample_AcTout(age, n, rs=None):\n",
        "    rs = rs if rs is not None else child_rs()\n",
        "    if age in ACT_POINT:\n",
        "        return np.full(n, float(ACT_POINT[age]), dtype=float)\n",
        "    p5,p95=ACT_LN_P5_P95[age]\n",
        "    mu,sg=mu_sigma_from_p5p95(p5,p95)\n",
        "    return rs.lognormal(mu,sg,size=n)\n",
        "\n",
        "def K_by_group(n):\n",
        "    Kg = {'Infant':np.zeros(n), 'Child':np.zeros(n), 'Adult':np.zeros(n)}\n",
        "    for age in INFANT+CHILD+ADULT:\n",
        "        act = sample_AcTout(age, n, rs=child_rs())\n",
        "        act_dayfrac = act / 1440.0\n",
        "        add = act_dayfrac * EF * (ED_years[age]/LT_years) * (10.0 if age in INFANT else (3.0 if age in CHILD else 1.0))\n",
        "        if age in INFANT:\n",
        "            Kg['Infant'] += add\n",
        "        elif age in CHILD:\n",
        "            Kg['Child'] += add\n",
        "        else:\n",
        "            Kg['Adult'] += add\n",
        "    Kg['Lifetime'] = Kg['Infant'] + Kg['Child'] + Kg['Adult']\n",
        "    return Kg\n",
        "\n",
        "def check_time_out_samples():\n",
        "    print(\"\\n===== Time outdoors 난수 분포 검증 =====\")\n",
        "    print(f\"{'Age':<10} {'Mean(sample)':>12} {'P5(sample)':>12} {'P95(sample)':>12} {'Target Mean':>12} {'Target 95th':>12}\")\n",
        "    for age in AGE_ORDER:\n",
        "        n=TOUT_QA_N\n",
        "        s=sample_AcTout(age, n, rs=child_rs())\n",
        "        mean_s=np.mean(s); p5_s=np.percentile(s,5); p95_s=np.percentile(s,95)\n",
        "        if age in ACT_POINT:\n",
        "            t_mean=ACT_POINT[age]; t_p95=ACT_POINT[age]\n",
        "        else:\n",
        "            t_mean=None; t_p95=ACT_LN_P5_P95[age][1]\n",
        "        t_mean_str = f\"{t_mean:,.1f}\" if t_mean is not None else \"---\"\n",
        "        print(f\"{age:<10} {mean_s:12.3f} {p5_s:12.3f} {p95_s:12.3f} {t_mean_str:>12} {t_p95:12.1f}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 14) LECR 계산 (Infant/Child/Adult 분리) + 저장\n",
        "# ============================================================\n",
        "def _stats(v: np.ndarray):\n",
        "    v = np.asarray(v, float)\n",
        "    v = v[np.isfinite(v)]\n",
        "    if v.size == 0:\n",
        "        return dict(mean=np.nan, median=np.nan, p95=np.nan, p99=np.nan)\n",
        "    return dict(\n",
        "        mean=float(np.mean(v)),\n",
        "        median=float(np.median(v)),\n",
        "        p95=float(np.percentile(v, 95)),\n",
        "        p99=float(np.percentile(v, 99)))\n",
        "\n",
        "def summarize_risk_by_stage(C_sims: dict, Kg: dict):\n",
        "    out_rows = []\n",
        "    cum_vec  = np.zeros(N_SIM, float)\n",
        "\n",
        "    for m in ACTIVE_ORDER:\n",
        "        if (m not in IUR) or (m not in C_sims):\n",
        "            continue\n",
        "\n",
        "        C = np.asarray(C_sims[m], float)\n",
        "        C = clean_conc(C, allow_zero=True, drop_nonfinite=False)\n",
        "\n",
        "        if C.size < N_SIM:\n",
        "            C = np.concatenate([C, np.zeros(N_SIM - C.size)])\n",
        "        C = C[:N_SIM]\n",
        "\n",
        "        lecr_inf   = C * Kg['Infant'] * float(IUR[m])\n",
        "        lecr_child = C * Kg['Child']  * float(IUR[m])\n",
        "        lecr_adult = C * Kg['Adult']  * float(IUR[m])\n",
        "        lecr_tot   = lecr_inf + lecr_child + lecr_adult\n",
        "\n",
        "        cum_vec += lecr_tot\n",
        "\n",
        "        out_rows.append({\n",
        "            'Metal': m,\n",
        "            'Infant': _stats(lecr_inf),\n",
        "            'Child':  _stats(lecr_child),\n",
        "            'Adult':  _stats(lecr_adult),\n",
        "            'LECR (per metal)': _stats(lecr_tot)})\n",
        "\n",
        "    cum_stats = {'Total LECR': _stats(cum_vec)}\n",
        "    return out_rows, cum_stats\n",
        "\n",
        "def save_lecr_excel(risk_rows, cum_stats):\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "    lecr_xlsx = os.path.join(SAVE_DIR, \"Tx.xlsx\")\n",
        "    wb2 = Workbook()\n",
        "    wsR=wb2.active\n",
        "    wsR.title=\"LECR 결과 요약\"\n",
        "    wsR.append([\"Metal\",\"mean\",\"median\",\"P95\",\"P99\"])\n",
        "    for r in risk_rows:\n",
        "        m=r['Metal']; s=r['LECR (per metal)']\n",
        "        wsR.append([m,s['mean'],s['median'],s['p95'],s['p99']])\n",
        "\n",
        "    wsR2 = wb2.create_sheet(\"Total LECR\")\n",
        "    wsR2.append([\"metric\",\"value\"])\n",
        "    for k,v in cum_stats['Total LECR'].items():\n",
        "        wsR2.append([k,v])\n",
        "\n",
        "    wb2.save(lecr_xlsx)\n",
        "    print(\"Saved:\", lecr_xlsx)\n",
        "    return lecr_xlsx\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# get_chosen_model_label()\n",
        "# ============================================================\n",
        "def get_chosen_model_label(m, used_model_map=None, series_map=None, fit_tables=None):\n",
        "    used_obj = None\n",
        "    if used_model_map is not None:\n",
        "        used_obj = used_model_map.get(m, None)\n",
        "\n",
        "    if (used_obj is None) or (not getattr(used_obj, \"valid\", False)):\n",
        "        return \"none\"\n",
        "\n",
        "    if isinstance(used_obj, GMMLog) or (getattr(used_obj, \"name\", \"\") == \"GMM(Log)\"):\n",
        "        K = used_obj.p.get(\"K\", None)\n",
        "        return f\"GMM(Log) K={int(K)}\" if (K is not None and np.isfinite(K)) else \"GMM(Log)\"\n",
        "\n",
        "    return ENG_NAME.get(used_obj.name, used_obj.name)\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# 15) 메인 실행 (MC→used_model_map 확정 후 플롯/엑셀/ECDF 수행)\n",
        "# ==============================================================\n",
        "raw, INPUT, SHEET = load_excel_auto_sheet()\n",
        "series_map, log_df = build_series_map(raw)\n",
        "\n",
        "fit_tables = run_fitting(series_map)\n",
        "\n",
        "# (1) 먼저 MC 생성에서 최종 사용모델(rollback 포함) 확정\n",
        "C_sims, used_model_map, decision, policy_meta = generate_C_sims(series_map, fit_tables)\n",
        "\n",
        "# (2) 확정된 used_model_map 기준으로 플롯/엑셀 생성\n",
        "save_plots(series_map, fit_tables, used_model_map)\n",
        "fit_xlsx = save_fit_excel(fit_tables, log_df, series_map, used_model_map)\n",
        "\n",
        "print(\"\\n===== ECDF & Q-Q diagnostics (Raw+Sim ECDF, Q-Q: Raw vs Single / Raw vs GMM) =====\")\n",
        "\n",
        "for m in ACTIVE_ORDER:\n",
        "    if m not in C_sims:\n",
        "        continue\n",
        "\n",
        "    rawx = pd.to_numeric(series_map[m], errors=\"coerce\").dropna().values\n",
        "    rawx = clean_conc(rawx, allow_zero=True)\n",
        "\n",
        "    simx = np.asarray(C_sims[m], float)\n",
        "    simx = clean_conc(simx, allow_zero=True)\n",
        "\n",
        "    used_obj = used_model_map.get(m, None)\n",
        "    label = f\"(chosen={get_chosen_model_label(m, used_model_map=used_model_map)})\"\n",
        "\n",
        "    # best_single / best_gmm에서 obj 가져오기\n",
        "    ft = fit_tables.get(m, {})\n",
        "    best_single = ft.get(\"best_single\", None)\n",
        "    best_gmm    = ft.get(\"best_gmm\", None)\n",
        "    single_obj  = best_single[\"obj\"] if (best_single is not None and best_single.get(\"obj\", None) is not None) else None\n",
        "    gmm_obj     = best_gmm[\"obj\"]    if (best_gmm is not None and best_gmm.get(\"obj\", None) is not None) else None\n",
        "\n",
        "    plot_ecdf_qq(\n",
        "        metal=m,\n",
        "        raw_x=rawx,\n",
        "        sim_x=simx,\n",
        "        single_obj=single_obj,\n",
        "        gmm_obj=gmm_obj,\n",
        "        title_suffix=label)\n",
        "\n",
        "def print_mc_samples(C_sims, used_model_map, n_show=10, ndigits=8):\n",
        "    print(\"\\n===== Monte Carlo 농도 난수 샘플 (금속별, µg/m³) =====\")\n",
        "    for m in ACTIVE_ORDER:\n",
        "        if m not in C_sims:\n",
        "            continue\n",
        "\n",
        "        label = get_chosen_model_label(m, used_model_map=used_model_map)\n",
        "\n",
        "        arr = np.asarray(C_sims[m], float)\n",
        "        arr = arr[np.isfinite(arr)]\n",
        "        if arr.size == 0:\n",
        "            print(f\"- {m}: ({label})  -> no samples\")\n",
        "            continue\n",
        "\n",
        "        out = arr[:n_show]\n",
        "        vals = \", \".join([f\"{v:.{ndigits}f}\" for v in out])\n",
        "        print(f\"- {m}: ({label})  [{vals}]\")\n",
        "\n",
        "print_mc_samples(C_sims, used_model_map, n_show=10, ndigits=6)\n",
        "\n",
        "Kg = K_by_group(N_SIM)\n",
        "\n",
        "print(\"\\n===== Time outdoors 난수 샘플 (min/day) =====\")\n",
        "for age in AGE_ORDER:\n",
        "    arr = sample_AcTout(age, 10, rs=child_rs())\n",
        "    print(f\"{age}: {np.array2string(arr, precision=3, separator=', ')}\")\n",
        "\n",
        "if RUN_TOUT_QA:\n",
        "    check_time_out_samples()\n",
        "\n",
        "risk_rows, cum_stats = summarize_risk_by_stage(C_sims, Kg)\n",
        "\n",
        "print(\"\\n===== LECR 요약 (Infant / Child / Adult / LECR (per metal)) =====\")\n",
        "for r in risk_rows:\n",
        "    m = r['Metal']\n",
        "    si, sc, sa, st = r['Infant'], r['Child'], r['Adult'], r['LECR (per metal)']\n",
        "    print(f\"\\n[{m}]\")\n",
        "    print(f\"  Infant          : mean={si['mean']:.5e}, median={si['median']:.5e}, P95={si['p95']:.5e}, P99={si['p99']:.5e}\")\n",
        "    print(f\"  Child           : mean={sc['mean']:.5e}, median={sc['median']:.5e}, P95={sc['p95']:.5e}, P99={sc['p99']:.5e}\")\n",
        "    print(f\"  Adult           : mean={sa['mean']:.5e}, median={sa['median']:.5e}, P95={sa['p95']:.5e}, P99={sa['p99']:.5e}\")\n",
        "    print(f\"  LECR (per metal): mean={st['mean']:.5e}, median={st['median']:.5e}, P95={st['p95']:.5e}, P99={st['p99']:.5e}\")\n",
        "\n",
        "print(\"\\n===== Total LECR (Lifetime, across metals) =====\")\n",
        "cs = cum_stats['Total LECR']\n",
        "print(f\"  mean={cs['mean']:.3e}, median={cs['median']:.3e}, P95={cs['p95']:.3e}, P99={cs['p99']:.3e}\")\n",
        "\n",
        "lecr_xlsx = save_lecr_excel(risk_rows, cum_stats)\n",
        "\n",
        "print(\"\\n=== 완료 ===\")\n",
        "print(f\"- 피팅 엑셀: {fit_xlsx}\")\n",
        "print(f\"- LECR 엑셀: {lecr_xlsx}\")\n",
        "print(f\"- 그림 폴더: {SAVE_DIR}/plots\")\n",
        "\n",
        "files.download(fit_xlsx)\n",
        "files.download(lecr_xlsx)"
      ],
      "metadata": {
        "id": "XMoutPQcgfEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 금속별 LECR 누적확률분포 그래프 생성 ##"
      ],
      "metadata": {
        "id": "8kX2Jp6Ag8wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 색상 팔레트\n",
        "COLORS = {\n",
        "    'Cr(VI)': '#1f77b4',  # blue\n",
        "    'Co':     '#ff7f0e',  # orange\n",
        "    'Ni':     '#2ca02c',  # green\n",
        "    'Cd':     '#d62728',  # red\n",
        "    'As':     '#17becf',  # cyan\n",
        "    'Sb':     '#9467bd',  # purple\n",
        "    'Pb':     '#8c564b',  # brown\n",
        "    'Total':  '#000000'   # black\n",
        "    }\n",
        "\n",
        "REFLINE_COLOR = \"#003366\" # 기준선\n",
        "\n",
        "def ecdf(arr: np.ndarray):\n",
        "    x = np.asarray(arr, dtype=float)\n",
        "    x = x[np.isfinite(x)]\n",
        "    if x.size == 0:\n",
        "        return np.array([]), np.array([])\n",
        "    x = np.sort(x)\n",
        "    n = x.size\n",
        "    F = np.arange(1, n+1) / n\n",
        "    return x, F\n",
        "\n",
        "def make_positive_for_log(x: np.ndarray, fallback=1e-18):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    pos = x[x > 0]\n",
        "    if pos.size == 0:\n",
        "        return np.full_like(x, fallback)\n",
        "    eps = float(np.min(pos)) * 0.5\n",
        "    eps = eps if eps > 0 else float(fallback)\n",
        "    return np.where(x > 0, x, eps)\n",
        "\n",
        "# ====== 금속 선택 로직: 메인 파이프라인과 동기화 ======\n",
        "EXCLUDE_SET = set(globals().get('EXCLUDE_SET', set()))\n",
        "ORDER = globals().get('ORDER', [])\n",
        "ACTIVE_ORDER = list(globals().get('ACTIVE_ORDER', [m for m in ORDER if m not in EXCLUDE_SET]))\n",
        "\n",
        "IUR = globals().get('IUR', {})\n",
        "C_sims = globals().get('C_sims', {})\n",
        "Kg = globals().get('Kg', {})\n",
        "assert 'Lifetime' in Kg, \"Kg['Lifetime']가 필요합니다.\"\n",
        "\n",
        "# 플로팅에 쓸 금속 = 활성 금속 중 IUR과 C_sims가 모두 존재하는 항목\n",
        "PLOT_METALS = [m for m in ACTIVE_ORDER if (m in IUR) and (m in C_sims) and (np.asarray(C_sims[m]).size > 0)]\n",
        "\n",
        "# === 특정 금속(예: As)만 그래프에서 제외하고 싶을 때 ===\n",
        "EXCLUDE_LOCAL = {'As'}   # 여기에 제외 금속 추가 / 예: {'As', 'Cd'}\n",
        "PLOT_METALS = [m for m in PLOT_METALS if m not in EXCLUDE_LOCAL]\n",
        "\n",
        "# 1) 금속별 LECR (활성 금속만)\n",
        "lecr_per_metal = {}\n",
        "for m in PLOT_METALS:\n",
        "    lecr_per_metal[m] = C_sims[m] * Kg['Lifetime'] * IUR[m]\n",
        "\n",
        "# 2) Total LECR (금속별 합; 활성 금속만)\n",
        "cumulative_lecr = None\n",
        "if lecr_per_metal:\n",
        "    cumulative_lecr = np.sum(list(lecr_per_metal.values()), axis=0)\n",
        "\n",
        "# 2-1) P95 계산 (금속별 + Total)\n",
        "lecr_p95 = {}\n",
        "for m, v in lecr_per_metal.items():\n",
        "    vv = np.asarray(v, float)\n",
        "    vv = vv[np.isfinite(vv)]\n",
        "    if vv.size > 0:\n",
        "        lecr_p95[m] = float(np.percentile(vv, 95))\n",
        "\n",
        "if cumulative_lecr is not None:\n",
        "    vt = np.asarray(cumulative_lecr, float)\n",
        "    vt = vt[np.isfinite(vt)]\n",
        "    if vt.size > 0:\n",
        "        lecr_p95['Total'] = float(np.percentile(vt, 95))\n",
        "\n",
        "# 3) ECDF 그리기\n",
        "TITLE_FT = 17   # 그래프 제목\n",
        "LABEL_FT = 17   # 축 제목\n",
        "TICK_FT  = 17   # 축 숫자\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "ax = plt.gca()\n",
        "\n",
        "# 금속별\n",
        "for m, v in lecr_per_metal.items():\n",
        "    v_plot = make_positive_for_log(v)\n",
        "    x, y = ecdf(v_plot)\n",
        "    if x.size > 0:\n",
        "        plt.step(x, y, where='post', label=m, alpha=0.9,\n",
        "                 color=COLORS.get(m, None), linewidth=4.0)\n",
        "\n",
        "# Total LECR (금속별 합)\n",
        "if cumulative_lecr is not None:\n",
        "    v_total = make_positive_for_log(cumulative_lecr)\n",
        "    x_all, y_all = ecdf(v_total)\n",
        "    if x_all.size > 0:\n",
        "        plt.step(x_all, y_all, where='post', label=\"Total\",\n",
        "                 linewidth=4.0, color=COLORS.get('Total', 'black'))\n",
        "\n",
        "# 기준선 (1e-6, 1e-4)\n",
        "for ref in [1e-6, 1e-4]:\n",
        "    ax.axvline(ref, linestyle='--', linewidth=3.5, alpha=0.9,\n",
        "               color=REFLINE_COLOR, zorder=1)\n",
        "    plt.text(ref, 0.02, f\"{ref:.0e}\", rotation=90, va='bottom', ha='right')\n",
        "\n",
        "# --- P95 세로선만 표시 ---\n",
        "for m, p95 in lecr_p95.items():\n",
        "    if np.isfinite(p95):\n",
        "        ax.axvline(p95,\n",
        "                   color=COLORS.get(m, 'black'),\n",
        "                   linestyle=':', linewidth=2.0, alpha=0.8,\n",
        "                   label=None)  # label=None\n",
        "\n",
        "# 서식 설정\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Lifetime Excess Cancer Risk', fontsize=LABEL_FT)\n",
        "plt.ylabel('Cumulative probability', fontsize=LABEL_FT)\n",
        "plt.title(\"ECDF of LECR (per metal & Total)\", fontsize=LABEL_FT, pad=8)\n",
        "\n",
        "plt.grid(False)\n",
        "ax.tick_params(axis='both', which='both', labelsize=TICK_FT)\n",
        "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "    label.set_fontweight('bold')\n",
        "\n",
        "# 범례\n",
        "leg = ax.legend(\n",
        "    title='Metals',\n",
        "    title_fontsize=15, fontsize=13,\n",
        "    loc='upper left',\n",
        "    bbox_to_anchor=(0.02, 0.98),\n",
        "    bbox_transform=ax.transAxes,\n",
        "    frameon=True, fancybox=True, framealpha=1.0,\n",
        "    borderpad=0.6, handlelength=2.0)\n",
        "leg.get_title().set_fontweight('bold')\n",
        "for text in leg.get_texts():\n",
        "    text.set_fontweight('bold')\n",
        "leg.get_frame().set_edgecolor('0.3')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 콘솔에 P95 요약만 출력\n",
        "print(\"=== LECR 95th percentile ===\")\n",
        "for k, v in lecr_p95.items():\n",
        "    print(f\"{k}: {v:.3e}\")"
      ],
      "metadata": {
        "id": "l2H4BJLAhJAH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}