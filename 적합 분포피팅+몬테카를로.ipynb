{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlbul1vvntS9R5oxhtGlsL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 전처리 코드 보완"
      ],
      "metadata": {
        "id": "WbTLlkGNgeqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Namhae PM2.5 Metals: Cleaning vFinal (for MC fitting & LECR)\n",
        "# 改: ND/MDL 수치화, PM2.5-금속 분리, 로그-IQR, IQR 로그 저장\n",
        "# 정책: 음수→정책(NaN/0), IQR 3.0 셀-마스킹, 행 삭제(대상 전부 NaN일 때만), 전/후 QA 리포트 저장\n",
        "# =========================\n",
        "\n",
        "# --- imports & display ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io, os, re\n",
        "from google.colab import files\n",
        "\n",
        "pd.options.display.float_format = \"{:.6g}\".format\n",
        "\n",
        "# =========================\n",
        "# 설정값 (네오 기준 확정안)\n",
        "# =========================\n",
        "CONFIRM_DETECTED_COLUMNS = True\n",
        "\n",
        "# 음수 처리 정책\n",
        "NEGATIVE_POLICY = \"nan\"  # [PATCH] 'nan' | 'zero' (장비 오프셋으로 근소 음수 → 0 고정 시 'zero')\n",
        "\n",
        "# IQR 셀-마스킹 적용 + 완화 기준(IQR_K=3.0)\n",
        "APPLY_IQR_FILTER = True\n",
        "IQR_K = 3.0\n",
        "LOG_IQR = True          # [PATCH] 금속 분포의 우측 꼬리 보호 위해 로그스케일 IQR 적용\n",
        "\n",
        "# 대상 전부 NaN인 행만 삭제\n",
        "DROP_EMPTY_TARGET = True\n",
        "\n",
        "# ND/MDL 처리 정책\n",
        "MDL_POLICY = \"uniform\"  # [PATCH] 'half'|'nan'|'uniform'\n",
        "RAND_SEED = 20250912    # [PATCH] 재현성 고정\n",
        "\n",
        "# =========================\n",
        "# 파일 업로드(Colab 위젯) + 메모리 직접 로드\n",
        "# =========================\n",
        "def _safe_basename(name: str) -> str:\n",
        "    base, ext = os.path.splitext(name)\n",
        "    base = re.sub(r\"[^\\w\\-]+\", \"_\", base).strip(\"_\")\n",
        "    return base, ext\n",
        "\n",
        "print(\"엑셀 파일(.xlsx) 1개 이상 업로드하세요.\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise RuntimeError(\"업로드된 파일이 없습니다. 다시 실행하여 업로드하세요.\")\n",
        "\n",
        "xlsx_names = [k for k in uploaded.keys() if k.lower().endswith(\".xlsx\")]\n",
        "if not xlsx_names:\n",
        "    raise RuntimeError(\"업로드된 파일 중 .xlsx 확장자가 없습니다.\")\n",
        "\n",
        "src_name = xlsx_names[0]\n",
        "print(\"Uploaded (in-memory):\", src_name)\n",
        "\n",
        "# 메모리에서 바로 DataFrame 로드\n",
        "df_raw = pd.read_excel(io.BytesIO(uploaded[src_name]))\n",
        "df_raw.columns = [str(c).strip() for c in df_raw.columns]\n",
        "\n",
        "# 원본 파일명 기반 산출물 경로 자동 설정\n",
        "_base, _ = _safe_basename(src_name)\n",
        "RAW_REPORT_PATH   = f\"{_base}_QA_raw.xlsx\"     # 전처리 전 QA\n",
        "CLEAN_REPORT_PATH = f\"{_base}_QA_clean.xlsx\"   # 전처리 후 QA (+ IQR_RULES 시트 추가)\n",
        "CLEAN_DATA_PATH   = f\"{_base}_clean.xlsx\"      # 전처리 후 데이터(엑셀)\n",
        "CLEAN_DATA_CSV    = f\"{_base}_clean.csv\"       # 전처리 후 데이터(CSV)\n",
        "\n",
        "print(\"Output paths set:\")\n",
        "print(\" RAW_REPORT_PATH   =\", RAW_REPORT_PATH)\n",
        "print(\" CLEAN_REPORT_PATH =\", CLEAN_REPORT_PATH)\n",
        "print(\" CLEAN_DATA_PATH   =\", CLEAN_DATA_PATH)\n",
        "print(\" CLEAN_DATA_CSV    =\", CLEAN_DATA_CSV)\n",
        "\n",
        "# =========================\n",
        "# 유틸: 컬럼 자동 검출\n",
        "# =========================\n",
        "def detect_columns(df: pd.DataFrame):\n",
        "    df = df.copy()\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "\n",
        "    # 시간 후보\n",
        "    time_candidates = [c for c in df.columns\n",
        "                       if any(k in c.lower() for k in [\"pump-begin\", \"date\", \"datetime\", \"time\", \"측정일시\"])]\n",
        "    time_col = time_candidates[0] if len(time_candidates) > 0 else None\n",
        "\n",
        "    # PM2.5 후보\n",
        "    pm25_candidates = [c for c in df.columns\n",
        "                       if (\"pm2.5\" in c.lower())\n",
        "                       or (\"con(ug/m3)\" in c.lower())\n",
        "                       or (\"ug/m3\" in c.lower() and \"con\" in c.lower())]\n",
        "    pm25_col = pm25_candidates[0] if len(pm25_candidates) > 0 else None\n",
        "\n",
        "    # 금속 단위 패턴\n",
        "    metal_markers = [\"(ng/m3)\", \"(ng/㎥)\", \"ng/m3\", \"ng/㎥\"]\n",
        "    metal_cols = [c for c in df.columns if any(m.lower() in c.lower() for m in metal_markers)]\n",
        "\n",
        "    # [PATCH] PM2.5가 ng/m³로 표기된 경우 금속 리스트에서 제외\n",
        "    if pm25_col:\n",
        "        metal_cols = [c for c in metal_cols if c != pm25_col]\n",
        "\n",
        "    # 숫자형 후보(참고용)\n",
        "    numeric_cols = []\n",
        "    for c in df.columns:\n",
        "        ser = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "        if ser.notna().mean() >= 0.7:\n",
        "            numeric_cols.append(c)\n",
        "\n",
        "    return {\"time_col\": time_col, \"pm25_col\": pm25_col,\n",
        "            \"metal_cols\": metal_cols, \"numeric_cols\": numeric_cols}\n",
        "\n",
        "# =========================\n",
        "# 로드 & 자동 검출 결과 출력\n",
        "# =========================\n",
        "detected = detect_columns(df_raw)\n",
        "time_col   = detected[\"time_col\"]\n",
        "pm25_col   = detected[\"pm25_col\"]\n",
        "metal_cols = detected[\"metal_cols\"]\n",
        "numeric_cols = detected[\"numeric_cols\"]\n",
        "\n",
        "print(\"Detected time_col:\", time_col)\n",
        "print(\"Detected pm25_col:\", pm25_col)\n",
        "print(\"Detected metal_cols (first 10):\", metal_cols[:10])\n",
        "print(\"Detected numeric_cols (first 10):\", numeric_cols[:10])\n",
        "\n",
        "if not CONFIRM_DETECTED_COLUMNS:\n",
        "    raise RuntimeError(\"자동 검출된 컬럼 확인 후, 맞으면 CONFIRM_DETECTED_COLUMNS=True로 설정하세요.\")\n",
        "\n",
        "# =========================\n",
        "# QA 리포트 함수\n",
        "# =========================\n",
        "def summarize_series(s: pd.Series, name: str):\n",
        "    s_num = pd.to_numeric(s, errors=\"coerce\")\n",
        "    return pd.Series({\n",
        "        \"col\": name,\n",
        "        \"count_total\": int(s_num.shape[0]),\n",
        "        \"count_valid\": int(s_num.notna().sum()),\n",
        "        \"valid_pct\": float(100.0 * s_num.notna().mean()),\n",
        "        \"mean\": float(s_num.mean(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"std\": float(s_num.std(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"p5\": float(s_num.quantile(0.05)) if s_num.notna().any() else np.nan,\n",
        "        \"p50\": float(s_num.quantile(0.50)) if s_num.notna().any() else np.nan,\n",
        "        \"p95\": float(s_num.quantile(0.95)) if s_num.notna().any() else np.nan,\n",
        "        \"min\": float(s_num.min(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "        \"max\": float(s_num.max(skipna=True)) if s_num.notna().any() else np.nan,\n",
        "    })\n",
        "\n",
        "def build_qc_table(df: pd.DataFrame, targets: list):\n",
        "    rows = []\n",
        "    for c in targets:\n",
        "        if c in df.columns:\n",
        "            rows.append(summarize_series(df[c], c))\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# =========================\n",
        "# 대상 컬럼 정의\n",
        "# =========================\n",
        "target_cols = []\n",
        "if pm25_col:\n",
        "    target_cols.append(pm25_col)\n",
        "if isinstance(metal_cols, (list, tuple)):\n",
        "    target_cols += list(metal_cols)\n",
        "target_cols = [c for c in target_cols if c in df_raw.columns]\n",
        "assert len(target_cols) > 0, \"PM2.5 또는 금속 대상 컬럼을 찾지 못했습니다.\"\n",
        "\n",
        "# =========================\n",
        "# QA 리포트(전처리 전)\n",
        "# =========================\n",
        "qc_raw = build_qc_table(df_raw, target_cols)\n",
        "with pd.ExcelWriter(RAW_REPORT_PATH, engine=\"openpyxl\") as w:\n",
        "    qc_raw.to_excel(w, index=False, sheet_name=\"RAW_QA\")\n",
        "\n",
        "# =========================\n",
        "# [PATCH] ND/MDL 파서 (재현성 보장)\n",
        "# =========================\n",
        "_rs = np.random.RandomState(RAND_SEED)\n",
        "\n",
        "def parse_mdl_like(s):\n",
        "    s = str(s).strip().replace(',', '')\n",
        "    # <a or ≤a\n",
        "    m = re.match(r'^[<≤]\\s*([0-9]*\\.?[0-9]+)$', s)\n",
        "    if m:\n",
        "        a = float(m.group(1))\n",
        "        if MDL_POLICY == 'half':\n",
        "            return a / 2.0\n",
        "        elif MDL_POLICY == 'uniform':\n",
        "            return float(_rs.uniform(0.0, a))\n",
        "        else:  # 'nan'\n",
        "            return np.nan\n",
        "    # 공통 토큰\n",
        "    if s.upper() in {\"ND\", \"N.D.\", \"MDL\", \"BDL\", \"-\", \"--\", \"\"}:\n",
        "        return np.nan\n",
        "    # 일반 숫자\n",
        "    try:\n",
        "        return float(s)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# =========================\n",
        "# 전처리\n",
        "# =========================\n",
        "df_clean = df_raw.copy()\n",
        "\n",
        "# 시간 정렬\n",
        "if (time_col is not None) and (time_col in df_clean.columns):\n",
        "    df_clean[time_col] = pd.to_datetime(df_clean[time_col], errors=\"coerce\")\n",
        "    df_clean = df_clean.sort_values(time_col).reset_index(drop=True)\n",
        "\n",
        "# 대상만 숫자화(별도 프레임 보관) — ND/MDL 포함 처리\n",
        "num_targets = df_clean[target_cols].applymap(parse_mdl_like)\n",
        "\n",
        "# --- 음수 처리 정책 ---\n",
        "neg_before = int((pd.DataFrame(num_targets) < 0).sum().sum())\n",
        "if NEGATIVE_POLICY == \"zero\":\n",
        "    num_targets = num_targets.mask(num_targets < 0, 0.0)\n",
        "else:  # \"nan\"\n",
        "    num_targets = num_targets.mask(num_targets < 0, np.nan)\n",
        "\n",
        "# --- IQR 셀-마스킹 (행 삭제 금지) ---\n",
        "cells_masked = 0\n",
        "iqr_log_rows = []  # [PATCH] IQR 기준/마스킹 카운트 기록\n",
        "if APPLY_IQR_FILTER:\n",
        "    # 로그 스케일 선택\n",
        "    X_ref = np.log1p(num_targets) if LOG_IQR else num_targets\n",
        "\n",
        "    # 컬럼별 IQR 기준 계산 및 마스킹\n",
        "    for c in num_targets.columns:\n",
        "        x = X_ref[c]\n",
        "        q1 = x.quantile(0.25)\n",
        "        q3 = x.quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lo = q1 - IQR_K * iqr\n",
        "        hi = q3 + IQR_K * iqr\n",
        "\n",
        "        # 해당 기준으로 원래 스케일 값에 마스킹 적용 (기준은 X_ref 기준)\n",
        "        mask = (x < lo) | (x > hi)\n",
        "        mcount = int(mask.sum())\n",
        "        cells_masked += mcount\n",
        "        num_targets.loc[mask, c] = np.nan\n",
        "\n",
        "        # [PATCH] IQR 로그 기록\n",
        "        iqr_log_rows.append({\n",
        "            \"col\": c,\n",
        "            \"Q1\": float(q1) if np.isfinite(q1) else np.nan,\n",
        "            \"Q3\": float(q3) if np.isfinite(q3) else np.nan,\n",
        "            \"IQR\": float(iqr) if np.isfinite(iqr) else np.nan,\n",
        "            \"lower\": float(lo) if np.isfinite(lo) else np.nan,\n",
        "            \"upper\": float(hi) if np.isfinite(hi) else np.nan,\n",
        "            \"masked\": mcount,\n",
        "            \"log_scale\": LOG_IQR,\n",
        "            \"k\": IQR_K\n",
        "        })\n",
        "\n",
        "# 대상 컬럼 적용\n",
        "df_clean[target_cols] = num_targets\n",
        "\n",
        "# --- 대상 전부 NaN 행 삭제(선택) ---\n",
        "rows_before_drop_empty = len(df_clean)\n",
        "if DROP_EMPTY_TARGET:\n",
        "    df_clean = df_clean.dropna(subset=target_cols, how=\"all\").reset_index(drop=True)\n",
        "rows_dropped_empty = rows_before_drop_empty - len(df_clean)\n",
        "\n",
        "neg_after = int((df_clean[target_cols].apply(pd.to_numeric, errors=\"coerce\") < 0).sum().sum())\n",
        "\n",
        "# =========================\n",
        "# 요약 출력\n",
        "# =========================\n",
        "print(\"=== Cleaning Summary ===\")\n",
        "print(f\"Target columns (n={len(target_cols)}): {target_cols[:6]}{' ...' if len(target_cols)>6 else ''}\")\n",
        "print(f\"Negatives (before -> after): {neg_before} -> {neg_after}\")\n",
        "print(f\"IQR masked cells (k={IQR_K}, log={LOG_IQR}): {cells_masked}\")\n",
        "print(f\"Empty-target dropped rows: {rows_dropped_empty}\")\n",
        "print(f\"Shape: raw {df_raw.shape} -> clean {df_clean.shape}\")\n",
        "\n",
        "# =========================\n",
        "# QA 리포트(전처리 후)\n",
        "# =========================\n",
        "qc_clean = build_qc_table(df_clean, target_cols)\n",
        "\n",
        "with pd.ExcelWriter(CLEAN_REPORT_PATH, engine=\"openpyxl\") as w:\n",
        "    qc_clean.to_excel(w, index=False, sheet_name=\"CLEAN_QA\")\n",
        "    # [PATCH] IQR 기준 및 마스킹 로그 추가 저장\n",
        "    if APPLY_IQR_FILTER:\n",
        "        iqr_df = pd.DataFrame(iqr_log_rows, columns=[\n",
        "            \"col\",\"Q1\",\"Q3\",\"IQR\",\"lower\",\"upper\",\"masked\",\"log_scale\",\"k\"\n",
        "        ])\n",
        "        iqr_df.to_excel(w, index=False, sheet_name=\"IQR_RULES\")\n",
        "\n",
        "# =========================\n",
        "# 저장 + 다운로드\n",
        "# =========================\n",
        "df_clean.to_excel(CLEAN_DATA_PATH, index=False)\n",
        "df_clean.to_csv(CLEAN_DATA_CSV, index=False)\n",
        "\n",
        "files.download(CLEAN_DATA_PATH)\n",
        "files.download(CLEAN_REPORT_PATH)\n",
        "files.download(RAW_REPORT_PATH)\n",
        "# 필요 시 CSV도:\n",
        "# files.download(CLEAN_DATA_CSV)"
      ],
      "metadata": {
        "id": "Wp4UE_FvghRN",
        "outputId": "6b6605d0-ab38-4fa0-f59c-6c6a6e150d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "엑셀 파일(.xlsx) 1개 이상 업로드하세요.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7743ca08-1930-4554-9717-b30f55e60bc6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7743ca08-1930-4554-9717-b30f55e60bc6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 202501_04.xlsx to 202501_04.xlsx\n",
            "Uploaded (in-memory): 202501_04.xlsx\n",
            "Output paths set:\n",
            " RAW_REPORT_PATH   = 202501_04_QA_raw.xlsx\n",
            " CLEAN_REPORT_PATH = 202501_04_QA_clean.xlsx\n",
            " CLEAN_DATA_PATH   = 202501_04_clean.xlsx\n",
            " CLEAN_DATA_CSV    = 202501_04_clean.csv\n",
            "Detected time_col: Pump-Begin\n",
            "Detected pm25_col: Conc(ug/m3)\n",
            "Detected metal_cols (first 10): ['Cr(ng/m3)', 'Co(ng/m3)', 'Ni(ng/m3)', 'As(ng/m3)', 'Cd(ng/m3)', 'Sb(ng/m3)', 'Pb(ng/m3)']\n",
            "Detected numeric_cols (first 10): ['Pump-Begin', 'Pump-End', 'MassResetTime', 'Conc(ug/m3)', 'Cr(ng/m3)', 'Co(ng/m3)', 'Ni(ng/m3)', 'As(ng/m3)', 'Cd(ng/m3)', 'Sb(ng/m3)']\n",
            "=== Cleaning Summary ===\n",
            "Target columns (n=8): ['Conc(ug/m3)', 'Cr(ng/m3)', 'Co(ng/m3)', 'Ni(ng/m3)', 'As(ng/m3)', 'Cd(ng/m3)'] ...\n",
            "Negatives (before -> after): 1817 -> 0\n",
            "IQR masked cells (k=3.0, log=True): 26\n",
            "Empty-target dropped rows: 1\n",
            "Shape: raw (1683, 11) -> clean (1682, 11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1785478853.py:207: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  num_targets = df_clean[target_cols].applymap(parse_mdl_like)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_93e1d603-af1b-427b-b1b0-0e5ecff1728d\", \"202501_04_clean.xlsx\", 98684)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9c8490e8-088e-408f-97a4-c9f76f686a40\", \"202501_04_QA_clean.xlsx\", 7057)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dfad3eb7-b2c9-4c6f-8b1c-2c12c4e67a5b\", \"202501_04_QA_raw.xlsx\", 5705)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b62GosovgjFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 통합 파이프라인\n",
        "# ============================================================\n",
        "\n",
        "# ---------- Imports ----------\n",
        "from google.colab import files\n",
        "import os, re, json, math, warnings, glob\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import kstest\n",
        "from scipy.stats import (\n",
        "    gumbel_r, gumbel_l, lognorm, weibull_min, logistic,\n",
        "    norm, gamma, beta, triang, expon, pareto, uniform, chi2\n",
        ")\n",
        "from scipy.stats import t as student_t\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
        "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---------- 사용자 설정 ----------\n",
        "np.random.seed(20250912)\n",
        "N_SIM       = 10_000\n",
        "BOOTSTRAP_B = 200\n",
        "CD_INCLUDE  = True\n",
        "SAVE_DIR    = \"outputs\"\n",
        "\n",
        "# ---------- 고정 상수 ----------\n",
        "IUR = {\"Cr(VI)\":1.20e-02,\"Co\":9.00e-03,\"Ni\":2.40e-04,\"As\":4.30e-03,\"Cd\":1.80e-03,\"Sb\":2.29e-06,\"Pb\":1.20e-05}\n",
        "ORDER = ['Cr','Cr(VI)','Co','Ni','As','Cd','Sb','Pb']\n",
        "\n",
        "ENG_NAME = {\n",
        "    '로그 정규':'Lognormal', '와이블':'Weibull', '감마':'Gamma', '지수':'Exponential',\n",
        "    '최대 극값':'Gumbel Max', '최소 극값':'Gumbel Min', '정규':'Normal', '로지스틱':'Logistic',\n",
        "    \"스튜던트의 t\":\"Student's t\", '베타':'Beta', 'BetaPERT':'BetaPERT',\n",
        "    '삼각형':'Triangular', '균일':'Uniform', '파레토':'Pareto'}\n",
        "\n",
        "# ===== [추가] 분포별 라인 색상 팔레트 =====\n",
        "DIST_COLOR = {\n",
        "    'Lognormal': 'tab:orange',\n",
        "    'Weibull': 'tab:green',\n",
        "    'Gamma': 'tab:purple',\n",
        "    'Exponential': 'tab:red',\n",
        "    'Gumbel Max': 'tab:olive',\n",
        "    'Gumbel Min': 'tab:cyan',\n",
        "    'Normal': 'tab:blue',\n",
        "    'Logistic': 'tab:pink',\n",
        "    \"Student's t\": 'tab:brown',\n",
        "    'Beta': 'tab:gray',\n",
        "    'BetaPERT': 'tab:purple',\n",
        "    'Triangular': 'tab:teal',\n",
        "    'Uniform': 'tab:cyan',\n",
        "    'Pareto': 'tab:red',\n",
        "}\n",
        "\n",
        "# --- 패턴 ---\n",
        "PAT = {\n",
        "    \"Cr(VI)\": r\"(?:\\bCr\\s*VI\\b|\\bCr[-\\s]*VI\\b|\\bCr\\s*6\\+\\b|Cr[-\\s]*6\\+|Hexa(?:valent)?\\s*Chrom(?:ium)?|6가\\s*크롬|육가\\s*크롬|육가크롬)\",\n",
        "    \"Cr\"    : r\"(?:\\bCr\\b(?!\\s*(?:VI|6\\+))|Chromium|크롬)\",\n",
        "    \"Co\"    : r\"(?:\\bCo\\b|\\bC\\s*o\\b|Cobalt|코발트)\",\n",
        "    \"Ni\"    : r\"(?:\\bNi\\b|\\bN\\s*i\\b|Nickel|니켈)\",\n",
        "    \"As\"    : r\"(?:\\bA\\s*s\\b|\\bAs\\b(?=[\\s\\(\\[]|$)|Arsenic|비소)\",\n",
        "    \"Cd\"    : r\"(?:\\bCd\\b|\\bC\\s*d\\b|Cadmium|카드뮴)\",\n",
        "    \"Sb\"    : r\"(?:\\bS[bB]\\b|\\bS\\s*B\\b|Stibium|Antimon(?:y)?|안티몬)\",\n",
        "    \"Pb\"    : r\"(?:\\bPb\\b|\\bP\\s*b\\b|Lead|납)\"\n",
        "}\n",
        "\n",
        "# Excel 스타일\n",
        "HEADER_BLUE = '2F5597'; BEST_FILL='FFF2CC'; THIN_GRAY='999999'; TABLE_STYLE=\"TableStyleMedium9\"\n",
        "\n",
        "# 노출 파라미터\n",
        "EF_days_per_year = 350; EF = EF_days_per_year/365.0\n",
        "LT_years = 78.6\n",
        "ACT_POINT = {\"0-<1\":24,\"1-<2\":84,\"2-<3\":120,\"3-<6\":108,\"6-<11\":132,\"11-<16\":102,\"16-<18\":102}\n",
        "ACT_LN_P5_P95 = {\"18-<25\":(14.455,250.0),\"25-<35\":(6.516,220.0),\"35-<45\":(5.789,195.0),\n",
        "                 \"45-<55\":(6.401,260.0),\"55-<65\":(8.083,350.0),\"65-<78.6\":(6.094,390.0)}\n",
        "ED_years = {\"0-<1\":1,\"1-<2\":1,\"2-<3\":1,\"3-<6\":3,\"6-<11\":5,\"11-<16\":5,\"16-<18\":2,\n",
        "            \"18-<25\":7,\"25-<35\":10,\"35-<45\":10,\"45-<55\":10,\"55-<65\":10,\"65-<78.6\":13.6}\n",
        "AGE_ORDER=[\"0-<1\",\"1-<2\",\"2-<3\",\"3-<6\",\"6-<11\",\"11-<16\",\"16-<18\",\"18-<25\",\"25-<35\",\"35-<45\",\"45-<55\",\"55-<65\",\"65-<78.6\"]\n",
        "INFANT = [\"0-<1\",\"1-<2\"]; CHILD=[\"2-<3\",\"3-<6\",\"6-<11\",\"11-<16\",\"16-<18\"]; ADULT=[\"18-<25\",\"25-<35\",\"35-<45\",\"45-<55\",\"55-<65\",\"65-<78.6\"]\n",
        "\n",
        "# RNG helpers\n",
        "_master_rs = np.random.RandomState(20250912)\n",
        "def child_rs(): return np.random.RandomState(_master_rs.randint(0, 2**31-1))\n",
        "_mdl_rs = child_rs()  # ND/MDL 치환용 난수원\n",
        "\n",
        "# ============================================================\n",
        "# 유틸\n",
        "# ============================================================\n",
        "def freedman_diaconis_bins(x, min_bins=30, max_bins=70):\n",
        "    x = np.asarray(x, float); x = x[np.isfinite(x)]\n",
        "    n = x.size\n",
        "    if n < 2: return max(2, min_bins)\n",
        "    q75, q25 = np.percentile(x, [75, 25]); iqr = q75 - q25\n",
        "    if iqr <= 0: return max(min_bins, min(max_bins, int(np.sqrt(n))))\n",
        "    h = 2 * iqr * (n ** (-1/3))\n",
        "    if h <= 0: return max(min_bins, min(max_bins, int(np.sqrt(n))))\n",
        "    bins = int(np.ceil((x.max() - x.min()) / h))\n",
        "    return max(2, max(min_bins, min(max_bins, bins)))\n",
        "\n",
        "# --- ND/<MDL> 수치화 ---\n",
        "MDL_POLICY = \"uniform\"  # \"half\" | \"nan\" | \"uniform\"\n",
        "def coerce_numeric_with_mdl(s):\n",
        "    s = pd.Series(s).astype(str).str.strip().str.replace(',', '', regex=False)\n",
        "\n",
        "    # <a or ≤a → half*a / NaN / Uniform(0,a)\n",
        "    m = s.str.match(r'^[<≤]\\s*([0-9]*\\.?[0-9]+)$')\n",
        "    if m.any():\n",
        "        vals = s[m].str.replace('≤','<',regex=False).str.replace('<','',regex=False).astype(float).values\n",
        "        if MDL_POLICY == 'half':\n",
        "            s.loc[m] = (vals/2.0)\n",
        "        elif MDL_POLICY == 'nan':\n",
        "            s.loc[m] = np.nan\n",
        "        elif MDL_POLICY == 'uniform':\n",
        "            # Uniform(0, a) 샘플\n",
        "            u = _mdl_rs.uniform(0.0, 1.0, size=len(vals))\n",
        "            s.loc[m] = vals * u\n",
        "        else:\n",
        "            s.loc[m] = (vals/2.0)\n",
        "\n",
        "    # common tokens → NaN\n",
        "    s = s.replace({'ND':np.nan,'N.D.':np.nan,'MDL':np.nan,'BDL':np.nan,'-':np.nan,'--':np.nan,'':np.nan}, regex=False)\n",
        "    return pd.to_numeric(s, errors='coerce')\n",
        "\n",
        "def hist_mode_estimate(x):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "    if x.size<2: return float(np.nanmedian(x)) if x.size else np.nan\n",
        "    iqr=np.subtract(*np.percentile(x,[75,25]))\n",
        "    bins=max(10,int(np.sqrt(x.size))) if iqr<=0 else max(10,int(np.ceil((x.max()-x.min())/(2*iqr*x.size**(-1/3)))))\n",
        "    cnt,edges=np.histogram(x,bins=bins); i=int(cnt.argmax())\n",
        "    return float((edges[i]+edges[i+1])/2)\n",
        "\n",
        "# ============================================================\n",
        "# 1) 파일 업로드 & 시트 자동 선택\n",
        "# ============================================================\n",
        "print(\"엑셀 파일 업로드(.xlsx/.xls)\")\n",
        "up = files.upload()\n",
        "INPUT = next((k for k in up if k.lower().endswith(('.xlsx','.xls'))), None)\n",
        "if INPUT is None:\n",
        "    cand = sorted(glob.glob(\"*.xlsx\"))\n",
        "    if not cand: raise FileNotFoundError(\"엑셀 파일을 찾지 못했습니다.\")\n",
        "    INPUT = cand[-1]\n",
        "\n",
        "xls = pd.ExcelFile(INPUT)\n",
        "sheet_scores=[]\n",
        "for sh in xls.sheet_names:\n",
        "    try:\n",
        "        df_head = pd.read_excel(INPUT, sheet_name=sh, nrows=3)\n",
        "    except Exception:\n",
        "        df_head = pd.DataFrame()\n",
        "    score=0\n",
        "    for c in df_head.columns:\n",
        "        s=str(c)\n",
        "        score += sum(bool(re.search(p, s, flags=re.I)) for p in PAT.values())\n",
        "    sheet_scores.append((sh,score))\n",
        "sheet_scores.sort(key=lambda x:x[1], reverse=True)\n",
        "SHEET = sheet_scores[0][0]\n",
        "raw = pd.read_excel(INPUT, sheet_name=SHEET)\n",
        "print(f\"선택된 시트: {SHEET}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2) 단위 통일 & 열 자동 매칭 (+ Cr(VI) 파생)\n",
        "# ============================================================\n",
        "def find_col(df, regex):\n",
        "    for c in df.columns:\n",
        "        if re.search(regex, str(c), flags=re.I): return c\n",
        "    return None\n",
        "\n",
        "def to_ug(series, name):\n",
        "    header = str(name)\n",
        "    s = coerce_numeric_with_mdl(series).replace([np.inf, -np.inf], np.nan)\n",
        "    has_ug = bool(re.search(r'(?i)[µμu]\\s*g\\s*/?\\s*m\\^?3', header))\n",
        "    has_ng = bool(re.search(r'(?i)n\\s*g\\s*/?\\s*m\\^?3', header))\n",
        "    if has_ug: return (s, 'as_is_ug')\n",
        "    if has_ng: return (s/1000.0, 'converted_from_ng')\n",
        "    return (s, 'as_is_ug')\n",
        "\n",
        "series_map, log_rows = {}, []\n",
        "for m in ORDER:\n",
        "    if (m=='Cd') and (not CD_INCLUDE):\n",
        "        log_rows.append((m, None, 'excluded_by_flag', 0, np.nan)); continue\n",
        "    c = find_col(raw, PAT.get(m, r\"^\"))\n",
        "    if c is None:\n",
        "        log_rows.append((m, None, 'missing', 0, np.nan)); continue\n",
        "    v, how = to_ug(raw[c], c); series_map[m]=v\n",
        "    n_nonna = int(pd.to_numeric(v, errors='coerce').notna().sum())\n",
        "    log_rows.append((m, c, how, n_nonna, float(np.nanmean(v))))\n",
        "log = pd.DataFrame(log_rows, columns=['Metal','Matched_Column','Unit_Status','N_nonNa','Mean(ug/m3)'])\n",
        "\n",
        "# 디버그 요약\n",
        "print(\"\\n[DEBUG] 유효 표본수 요약:\", {m:int(pd.to_numeric(series_map[m],errors='coerce').notna().sum()) for m in series_map})\n",
        "\n",
        "# Cr(VI) 파생 (없으면 Cr/7)\n",
        "if ('Cr(VI)' not in series_map) and ('Cr' in series_map):\n",
        "    series_map['Cr(VI)'] = series_map['Cr']/7.0\n",
        "    log.loc[len(log)] = ['Cr(VI)','(derived from Cr/7)','derived',\n",
        "                         int(pd.to_numeric(series_map['Cr(VI)'],errors='coerce').notna().sum()),\n",
        "                         float(np.nanmean(series_map['Cr(VI)']))]\n",
        "\n",
        "# ============================================================\n",
        "# 3) 14개 분포 래퍼 + 적합도 함수\n",
        "# ============================================================\n",
        "class D:\n",
        "    def __init__(self,name): self.name=name; self.p={}; self.np=None; self.valid=False\n",
        "    def ok(self,p,np_): self.p=p; self.np=np_; self.valid=True; return self\n",
        "    def cdf(self,z): raise NotImplementedError\n",
        "    def ppf(self,q): raise NotImplementedError\n",
        "    def rvs(self,n,rs=None): raise NotImplementedError\n",
        "\n",
        "class LogNormal(D):\n",
        "    def __init__(self): super().__init__('로그 정규')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: s,loc,sc=lognorm.fit(x)\n",
        "        except: return self\n",
        "        if s>0 and sc>0 and np.isfinite(loc): return self.ok({'s':s,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return lognorm.cdf(z, s=self.p['s'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return lognorm.ppf(q, s=self.p['s'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return lognorm.rvs(self.p['s'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class Weibull(D):\n",
        "    def __init__(self): super().__init__('와이블')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: c,loc,sc=weibull_min.fit(x)\n",
        "        except: return self\n",
        "        if c>0 and sc>0 and np.isfinite(loc): return self.ok({'c':c,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return weibull_min.cdf(z, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return weibull_min.ppf(q, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return weibull_min.rvs(self.p['c'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class Gamma_(D):\n",
        "    def __init__(self): super().__init__('감마')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: a,loc,sc=gamma.fit(x)\n",
        "        except: return self\n",
        "        if a>0 and sc>0 and np.isfinite(loc): return self.ok({'a':a,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return gamma.cdf(z, a=self.p['a'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return gamma.ppf(q, a=self.p['a'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return gamma.rvs(self.p['a'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class LogisticD(D):\n",
        "    def __init__(self): super().__init__('로지스틱')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=logistic.fit(x)\n",
        "        except: return self\n",
        "        if sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return logistic.cdf(z, **self.p)\n",
        "    def ppf(self,q): return logistic.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return logistic.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class NormalD(D):\n",
        "    def __init__(self): super().__init__('정규')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: mu,sig=norm.fit(x)\n",
        "        except: return self\n",
        "        if sig>0: return self.ok({'loc':mu,'scale':sig},2)\n",
        "        return self\n",
        "    def cdf(self,z): return norm.cdf(z, **self.p)\n",
        "    def ppf(self,q): return norm.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return norm.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class StudentT(D):\n",
        "    def __init__(self): super().__init__('스튜던트의 t')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: df_,loc,sc=student_t.fit(x)\n",
        "        except: return self\n",
        "        if df_>0 and sc>0: return self.ok({'df':df_,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return student_t.cdf(z, **self.p)\n",
        "    def ppf(self,q): return student_t.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return student_t.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class Exponential_(D):\n",
        "    def __init__(self): super().__init__('지수')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=expon.fit(x)\n",
        "        except: return self\n",
        "        if sc>0 and np.isfinite(loc): return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return expon.cdf(z, loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return expon.ppf(q, loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return expon.rvs(size=n, loc=self.p['loc'], scale=self.p['scale'], random_state=rs)\n",
        "\n",
        "class BetaPERT_(D):\n",
        "    def __init__(self,lam=4.0): super().__init__('BetaPERT'); self.lam=lam\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        a,b=float(np.nanmin(x)),float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        m=float(np.clip(hist_mode_estimate(x), a+1e-9, b-1e-9))\n",
        "        al=1+self.lam*(m-a)/(b-a); be=1+self.lam*(b-m)/(b-a)\n",
        "        if al<=0 or be<=0: return self\n",
        "        return self.ok({'a':a,'b':b,'alpha':al,'beta':be,'m':m},2)\n",
        "    def cdf(self,z):\n",
        "        zz=(z-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        return beta.cdf(np.clip(zz,1e-9,1-1e-9), self.p['alpha'], self.p['beta'])\n",
        "    def ppf(self,q): return self.p['a']+(self.p['b']-self.p['a'])*beta.ppf(q, self.p['alpha'], self.p['beta'])\n",
        "    def rvs(self,n,rs=None):\n",
        "        r=beta.rvs(self.p['alpha'], self.p['beta'], size=n, random_state=rs)\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*r\n",
        "\n",
        "class Triangular_(D):\n",
        "    def __init__(self): super().__init__('삼각형')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        a,b=float(np.nanmin(x)),float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        m=float(np.clip(hist_mode_estimate(x), a+1e-9, b-1e-9))\n",
        "        c=(m-a)/(b-a)\n",
        "        if not(0.0 < c < 1.0): return self\n",
        "        return self.ok({'c':c,'loc':a,'scale':(b-a)},2)\n",
        "    def cdf(self,z): return triang.cdf(z, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return triang.ppf(q, c=self.p['c'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return triang.rvs(self.p['c'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "class Uniform_(D):\n",
        "    def __init__(self): super().__init__('균일')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<2: return self\n",
        "        a=float(np.nanmin(x)); b=float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        return self.ok({'loc':a,'scale':(b-a)},2)\n",
        "    def cdf(self,z): return uniform.cdf(z, **self.p)\n",
        "    def ppf(self,q): return uniform.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return uniform.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class GumbelR_(D):\n",
        "    def __init__(self): super().__init__('최대 극값')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=gumbel_r.fit(x)\n",
        "        except: return self\n",
        "        if np.isfinite(loc) and sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return gumbel_r.cdf(z, **self.p)\n",
        "    def ppf(self,q): return gumbel_r.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return gumbel_r.rvs(size=n, **self.p, random_state=rs)\n",
        "\n",
        "class GumbelL_(D):\n",
        "    def __init__(self): super().__init__('최소 극값')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: loc,sc=gumbel_l.fit(x)\n",
        "        except: return self\n",
        "        if np.isfinite(loc) and sc>0: return self.ok({'loc':loc,'scale':sc},2)\n",
        "        return self\n",
        "    def cdf(self,z): return gumbel_l.cdf(z, **self.p)\n",
        "    def ppf(self,q): return gumbel_l.ppf(q, **self.p)\n",
        "    def rvs(self,n,rs=None): return gumbel_l.rvs(size=n, random_state=rs, **self.p)\n",
        "\n",
        "class Beta_(D):\n",
        "    def __init__(self): super().__init__('베타')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        a=float(np.nanmin(x)); b=float(np.nanmax(x))\n",
        "        if not(np.isfinite(a) and np.isfinite(b) and b>a): return self\n",
        "        z=np.clip((x-a)/(b-a), 1e-9, 1-1e-9)\n",
        "        try: al,be,_,_ = beta.fit(z, floc=0, fscale=1)\n",
        "        except: return self\n",
        "        if (al>0) and (be>0): return self.ok({'a':a,'b':b,'alpha':al,'beta':be},2)\n",
        "        return self\n",
        "    def cdf(self,z):\n",
        "        zz=(z-self.p['a'])/(self.p['b']-self.p['a'])\n",
        "        return beta.cdf(np.clip(zz,1e-9,1-1e-9), self.p['alpha'], self.p['beta'])\n",
        "    def ppf(self,q):\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*beta.ppf(q, self.p['alpha'], self.p['beta'])\n",
        "    def rvs(self,n,rs=None):\n",
        "        r=beta.rvs(self.p['alpha'], self.p['beta'], size=n, random_state=rs)\n",
        "        return self.p['a']+(self.p['b']-self.p['a'])*r\n",
        "\n",
        "class Pareto_(D):\n",
        "    def __init__(self): super().__init__('파레토')\n",
        "    def fit(self,x):\n",
        "        x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "        if x.size<3: return self\n",
        "        try: b,loc,sc=pareto.fit(x)\n",
        "        except: return self\n",
        "        if b>0 and sc>0 and np.isfinite(loc): return self.ok({'b':b,'loc':loc,'scale':sc},3)\n",
        "        return self\n",
        "    def cdf(self,z): return pareto.cdf(z, b=self.p['b'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def ppf(self,q): return pareto.ppf(q, b=self.p['b'], loc=self.p['loc'], scale=self.p['scale'])\n",
        "    def rvs(self,n,rs=None): return pareto.rvs(self.p['b'], loc=self.p['loc'], scale=self.p['scale'], size=n, random_state=rs)\n",
        "\n",
        "# 적합도 통계\n",
        "def AD_stat(x, cdf, eps=1e-12):\n",
        "    x=np.sort(np.asarray(x,float)); n=x.size\n",
        "    if n<5: return np.inf\n",
        "    u=np.clip(cdf(x),eps,1-eps); i=np.arange(1,n+1)\n",
        "    return float(-n - np.sum((2*i-1)*(np.log(u)+np.log(1-u[::-1])))/n)\n",
        "\n",
        "def AD_p_boot_refit(x, dist_obj, B=BOOTSTRAP_B):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
        "    n=x.size\n",
        "    if n<5 or (not dist_obj.valid): return np.nan\n",
        "    A2_obs=AD_stat(x, dist_obj.cdf); ge=0; m=0\n",
        "    for _ in range(B):\n",
        "        rs=child_rs(); xs=dist_obj.rvs(n, rs=rs)\n",
        "        d=type(dist_obj)(); d.fit(xs)\n",
        "        if not d.valid: continue\n",
        "        A2_bs=AD_stat(xs, d.cdf); ge+=(A2_bs>=A2_obs); m+=1\n",
        "    return float((ge+1)/(m+1)) if m>0 else np.nan\n",
        "\n",
        "def KS_stat_p(x, d):\n",
        "    try:\n",
        "        D, p = kstest(x, lambda z: d.cdf(z))\n",
        "        return float(D), float(p)\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def Chi2_stat_p(x,d):\n",
        "    try:\n",
        "        n=len(x); N=max(5,min(50,n//5)); eps=1e-6\n",
        "        qs=np.linspace(eps,1-eps,N+1); edges=np.unique(d.ppf(qs))\n",
        "        if len(edges)<3: return np.nan,np.nan\n",
        "        obs,_=np.histogram(x,bins=edges); exp=np.diff(qs)*n\n",
        "        k=d.np or 0; df=len(obs)-1-k\n",
        "        if df<=0: return np.nan,np.nan\n",
        "        exp=np.maximum(exp[:len(obs)],1e-9)\n",
        "        chi=np.sum((obs-exp)**2/exp); p=1.0-chi2.cdf(chi,df)\n",
        "        return float(chi), float(p)\n",
        "    except: return np.nan,np.nan\n",
        "\n",
        "def pstr(name,p):\n",
        "    try:\n",
        "        if name=='정규':         return f\"평균={p['loc']:.5g}, 표준 편차={p['scale']:.5g}\"\n",
        "        if name=='로지스틱':     return f\"평균={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='최대 극값':    return f\"최고가능성={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='최소 극값':    return f\"최고가능성={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='지수':         return f\"위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='로그 정규':    return f\"형태={p['s']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='와이블':       return f\"형태={p['c']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='감마':         return f\"형태={p['a']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='스튜던트의 t': return f\"자유도={p['df']:.5g}, 위치={p['loc']:.5g}, 스케일={p['scale']:.5g}\"\n",
        "        if name=='베타':         return f\"최소={p['a']:.5g}, 최대={p['b']:.5g}, 알파={p['alpha']:.5g}, 베타={p['beta']:.5g}\"\n",
        "        if name=='BetaPERT':    return f\"최소={p['a']:.5g}, 최빈값={p['m']:.5g}, 최대={p['b']:.5g}, 알파={p['alpha']:.5g}, 베타={p['beta']:.5g}\"\n",
        "        if name=='삼각형':       return f\"최소={p['loc']:.5g}, 최빈값={(p['loc']+p['c']*p['scale']):.5g}, 최대={(p['loc']+p['scale']):.5g}\"\n",
        "        if name=='균일':         return f\"최소={p['loc']:.5g}, 최대={(p['loc']+p['scale']):.5g}\"\n",
        "        if name=='파레토':       return f\"위치={p['loc']:.5g}, 스케일={p['scale']:.5g}, 형태={p['b']:.5g}\"\n",
        "        return json.dumps(p, ensure_ascii=False)\n",
        "    except Exception:\n",
        "        return json.dumps(p, ensure_ascii=False)\n",
        "\n",
        "# ============================================================\n",
        "# 4) 분포 피팅 & 랭킹\n",
        "# ============================================================\n",
        "def fit_one(x):\n",
        "    x=pd.Series(x, dtype=float).replace([np.inf,-np.inf], np.nan).dropna().values\n",
        "    if x.size < 8: return None\n",
        "    if np.unique(x).size < 3:\n",
        "        return None\n",
        "    cands=[LogNormal(),Gamma_(),Weibull(),LogisticD(),NormalD(),StudentT(),\n",
        "           Exponential_(),BetaPERT_(),Triangular_(),Uniform_(),GumbelR_(),GumbelL_(),\n",
        "           Beta_(), Pareto_()]\n",
        "    rows=[]\n",
        "    for d in cands:\n",
        "        d.fit(x)\n",
        "        if not d.valid:\n",
        "            rows.append({'분포':d.name,'AD':np.inf,'ADp':np.nan,'KS':np.nan,'KSp':np.nan,\n",
        "                         'Chi2':np.nan,'Chi2p':np.nan,'np':1e9,'obj':d})\n",
        "            continue\n",
        "        A2=AD_stat(x, d.cdf); pAD=AD_p_boot_refit(x, d, BOOTSTRAP_B)\n",
        "        D,pks=KS_stat_p(x,d); chi,pchi=Chi2_stat_p(x,d)\n",
        "        rows.append({'분포':d.name,'AD':A2,'ADp':pAD,'KS':D,'KSp':pks,\n",
        "                     'Chi2':chi,'Chi2p':pchi,'np':d.np or 9,'obj':d})\n",
        "    df=pd.DataFrame(rows)\n",
        "    ksp_key  = -df['KSp'].fillna(-np.inf)\n",
        "    chi2_key = -df['Chi2p'].fillna(-np.inf)\n",
        "    df['_key'] = list(zip(df['AD'].fillna(np.inf), ksp_key, chi2_key, df['np'].fillna(np.inf)))\n",
        "    df=df.sort_values('_key', kind='mergesort').drop(columns=['_key']).reset_index(drop=True)\n",
        "    best=df.iloc[0]\n",
        "    return best, df\n",
        "\n",
        "fit_tables={}\n",
        "for m in ORDER:\n",
        "    if (m=='Cd') and (not CD_INCLUDE):\n",
        "        fit_tables[m]={'best':None,'table':pd.DataFrame()}; continue\n",
        "    s = series_map.get(m, None)\n",
        "    if s is None:\n",
        "        fit_tables[m]={'best':None,'table':pd.DataFrame()}; continue\n",
        "    res=fit_one(s.values)\n",
        "    fit_tables[m] = {'best':None,'table':pd.DataFrame()} if res is None else {'best':res[0],'table':res[1]}\n",
        "\n",
        "# ============================================================\n",
        "# 5) 히스토그램 + 최적 PDF  (y축=빈도, PDF=빈도 스케일로 오버레이 + 캡 + 분포별 색상 적용)\n",
        "# ============================================================\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(f\"{SAVE_DIR}/plots\", exist_ok=True)\n",
        "\n",
        "def plot_hist_with_fit(ax, data, dist_obj, title, bins=None):\n",
        "    x = np.asarray(pd.to_numeric(data, errors='coerce'), float)\n",
        "    x = x[np.isfinite(x)]\n",
        "    n = x.size\n",
        "    ax.cla()\n",
        "\n",
        "    if n == 0:\n",
        "        ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=10)\n",
        "        ax.set_title(title); ax.set_xlabel(\"Concentration (µg/m³)\"); ax.set_ylabel(\"Frequency\")\n",
        "        ax.grid(True, alpha=0.25); return\n",
        "\n",
        "    if (bins is None) or (isinstance(bins, int) and bins <= 0):\n",
        "        bins = freedman_diaconis_bins(x, 30, 70)\n",
        "\n",
        "    # 히스토그램: 빈도\n",
        "    counts, edges, _ = ax.hist(x, bins=bins, density=False, alpha=0.5, edgecolor='k')\n",
        "    bin_width = np.diff(edges).mean()\n",
        "\n",
        "    # 최적분포 PDF를 빈도 스케일(n*bin_width)로 오버레이\n",
        "    if (dist_obj is not None) and getattr(dist_obj, 'valid', False):\n",
        "\n",
        "        # ===== [추가] 끝단 트리밍 (ppf 기반) =====\n",
        "        q_lo, q_hi = 0.0005, 0.9995\n",
        "        try:\n",
        "            lo_q = float(dist_obj.ppf(q_lo))\n",
        "            hi_q = float(dist_obj.ppf(q_hi))\n",
        "        except Exception:\n",
        "            lo_q, hi_q = np.nan, np.nan\n",
        "        lo = edges[0]  if (not np.isfinite(lo_q)) else max(edges[0],  lo_q)\n",
        "        hi = edges[-1] if (not np.isfinite(hi_q)) else min(edges[-1], hi_q)\n",
        "        if not (np.isfinite(lo) and np.isfinite(hi) and hi > lo):\n",
        "            lo, hi = edges[0], edges[-1]\n",
        "\n",
        "        xs = np.linspace(lo, hi, 600)\n",
        "\n",
        "        pdf = None\n",
        "        EPS = 1e-9\n",
        "        try:\n",
        "            name = dist_obj.name; p = dist_obj.p\n",
        "            if name == '로그 정규':\n",
        "                pdf = lognorm.pdf(xs, s=p['s'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '와이블':\n",
        "                pdf = weibull_min.pdf(xs, c=p['c'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '감마':\n",
        "                pdf = gamma.pdf(xs, a=p['a'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '지수':\n",
        "                pdf = expon.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '최대 극값':\n",
        "                pdf = gumbel_r.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '최소 극값':\n",
        "                pdf = gumbel_l.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '정규':\n",
        "                pdf = norm.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '로지스틱':\n",
        "                pdf = logistic.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '스튜던트의 t':\n",
        "                pdf = student_t.pdf(xs, df=p['df'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name in ('베타','BetaPERT'):\n",
        "                zz = np.clip((xs - p['a'])/(p['b']-p['a']), EPS, 1 - EPS)\n",
        "                pdf = beta.pdf(zz, p['alpha'], p['beta']) / (p['b']-p['a'])\n",
        "            elif name == '삼각형':\n",
        "                pdf = triang.pdf(xs, c=p['c'], loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '균일':\n",
        "                pdf = uniform.pdf(xs, loc=p['loc'], scale=p['scale'])\n",
        "            elif name == '파레토':\n",
        "                pdf = pareto.pdf(xs, b=p['b'], loc=p['loc'], scale=p['scale'])\n",
        "        except Exception:\n",
        "            pdf = None\n",
        "\n",
        "        if pdf is None:\n",
        "            cdf_vals = dist_obj.cdf(xs)\n",
        "            pdf = np.gradient(cdf_vals, xs)\n",
        "\n",
        "        y_pdf = pdf * (n * bin_width)\n",
        "\n",
        "        # ===== [유지] 팔레트 + y축 캡 =====\n",
        "        disp_name = ENG_NAME.get(dist_obj.name, dist_obj.name)\n",
        "        color = DIST_COLOR.get(disp_name, None)\n",
        "        ax.plot(xs, y_pdf, lw=2, label=disp_name, color=color)\n",
        "        ax.legend()\n",
        "\n",
        "        # y축 캡(특히 Beta 끝점 발산 방지) — 기존 로직 유지\n",
        "        y_hist_max = float(np.max(counts)) if len(counts) else 1.0\n",
        "        y_pdf_max  = float(np.nanmax(y_pdf)) if np.all(np.isfinite(y_pdf)) else y_hist_max\n",
        "        ax.set_ylim(0, min(max(y_hist_max, y_pdf_max)*1.2, y_hist_max*20.0))\n",
        "\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Concentration (µg/m³)\")\n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "    ax.grid(True, alpha=0.25)\n",
        "\n",
        "# 4x2 패널 요약 그림\n",
        "fig, axes = plt.subplots(4, 2, figsize=(12, 16))\n",
        "axes = axes.ravel()\n",
        "idx = 0\n",
        "for m in ORDER:\n",
        "    if (m == 'Cd') and (not CD_INCLUDE): continue\n",
        "    data = series_map.get(m, pd.Series(dtype=float))\n",
        "    best = fit_tables.get(m, {}).get('best')\n",
        "    obj  = best['obj'] if (best is not None and best.get('obj') is not None and best['obj'].valid) else None\n",
        "    plot_hist_with_fit(axes[idx], data, obj, m)\n",
        "    idx += 1\n",
        "    if idx >= 8: break\n",
        "while idx < 8:\n",
        "    axes[idx].axis('off'); idx += 1\n",
        "fig.suptitle(\"Histograms with Best-Fit Distribution\", fontsize=16)\n",
        "fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "fig.savefig(f\"{SAVE_DIR}/plots/Tx_fitting_summary.png\", dpi=200)\n",
        "plt.show()\n",
        "\n",
        "# 개별 그림\n",
        "for m in ORDER:\n",
        "    if (m == 'Cd') and (not CD_INCLUDE): continue\n",
        "    data = series_map.get(m, pd.Series(dtype=float))\n",
        "    best = fit_tables.get(m, {}).get('best')\n",
        "    obj  = best['obj'] if (best is not None and best.get('obj') is not None and best['obj'].valid) else None\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    plot_hist_with_fit(ax, data, obj, m)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(f\"{SAVE_DIR}/plots/{m}_fit.png\", dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "# ============================================================\n",
        "# 6) 피팅 결과 엑셀 저장\n",
        "# ============================================================\n",
        "fit_xlsx = os.path.join(SAVE_DIR, f\"Tx_fit_result_{'Cd_included' if CD_INCLUDE else 'Cd_excluded'}.xlsx\")\n",
        "wb=Workbook()\n",
        "ws=wb.active; ws.title=\"Tx-적합도 보고서\"\n",
        "\n",
        "def set_col_widths(ws, widths):\n",
        "    for col,w in widths.items(): ws.column_dimensions[col].width = w\n",
        "def styled_header(ws, row, headers, start_col=1, fill_color=HEADER_BLUE):\n",
        "    fill = PatternFill('solid', fgColor=fill_color); white = Font(color='FFFFFF', bold=True)\n",
        "    center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
        "    thin = Border(left=Side(style='thin', color=THIN_GRAY), right=Side(style='thin', color=THIN_GRAY),\n",
        "                  top=Side(style='thin', color=THIN_GRAY), bottom=Side(style='thin', color=THIN_GRAY))\n",
        "    for j,h in enumerate(headers, start=start_col):\n",
        "        c = ws.cell(row=row, column=j, value=h)\n",
        "        c.fill = fill; c.font = white; c.alignment = center; c.border = thin\n",
        "def write_num(ws, r, c, v, fmt='0.0000'):\n",
        "    cell=ws.cell(row=r, column=c)\n",
        "    if v is None or (isinstance(v,float) and (np.isnan(v) or np.isinf(v))): cell.value='---'\n",
        "    else:\n",
        "        cell.value=float(v) if isinstance(v,(int,float,np.floating)) else v\n",
        "        if isinstance(v,(int,float,np.floating)): cell.number_format = fmt\n",
        "\n",
        "set_col_widths(ws, {'A':18,'B':12,'C':12,'D':12,'E':12,'F':12,'G':12,'H':12,'I':64})\n",
        "ws.freeze_panes = 'B3'\n",
        "ws['A1'] = '순위: AD↓ → KS p↑ → χ² p↑ → #params↓'; ws['A2']='데이터 계열'\n",
        "\n",
        "row=3; table_idx=1\n",
        "for m in ORDER:\n",
        "    ws.cell(row=row, column=1, value=m).font = Font(bold=True); row += 1\n",
        "    headers=['분포','A-D','A-D P-값','K-S','K-S P-값','카이제곱','카이제곱 P-값','매개 변수']\n",
        "    styled_header(ws,row,headers,start_col=2); start_row=row; row+=1\n",
        "\n",
        "    tbl = fit_tables.get(m,{}).get('table', pd.DataFrame())\n",
        "    if tbl is None or tbl.empty:\n",
        "        note = \"(excluded)\" if (m=='Cd' and not CD_INCLUDE) else \"(no data or <8 or <3 uniques)\"\n",
        "        ws.cell(row=row, column=2, value=note); row+=2; continue\n",
        "\n",
        "    for i,r_ in tbl.iterrows():\n",
        "        rr=row+i\n",
        "        ws.cell(row=rr, column=2, value=r_['분포'])\n",
        "        write_num(ws, rr,3, r_['AD'])\n",
        "        write_num(ws, rr,4, r_['ADp'])\n",
        "        write_num(ws, rr,5, r_['KS'])\n",
        "        write_num(ws, rr,6, r_['KSp'])\n",
        "        write_num(ws, rr,7, r_['Chi2'])\n",
        "        write_num(ws, rr,8, r_['Chi2p'])\n",
        "        ws.cell(row=rr, column=9, value=pstr(r_['분포'], r_['obj'].p))\n",
        "\n",
        "    end_row = row + len(tbl) - 1\n",
        "    try:\n",
        "        t = Table(displayName=f\"T_{table_idx}\", ref=f\"B{start_row}:I{end_row}\")\n",
        "        t.tableStyleInfo = TableStyleInfo(name=TABLE_STYLE, showFirstColumn=False, showLastColumn=False,\n",
        "                                          showRowStripes=True, showColumnStripes=False)\n",
        "        ws.add_table(t); table_idx+=1\n",
        "    except Exception: pass\n",
        "    fill = PatternFill('solid', fgColor=BEST_FILL)\n",
        "    if len(tbl)>0:\n",
        "        for c in range(2,10): ws.cell(row=start_row+1, column=c).fill=fill\n",
        "    row=end_row+2\n",
        "\n",
        "# --- 시트2: Tx-일괄 분포 적합 가정 (데이터≥1이면 표기) ---\n",
        "wsS = wb.create_sheet(\"Tx-일괄 분포 적합 가정\")\n",
        "metals = [m for m in ORDER if (m in series_map) and (pd.to_numeric(series_map[m], errors='coerce').notna().sum()>=1)]\n",
        "\n",
        "rows_hdr = [\"분포:\", \"최선 적합:\", \"앤더슨-달링\", \"P 값:\"]\n",
        "for i, label in enumerate(rows_hdr, start=1):\n",
        "    wsS.cell(row=i, column=1, value=label).font = Font(bold=True)\n",
        "\n",
        "def safe_EX(best, m):\n",
        "    if best is not None and best.get('obj') is not None and best['obj'].valid:\n",
        "        try:\n",
        "            return float(np.mean(best['obj'].rvs(200000, rs=child_rs())))\n",
        "        except Exception:\n",
        "            pass\n",
        "    if m in series_map:\n",
        "        return float(np.nanmean(pd.to_numeric(series_map[m], errors='coerce')))\n",
        "    return np.nan\n",
        "\n",
        "for j, m in enumerate(metals, start=2):\n",
        "    best = fit_tables.get(m, {}).get('best')\n",
        "    wsS.cell(row=1, column=j, value=m)\n",
        "    ex = safe_EX(best, m); wsS.cell(row=1, column=j, value=ex); wsS.cell(row=1, column=j).number_format='0.0000'\n",
        "    wsS.cell(row=2, column=j, value=(best['분포'] if best is not None else '---'))\n",
        "    wsS.cell(row=3, column=j, value=(float(best['AD']) if (best is not None) else np.nan)); wsS.cell(row=3, column=j).number_format='0.0000'\n",
        "    wsS.cell(row=4, column=j, value=(float(best['ADp']) if (best is not None) else np.nan)); wsS.cell(row=4, column=j).number_format='0.0000'\n",
        "\n",
        "# 상관행렬\n",
        "start_r = 6\n",
        "wsS.cell(row=start_r, column=1, value=\"상관관계:\").font = Font(bold=True)\n",
        "if metals:\n",
        "    df_corr = pd.DataFrame({m: pd.to_numeric(series_map[m], errors='coerce') for m in metals}).corr()\n",
        "    for i, m in enumerate(metals, start=2):\n",
        "        wsS.cell(row=start_r+1, column=i, value=m).font = Font(bold=True)\n",
        "        wsS.cell(row=start_r+1+i-1, column=1, value=m).font = Font(bold=True)\n",
        "    for r, m in enumerate(metals, start=0):\n",
        "        for c, n in enumerate(metals, start=0):\n",
        "            v = float(df_corr.iloc[r, c]) if np.isfinite(df_corr.iloc[r, c]) else np.nan\n",
        "            cell = wsS.cell(row=start_r+2+r, column=2+c, value=v); cell.number_format='0.000'\n",
        "\n",
        "# --- 시트3: Log ---\n",
        "wsL = wb.create_sheet(\"Log\")\n",
        "wsL.append(list(log.columns))\n",
        "for _,r in log.iterrows(): wsL.append(list(r.values))\n",
        "\n",
        "wb.save(fit_xlsx)\n",
        "print(\"Saved:\", fit_xlsx)\n",
        "\n",
        "# ============================================================\n",
        "# 7) 몬테카를로: 농도 난수 + 검증(ECDF/QQ)\n",
        "# ============================================================\n",
        "C_sims={}\n",
        "for m in ORDER:\n",
        "    if (m=='Cd') and (not CD_INCLUDE): continue\n",
        "    s = series_map.get(m, None)\n",
        "    if s is None: continue\n",
        "    info=fit_tables[m]['best']\n",
        "    if (info is not None) and (info.get('obj') is not None) and (info['obj'].valid):\n",
        "        C_sims[m]=info['obj'].rvs(N_SIM, rs=child_rs())\n",
        "    else:\n",
        "        x = pd.to_numeric(s, errors='coerce').dropna().values\n",
        "        if x.size>=1:\n",
        "            idx=np.random.randint(0,len(x), size=N_SIM); C_sims[m]=x[idx]\n",
        "if 'Cr(VI)' not in C_sims and 'Cr' in C_sims: C_sims['Cr(VI)']=C_sims['Cr']/7.0\n",
        "\n",
        "print(\"\\n===== Monte Carlo 난수 샘플 (금속별 농도, µg/m³) =====\")\n",
        "for m in ORDER:\n",
        "    if m in C_sims:\n",
        "        arr = np.array(C_sims[m]); print(f\"{m}: {np.array2string(arr[:10], precision=6, separator=', ')}\")\n",
        "\n",
        "def qstats(x):\n",
        "    x=np.asarray(x, float); x=x[np.isfinite(x)]\n",
        "    return {'mean': float(np.mean(x)), 'median': float(np.median(x)),\n",
        "            'p5': float(np.percentile(x,5)), 'p95': float(np.percentile(x,95))}\n",
        "def print_row(label, d):\n",
        "    print(f\"{label:<18} mean={d['mean']:.3e}, median={d['median']:.3e}, p5={d['p5']:.3e}, p95={d['p95']:.3e}\")\n",
        "def fitted_ppf_summary(dist_obj):\n",
        "    p5  = float(dist_obj.ppf(0.05)); p50 = float(dist_obj.ppf(0.50)); p95 = float(dist_obj.ppf(0.95))\n",
        "    xs  = dist_obj.rvs(200000, rs=child_rs()); mean = float(np.mean(xs))\n",
        "    return {'mean':mean, 'median':p50, 'p5':p5, 'p95':p95}\n",
        "def ecdf(x):\n",
        "    x=np.asarray(x,float); x=x[np.isfinite(x)]; x=np.sort(x); n=x.size\n",
        "    if n==0: return x, x\n",
        "    y=np.arange(1,n+1)/n; return x,y\n",
        "def qq_plot(ax, sample, dist_obj, title):\n",
        "    x=np.asarray(sample,float); x=x[np.isfinite(x)]\n",
        "    if x.size<5: ax.text(0.5,0.5,\"(표본부족)\", ha='center', va='center'); ax.set_title(title); return\n",
        "    x=np.sort(x); n=x.size; probs=(np.arange(1,n+1)-0.5)/n; theo = dist_obj.ppf(probs)\n",
        "    ax.scatter(theo, x, s=6, alpha=0.6); lo,hi = np.nanpercentile(np.concatenate([theo,x]), [1,99])\n",
        "    ax.plot([lo,hi],[lo,hi], lw=1); ax.set_xlabel(\"Theoretical quantile (fit)\"); ax.set_ylabel(\"Sample quantile\")\n",
        "    ax.set_title(title); ax.grid(True, alpha=0.3)\n",
        "\n",
        "def validate_C_distributions():\n",
        "    metals_to_check = [m for m in ORDER if m in C_sims]\n",
        "    for m in metals_to_check:\n",
        "        print(\"\\n\" + \"=\"*76); print(f\"[C 검증] {m}\")\n",
        "        raw_trim = pd.to_numeric(series_map.get(m, pd.Series(dtype=float)), errors='coerce')\n",
        "        raw_trim = raw_trim[np.isfinite(raw_trim)]\n",
        "        s_raw = qstats(raw_trim) if raw_trim.size>0 else None\n",
        "\n",
        "        best = fit_tables.get(m, {}).get('best')\n",
        "        dist = best['obj'] if (best is not None and best.get('obj') is not None) else None\n",
        "        s_fit = fitted_ppf_summary(dist) if (dist is not None and dist.valid) else None\n",
        "\n",
        "        csim = np.asarray(C_sims[m], float); s_sim = qstats(csim)\n",
        "        if s_raw: print_row(\"Raw(trimmed)\", s_raw)\n",
        "        else: print(\"Raw(trimmed)     없음/표본부족\")\n",
        "        if s_fit: print_row(\"Fitted(theory)\", s_fit)\n",
        "        else: print(\"Fitted(theory)   없음/피팅불가\")\n",
        "        print_row(\"Simulated(C_sims)\", s_sim)\n",
        "\n",
        "        plt.figure(figsize=(10,4))\n",
        "        ax1 = plt.subplot(1,2,1)\n",
        "        if raw_trim.size>0:\n",
        "            x,y = ecdf(raw_trim); ax1.step(x,y, where='post', label='Raw', alpha=0.8)\n",
        "        xs,ys = ecdf(csim); ax1.step(xs,ys, where='post', label='Simulated', alpha=0.8)\n",
        "        try:\n",
        "            spread = np.nanpercentile(xs,95)/max(1e-12,np.nanpercentile(xs,5))\n",
        "            if spread>20: ax1.set_xscale('log')\n",
        "        except: pass\n",
        "        ax1.set_title(f\"{m} – ECDF\"); ax1.set_xlabel(\"Concentration (µg/m³)\"); ax1.set_ylabel(\"Cumulative probability\")\n",
        "        ax1.grid(True, alpha=0.3); ax1.legend()\n",
        "\n",
        "        ax2 = plt.subplot(1,2,2)\n",
        "        if (dist is not None) and dist.valid:\n",
        "            qq_plot(ax2, csim, dist, f\"{m} – Q–Q (Sim vs Fit)\")\n",
        "        else:\n",
        "            ax2.text(0.5,0.5,\"피팅없음\", ha='center', va='center'); ax2.axis('off')\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "validate_C_distributions()\n",
        "\n",
        "# ============================================================\n",
        "# 8) Time-outdoors 난수 → K 계산 + 검증 표\n",
        "# ============================================================\n",
        "_Z95=1.6448536269514722\n",
        "def mu_sigma_from_p5p95(p5,p95):\n",
        "    p5=max(1e-9,float(p5)); p95=max(1e-9,float(p95))\n",
        "    if p95<=p5: p95=p5*1.01\n",
        "    ln5,ln95=np.log(p5),np.log(p95); sigma=(ln95-ln5)/(2*_Z95); mu=(ln5+ln95)/2; return mu,sigma\n",
        "def sample_AcTout(age, n):\n",
        "    if age in ACT_POINT: return np.full(n, float(ACT_POINT[age]), dtype=float)\n",
        "    p5,p95=ACT_LN_P5_P95[age]; mu,sg=mu_sigma_from_p5p95(p5,p95)\n",
        "    return np.random.lognormal(mu,sg,size=n)\n",
        "def K_by_group(n):\n",
        "    Kg = {'Infant':np.zeros(n), 'Child':np.zeros(n), 'Adult':np.zeros(n)}\n",
        "    for age in INFANT+CHILD+ADULT:\n",
        "        act = sample_AcTout(age, n)\n",
        "        act_dayfrac = act / 1440.0\n",
        "        add = act_dayfrac * EF * (ED_years[age]/LT_years) * (10.0 if age in INFANT else (3.0 if age in CHILD else 1.0))\n",
        "        if age in INFANT: Kg['Infant'] += add\n",
        "        elif age in CHILD: Kg['Child'] += add\n",
        "        else: Kg['Adult'] += add\n",
        "    Kg['Lifetime'] = Kg['Infant'] + Kg['Child'] + Kg['Adult']\n",
        "    return Kg\n",
        "Kg = K_by_group(N_SIM)\n",
        "\n",
        "print(\"\\n===== Time outdoors 난수 샘플 (min/day) =====\")\n",
        "for age in AGE_ORDER:\n",
        "    arr = sample_AcTout(age, 10)\n",
        "    print(f\"{age}: {np.array2string(arr, precision=3, separator=', ')}\")\n",
        "\n",
        "def check_time_out_samples():\n",
        "    print(\"\\n===== Time outdoors 난수 분포 검증 =====\")\n",
        "    print(f\"{'Age':<10} {'Mean(sample)':>12} {'P5(sample)':>12} {'P95(sample)':>12} {'Target Mean':>12} {'Target 95th':>12}\")\n",
        "    for age in AGE_ORDER:\n",
        "        n=200000\n",
        "        s=sample_AcTout(age, n)\n",
        "        mean_s=np.mean(s); p5_s=np.percentile(s,5); p95_s=np.percentile(s,95)\n",
        "        if age in ACT_POINT: t_mean=ACT_POINT[age]; t_p95=ACT_POINT[age]\n",
        "        else: t_mean=None; t_p95=ACT_LN_P5_P95[age][1]\n",
        "        t_mean_str = f\"{t_mean:,.1f}\" if t_mean is not None else \"---\"\n",
        "        print(f\"{age:<10} {mean_s:12.3f} {p5_s:12.3f} {p95_s:12.3f} {t_mean_str:>12} {t_p95:12.1f}\")\n",
        "check_time_out_samples()\n",
        "\n",
        "# ============================================================\n",
        "# 9) LECR 계산 + 요약 출력 + 엑셀 저장\n",
        "# ============================================================\n",
        "def summarize_risk(C_sims, Kg):\n",
        "    out_rows=[]; cum_vec = np.zeros(N_SIM)\n",
        "    for m in ORDER:\n",
        "        if (m not in IUR) or (m not in C_sims): continue\n",
        "        C = np.asarray(C_sims[m], float)\n",
        "        ladd_tot = C * Kg['Lifetime']\n",
        "        lecr_tot = ladd_tot * float(IUR[m])\n",
        "        cum_vec += lecr_tot\n",
        "        def stats1(v):\n",
        "            v=np.asarray(v,float); return dict(mean=float(np.mean(v)), median=float(np.median(v)),\n",
        "                                               p95=float(np.percentile(v,95)), p99=float(np.percentile(v,99)))\n",
        "        out_rows.append({'Metal': m, 'LECR (per metal)':  stats1(lecr_tot)})\n",
        "    cum_stats = {'Total LECR': {'mean': float(np.mean(cum_vec)),\n",
        "                                'median': float(np.median(cum_vec)),\n",
        "                                'p95': float(np.percentile(cum_vec,95)),\n",
        "                                'p99': float(np.percentile(cum_vec,99))}}\n",
        "    return out_rows, cum_stats\n",
        "\n",
        "risk_rows, cum_stats = summarize_risk(C_sims, Kg)\n",
        "\n",
        "print(\"\\n===== LECR 요약 (per metal; Lifetime) =====\")\n",
        "for r in risk_rows:\n",
        "    s=r['LECR (per metal)']\n",
        "    print(f\"[{r['Metal']}]  mean={s['mean']:.3e}, median={s['median']:.3e}, P95={s['p95']:.3e}, P99={s['p99']:.3e}\")\n",
        "print(\"\\n===== Total LECR (Lifetime, across metals) =====\")\n",
        "cs = cum_stats['Total LECR']\n",
        "print(f\"  mean={cs['mean']:.3e}, median={cs['median']:.3e}, P95={cs['p95']:.3e}, P99={cs['p99']:.3e}\")\n",
        "\n",
        "# 엑셀 저장\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "lecr_xlsx = os.path.join(SAVE_DIR, \"Tx.xlsx\")\n",
        "wb2 = Workbook(); wsR=wb2.active; wsR.title=\"LECR 결과 요약\"\n",
        "wsR.append([\"Metal\",\"mean\",\"median\",\"P95\",\"P99\"])\n",
        "for r in risk_rows:\n",
        "    m=r['Metal']; s=r['LECR (per metal)']; wsR.append([m,s['mean'],s['median'],s['p95'],s['p99']])\n",
        "wsR2 = wb2.create_sheet(\"Total LECR\")\n",
        "wsR2.append([\"metric\",\"value\"])\n",
        "for k,v in cum_stats['Total LECR'].items(): wsR2.append([k,v])\n",
        "wb2.save(lecr_xlsx)\n",
        "\n",
        "print(\"\\n=== 완료 ===\")\n",
        "print(f\"- 피팅 엑셀: {fit_xlsx}\")\n",
        "print(f\"- LECR 엑셀: {lecr_xlsx}\")\n",
        "print(f\"- 그림 폴더: {SAVE_DIR}/plots\")\n",
        "from google.colab import files; files.download(fit_xlsx); files.download(lecr_xlsx)"
      ],
      "metadata": {
        "id": "FiBFX0u1wAap",
        "outputId": "a45d607f-791e-4bda-bd7d-75a403f1148d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "엑셀 파일 업로드(.xlsx/.xls)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e3b4e1b-9bdd-4953-87f9-6d6ba72c9005\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e3b4e1b-9bdd-4953-87f9-6d6ba72c9005\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 202501_04_clean.xlsx to 202501_04_clean (4).xlsx\n",
            "선택된 시트: Sheet1\n",
            "\n",
            "[DEBUG] 유효 표본수 요약: {'Cr': 1092, 'Co': 1520, 'Ni': 1051, 'As': 1514, 'Cd': 1540, 'Sb': 918, 'Pb': 1277}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LECR 결과값 검토"
      ],
      "metadata": {
        "id": "YTEZwZfa8bd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BTcJ491-83RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 금속별 + 총합 LECR 누적확률분포 그래프 추가"
      ],
      "metadata": {
        "id": "uStyw3HD8bHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0A1QK6C83ec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}